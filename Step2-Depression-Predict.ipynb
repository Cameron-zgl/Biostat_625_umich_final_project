{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed1f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d19692a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # Check if GPU is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d5bc7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/gulizhu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/gulizhu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/gulizhu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Filtering depression data...\n",
      "Sampling 117331 rows from non-mental health data...\n",
      "Annotating depression data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2444665/283474530.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  depression_data['processed_post'] = depression_data['post'].apply(preprocess_text)\n",
      "/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotating sampled non-mental health data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2444665/283474530.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  depression_data['category'] = 'depression'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging annotated datasets...\n",
      "Annotation complete. Results saved to combined_annotated_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from transformers import pipeline\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# List of depression-related keywords\n",
    "depression_keywords = [\"depression\", \"sad\", \"hopeless\", \"tired\", \"lonely\", \n",
    "                       \"suicidal\", \"cry\", \"worthless\", \"empty\", \"dark\", \"hurt\"]\n",
    "\n",
    "# Load sentiment analysis models\n",
    "sia = SentimentIntensityAnalyzer()  # VADER model\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", device=0, truncation=True, max_length=512)\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess text by lowercasing, tokenizing, removing stopwords, and filtering alphanumeric words.\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(str(text).lower())  # Tokenize and convert to lowercase\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Function to annotate posts for depression risk\n",
    "def annotate_post(text):\n",
    "    \"\"\"\n",
    "    Annotate text with depression risk labels.\n",
    "    - Truncate text to avoid model token limit errors.\n",
    "    \"\"\"\n",
    "    text = preprocess_text(text)\n",
    "    text = ' '.join(text.split()[:512])  # Truncate to 512 tokens\n",
    "    \n",
    "    # Keyword matching\n",
    "    keyword_match = any(word in text for word in depression_keywords)\n",
    "    \n",
    "    # VADER sentiment analysis\n",
    "    sentiment_score = sia.polarity_scores(text)['compound']\n",
    "    vader_label = 1 if sentiment_score < -0.5 else 0\n",
    "    \n",
    "    # Transformers sentiment analysis with truncation\n",
    "    sentiment_result = sentiment_pipeline(text, truncation=True, max_length=512)[0]['label']\n",
    "    transformer_label = 1 if sentiment_result == \"NEGATIVE\" else 0\n",
    "    \n",
    "    # Final depression label\n",
    "    # Changed logic to \"and\": both keyword match and negative sentiment required\n",
    "    depression_label = 1 if (keyword_match and vader_label and transformer_label) else 0\n",
    "    return depression_label, sentiment_score, transformer_label\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "print(\"Loading datasets...\")\n",
    "mental_health_data = pd.read_csv(\"mental_health_support.csv\")\n",
    "non_mental_health_data = pd.read_csv(\"non_mental_health.csv\")\n",
    "\n",
    "# Filter depression data\n",
    "print(\"Filtering depression data...\")\n",
    "depression_data = mental_health_data[mental_health_data['subreddit'] == 'depression']\n",
    "\n",
    "# Randomly sample the same number of posts from non-mental health data\n",
    "sample_size = len(depression_data)\n",
    "print(f\"Sampling {sample_size} rows from non-mental health data...\")\n",
    "non_mental_sample = non_mental_health_data.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Annotate depression data\n",
    "print(\"Annotating depression data...\")\n",
    "depression_data['processed_post'] = depression_data['post'].apply(preprocess_text)\n",
    "depression_data[['depression_label', 'vader_score', 'transformer_label']] = \\\n",
    "    depression_data['post'].apply(lambda x: pd.Series(annotate_post(x)))\n",
    "\n",
    "# Annotate sampled non-mental health data\n",
    "print(\"Annotating sampled non-mental health data...\")\n",
    "non_mental_sample['processed_post'] = non_mental_sample['post'].apply(preprocess_text)\n",
    "non_mental_sample[['depression_label', 'vader_score', 'transformer_label']] = \\\n",
    "    non_mental_sample['post'].apply(lambda x: pd.Series(annotate_post(x)))\n",
    "\n",
    "# Add category labels\n",
    "depression_data['category'] = 'depression'\n",
    "non_mental_sample['category'] = 'non_mental_health'\n",
    "\n",
    "# Merge the two datasets\n",
    "print(\"Merging annotated datasets...\")\n",
    "combined_data = pd.concat([depression_data, non_mental_sample], ignore_index=True)\n",
    "\n",
    "# Save the annotated results to a CSV file\n",
    "output_file = \"combined_annotated_data.csv\"\n",
    "combined_data.to_csv(output_file, index=False)\n",
    "print(f\"Annotation complete. Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85fdd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved to combined_annotated_data_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# keyword\n",
    "depression_keywords = [\"depression\", \"sad\", \"hopeless\", \"tired\", \"lonely\", \n",
    "                       \"suicidal\", \"cry\", \"worthless\", \"empty\", \"dark\", \"hurt\"]\n",
    "\n",
    "\n",
    "input_file = \"combined_annotated_data.csv\"\n",
    "output_file = \"combined_annotated_data_updated.csv\"\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "\n",
    "def contains_keyword(text):\n",
    "    \"\"\"\n",
    "    Check if the text contains any depression-related keywords.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):  \n",
    "        return False\n",
    "    return any(keyword in text for keyword in depression_keywords)\n",
    "\n",
    "#depression_label\n",
    "def recalculate_label(row):\n",
    "    \"\"\"\n",
    "    Recalculate depression_label based on 'vader_score' and 'processed_post'.\n",
    "    Both conditions (keywords and vader_score) must be met.\n",
    "    \"\"\"\n",
    "    has_keyword = contains_keyword(row['processed_post'])\n",
    "    is_negative_sentiment = row['vader_score'] < -0.5\n",
    "    return 1 if has_keyword and is_negative_sentiment else 0\n",
    "\n",
    "\n",
    "data['depression_label'] = data.apply(recalculate_label, axis=1)\n",
    "\n",
    "\n",
    "data.to_csv(output_file, index=False)\n",
    "print(f\"Updated file saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db97396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive examples (depression_label=1): 48159\n",
      "Negative examples (depression_label=0): 186503\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"combined_annotated_data_updated.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "positive_count = (data['depression_label'] == 1).sum()\n",
    "negative_count = (data['depression_label'] == 0).sum()\n",
    "\n",
    "\n",
    "print(f\"Positive examples (depression_label=1): {positive_count}\")\n",
    "print(f\"Negative examples (depression_label=0): {negative_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fde9221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4891b521",
   "metadata": {},
   "source": [
    "# Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "624fe6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load annotated dataset\n",
    "data = pd.read_csv(\"combined_annotated_data_updated.csv\")\n",
    "data['processed_post'] = data['processed_post'].fillna(\"\")  # Clean NaN values in the entire column\n",
    "\n",
    "# Prepare labels and features\n",
    "X = data['processed_post']\n",
    "y = data['depression_label']\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Feature Extraction\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdb51bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>post</th>\n",
       "      <th>processed_post</th>\n",
       "      <th>depression_label</th>\n",
       "      <th>vader_score</th>\n",
       "      <th>transformer_label</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>depression</td>\n",
       "      <td>What_I_do_45</td>\n",
       "      <td>2019/08/28</td>\n",
       "      <td>I want to enjoy relationships with people but ...</td>\n",
       "      <td>want enjoy relationships people ca enjoy peopl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depression</td>\n",
       "      <td>Bleumoon_Selene</td>\n",
       "      <td>2019/08/28</td>\n",
       "      <td>I didn't ask to be here. I didn't ask to be bo...</td>\n",
       "      <td>ask ask born come life willingly least feels l...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depression</td>\n",
       "      <td>Karuderu</td>\n",
       "      <td>2019/08/28</td>\n",
       "      <td>I don't know, If i can't handle anything anymo...</td>\n",
       "      <td>know ca handle anything anymore feel like hope...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>depression</td>\n",
       "      <td>ThisNotMyMainAcc</td>\n",
       "      <td>2019/08/28</td>\n",
       "      <td>I want to know what it feels like to feel genu...</td>\n",
       "      <td>want know feels like feel genuinely loved some...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>depression</td>\n",
       "      <td>edgelord3045</td>\n",
       "      <td>2019/08/28</td>\n",
       "      <td>It doesn't even matter I know this will most l...</td>\n",
       "      <td>even matter know likely even opened gon na sit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234657</th>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Tossmeout3241</td>\n",
       "      <td>2018/01/15</td>\n",
       "      <td>On December 31st 2018, I want to quit my job a...</td>\n",
       "      <td>december 31st 2018 want quit job pursue person...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>non_mental_health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234658</th>\n",
       "      <td>personalfinance</td>\n",
       "      <td>mediumcake</td>\n",
       "      <td>2019/04/15</td>\n",
       "      <td>How much house can I really afford? My wife an...</td>\n",
       "      <td>much house really afford wife looking forever ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>non_mental_health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234659</th>\n",
       "      <td>personalfinance</td>\n",
       "      <td>N301CF</td>\n",
       "      <td>2019/04/10</td>\n",
       "      <td>Moving Jobs / Offer Process Taking Long I’m in...</td>\n",
       "      <td>moving jobs offer process taking long process ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>non_mental_health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234660</th>\n",
       "      <td>meditation</td>\n",
       "      <td>knucklehead21</td>\n",
       "      <td>2018/02/25</td>\n",
       "      <td>What do you do for anxiety? How do you meditat...</td>\n",
       "      <td>anxiety meditate improve life life completely ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>non_mental_health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234661</th>\n",
       "      <td>personalfinance</td>\n",
       "      <td>lyonconner</td>\n",
       "      <td>2018/03/15</td>\n",
       "      <td>Pilot license, loans etc A brief introduction ...</td>\n",
       "      <td>pilot license loans etc brief introduction 20 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>non_mental_health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234662 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              subreddit            author        date  \\\n",
       "0            depression      What_I_do_45  2019/08/28   \n",
       "1            depression   Bleumoon_Selene  2019/08/28   \n",
       "2            depression          Karuderu  2019/08/28   \n",
       "3            depression  ThisNotMyMainAcc  2019/08/28   \n",
       "4            depression      edgelord3045  2019/08/28   \n",
       "...                 ...               ...         ...   \n",
       "234657  personalfinance     Tossmeout3241  2018/01/15   \n",
       "234658  personalfinance        mediumcake  2019/04/15   \n",
       "234659  personalfinance            N301CF  2019/04/10   \n",
       "234660       meditation     knucklehead21  2018/02/25   \n",
       "234661  personalfinance        lyonconner  2018/03/15   \n",
       "\n",
       "                                                     post  \\\n",
       "0       I want to enjoy relationships with people but ...   \n",
       "1       I didn't ask to be here. I didn't ask to be bo...   \n",
       "2       I don't know, If i can't handle anything anymo...   \n",
       "3       I want to know what it feels like to feel genu...   \n",
       "4       It doesn't even matter I know this will most l...   \n",
       "...                                                   ...   \n",
       "234657  On December 31st 2018, I want to quit my job a...   \n",
       "234658  How much house can I really afford? My wife an...   \n",
       "234659  Moving Jobs / Offer Process Taking Long I’m in...   \n",
       "234660  What do you do for anxiety? How do you meditat...   \n",
       "234661  Pilot license, loans etc A brief introduction ...   \n",
       "\n",
       "                                           processed_post  depression_label  \\\n",
       "0       want enjoy relationships people ca enjoy peopl...                 0   \n",
       "1       ask ask born come life willingly least feels l...                 0   \n",
       "2       know ca handle anything anymore feel like hope...                 0   \n",
       "3       want know feels like feel genuinely loved some...                 0   \n",
       "4       even matter know likely even opened gon na sit...                 0   \n",
       "...                                                   ...               ...   \n",
       "234657  december 31st 2018 want quit job pursue person...                 0   \n",
       "234658  much house really afford wife looking forever ...                 0   \n",
       "234659  moving jobs offer process taking long process ...                 0   \n",
       "234660  anxiety meditate improve life life completely ...                 0   \n",
       "234661  pilot license loans etc brief introduction 20 ...                 0   \n",
       "\n",
       "        vader_score  transformer_label           category  \n",
       "0            0.9577                1.0         depression  \n",
       "1           -0.3182                1.0         depression  \n",
       "2            0.9845                1.0         depression  \n",
       "3            0.0384                1.0         depression  \n",
       "4            0.9970                1.0         depression  \n",
       "...             ...                ...                ...  \n",
       "234657       0.7010                1.0  non_mental_health  \n",
       "234658       0.2263                1.0  non_mental_health  \n",
       "234659       0.6486                1.0  non_mental_health  \n",
       "234660       0.6133                1.0  non_mental_health  \n",
       "234661       0.9022                1.0  non_mental_health  \n",
       "\n",
       "[234662 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04100602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression Model...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95     37362\n",
      "           1       0.84      0.73      0.78      9571\n",
      "\n",
      "    accuracy                           0.92     46933\n",
      "   macro avg       0.89      0.84      0.86     46933\n",
      "weighted avg       0.91      0.92      0.91     46933\n",
      "\n",
      "Accuracy: 0.9158800843755993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "print(\"Training Logistic Regression Model...\")\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Model Predictions\n",
    "y_pred = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Model Evaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d7e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ffdb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341f5428fa104e75a334dc4498b8d1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e3797f46ec420c94492605e16731dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624b77bb60d9489d9213019e4a963ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b905929dba2e4292828db051bfe9b5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c536a3fa2c994c118329cddf8d782deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM Model with BERT Embeddings...\n",
      "Starting epoch 1...\n",
      "Epoch 1, Batch 10/5867, Loss: 0.3008\n",
      "Epoch 1, Batch 20/5867, Loss: 0.4418\n",
      "Epoch 1, Batch 30/5867, Loss: 0.4061\n",
      "Epoch 1, Batch 40/5867, Loss: 0.5457\n",
      "Epoch 1, Batch 50/5867, Loss: 0.3661\n",
      "Epoch 1, Batch 60/5867, Loss: 0.3373\n",
      "Epoch 1, Batch 70/5867, Loss: 0.2036\n",
      "Epoch 1, Batch 80/5867, Loss: 0.3546\n",
      "Epoch 1, Batch 90/5867, Loss: 0.2359\n",
      "Epoch 1, Batch 100/5867, Loss: 0.3414\n",
      "Epoch 1, Batch 110/5867, Loss: 0.4045\n",
      "Epoch 1, Batch 120/5867, Loss: 0.3469\n",
      "Epoch 1, Batch 130/5867, Loss: 0.3419\n",
      "Epoch 1, Batch 140/5867, Loss: 0.4231\n",
      "Epoch 1, Batch 150/5867, Loss: 0.5546\n",
      "Epoch 1, Batch 160/5867, Loss: 0.4145\n",
      "Epoch 1, Batch 170/5867, Loss: 0.2907\n",
      "Epoch 1, Batch 180/5867, Loss: 0.2384\n",
      "Epoch 1, Batch 190/5867, Loss: 0.3506\n",
      "Epoch 1, Batch 200/5867, Loss: 0.2749\n",
      "Epoch 1, Batch 210/5867, Loss: 0.3416\n",
      "Epoch 1, Batch 220/5867, Loss: 0.3589\n",
      "Epoch 1, Batch 230/5867, Loss: 0.3245\n",
      "Epoch 1, Batch 240/5867, Loss: 0.4403\n",
      "Epoch 1, Batch 250/5867, Loss: 0.3354\n",
      "Epoch 1, Batch 260/5867, Loss: 0.3010\n",
      "Epoch 1, Batch 270/5867, Loss: 0.2652\n",
      "Epoch 1, Batch 280/5867, Loss: 0.3469\n",
      "Epoch 1, Batch 290/5867, Loss: 0.5215\n",
      "Epoch 1, Batch 300/5867, Loss: 0.2229\n",
      "Epoch 1, Batch 310/5867, Loss: 0.4570\n",
      "Epoch 1, Batch 320/5867, Loss: 0.3318\n",
      "Epoch 1, Batch 330/5867, Loss: 0.3520\n",
      "Epoch 1, Batch 340/5867, Loss: 0.2697\n",
      "Epoch 1, Batch 350/5867, Loss: 0.2938\n",
      "Epoch 1, Batch 360/5867, Loss: 0.3350\n",
      "Epoch 1, Batch 370/5867, Loss: 0.3456\n",
      "Epoch 1, Batch 380/5867, Loss: 0.2890\n",
      "Epoch 1, Batch 390/5867, Loss: 0.2534\n",
      "Epoch 1, Batch 400/5867, Loss: 0.4372\n",
      "Epoch 1, Batch 410/5867, Loss: 0.4369\n",
      "Epoch 1, Batch 420/5867, Loss: 0.3644\n",
      "Epoch 1, Batch 430/5867, Loss: 0.6297\n",
      "Epoch 1, Batch 440/5867, Loss: 0.2880\n",
      "Epoch 1, Batch 450/5867, Loss: 0.2979\n",
      "Epoch 1, Batch 460/5867, Loss: 0.2582\n",
      "Epoch 1, Batch 470/5867, Loss: 0.3323\n",
      "Epoch 1, Batch 480/5867, Loss: 0.2440\n",
      "Epoch 1, Batch 490/5867, Loss: 0.3769\n",
      "Epoch 1, Batch 500/5867, Loss: 0.2765\n",
      "Epoch 1, Batch 510/5867, Loss: 0.3070\n",
      "Epoch 1, Batch 520/5867, Loss: 0.2094\n",
      "Epoch 1, Batch 530/5867, Loss: 0.1973\n",
      "Epoch 1, Batch 540/5867, Loss: 0.3449\n",
      "Epoch 1, Batch 550/5867, Loss: 0.5801\n",
      "Epoch 1, Batch 560/5867, Loss: 0.2779\n",
      "Epoch 1, Batch 570/5867, Loss: 0.1879\n",
      "Epoch 1, Batch 580/5867, Loss: 0.3626\n",
      "Epoch 1, Batch 590/5867, Loss: 0.3994\n",
      "Epoch 1, Batch 600/5867, Loss: 0.1833\n",
      "Epoch 1, Batch 610/5867, Loss: 0.4634\n",
      "Epoch 1, Batch 620/5867, Loss: 0.2124\n",
      "Epoch 1, Batch 630/5867, Loss: 0.3615\n",
      "Epoch 1, Batch 640/5867, Loss: 0.2949\n",
      "Epoch 1, Batch 650/5867, Loss: 0.2544\n",
      "Epoch 1, Batch 660/5867, Loss: 0.3177\n",
      "Epoch 1, Batch 670/5867, Loss: 0.4094\n",
      "Epoch 1, Batch 680/5867, Loss: 0.3610\n",
      "Epoch 1, Batch 690/5867, Loss: 0.2218\n",
      "Epoch 1, Batch 700/5867, Loss: 0.3085\n",
      "Epoch 1, Batch 710/5867, Loss: 0.3951\n",
      "Epoch 1, Batch 720/5867, Loss: 0.2694\n",
      "Epoch 1, Batch 730/5867, Loss: 0.2168\n",
      "Epoch 1, Batch 740/5867, Loss: 0.4877\n",
      "Epoch 1, Batch 750/5867, Loss: 0.3449\n",
      "Epoch 1, Batch 760/5867, Loss: 0.3333\n",
      "Epoch 1, Batch 770/5867, Loss: 0.1416\n",
      "Epoch 1, Batch 780/5867, Loss: 0.2260\n",
      "Epoch 1, Batch 790/5867, Loss: 0.1655\n",
      "Epoch 1, Batch 800/5867, Loss: 0.3170\n",
      "Epoch 1, Batch 810/5867, Loss: 0.3704\n",
      "Epoch 1, Batch 820/5867, Loss: 0.2298\n",
      "Epoch 1, Batch 830/5867, Loss: 0.1896\n",
      "Epoch 1, Batch 840/5867, Loss: 0.3349\n",
      "Epoch 1, Batch 850/5867, Loss: 0.2531\n",
      "Epoch 1, Batch 860/5867, Loss: 0.2931\n",
      "Epoch 1, Batch 870/5867, Loss: 0.3887\n",
      "Epoch 1, Batch 880/5867, Loss: 0.2610\n",
      "Epoch 1, Batch 890/5867, Loss: 0.2176\n",
      "Epoch 1, Batch 900/5867, Loss: 0.3605\n",
      "Epoch 1, Batch 910/5867, Loss: 0.2145\n",
      "Epoch 1, Batch 920/5867, Loss: 0.2841\n",
      "Epoch 1, Batch 930/5867, Loss: 0.2162\n",
      "Epoch 1, Batch 940/5867, Loss: 0.3976\n",
      "Epoch 1, Batch 950/5867, Loss: 0.3313\n",
      "Epoch 1, Batch 960/5867, Loss: 0.2346\n",
      "Epoch 1, Batch 970/5867, Loss: 0.1609\n",
      "Epoch 1, Batch 980/5867, Loss: 0.3879\n",
      "Epoch 1, Batch 990/5867, Loss: 0.2469\n",
      "Epoch 1, Batch 1000/5867, Loss: 0.3367\n",
      "Epoch 1, Batch 1010/5867, Loss: 0.2996\n",
      "Epoch 1, Batch 1020/5867, Loss: 0.2852\n",
      "Epoch 1, Batch 1030/5867, Loss: 0.4061\n",
      "Epoch 1, Batch 1040/5867, Loss: 0.4110\n",
      "Epoch 1, Batch 1050/5867, Loss: 0.2812\n",
      "Epoch 1, Batch 1060/5867, Loss: 0.2372\n",
      "Epoch 1, Batch 1070/5867, Loss: 0.2270\n",
      "Epoch 1, Batch 1080/5867, Loss: 0.3012\n",
      "Epoch 1, Batch 1090/5867, Loss: 0.4407\n",
      "Epoch 1, Batch 1100/5867, Loss: 0.3828\n",
      "Epoch 1, Batch 1110/5867, Loss: 0.2400\n",
      "Epoch 1, Batch 1120/5867, Loss: 0.3847\n",
      "Epoch 1, Batch 1130/5867, Loss: 0.2224\n",
      "Epoch 1, Batch 1140/5867, Loss: 0.2974\n",
      "Epoch 1, Batch 1150/5867, Loss: 0.1468\n",
      "Epoch 1, Batch 1160/5867, Loss: 0.4386\n",
      "Epoch 1, Batch 1170/5867, Loss: 0.3712\n",
      "Epoch 1, Batch 1180/5867, Loss: 0.4041\n",
      "Epoch 1, Batch 1190/5867, Loss: 0.4806\n",
      "Epoch 1, Batch 1200/5867, Loss: 0.2628\n",
      "Epoch 1, Batch 1210/5867, Loss: 0.2232\n",
      "Epoch 1, Batch 1220/5867, Loss: 0.2389\n",
      "Epoch 1, Batch 1230/5867, Loss: 0.1810\n",
      "Epoch 1, Batch 1240/5867, Loss: 0.2507\n",
      "Epoch 1, Batch 1250/5867, Loss: 0.2894\n",
      "Epoch 1, Batch 1260/5867, Loss: 0.3333\n",
      "Epoch 1, Batch 1270/5867, Loss: 0.3200\n",
      "Epoch 1, Batch 1280/5867, Loss: 0.1957\n",
      "Epoch 1, Batch 1290/5867, Loss: 0.1977\n",
      "Epoch 1, Batch 1300/5867, Loss: 0.2839\n",
      "Epoch 1, Batch 1310/5867, Loss: 0.3373\n",
      "Epoch 1, Batch 1320/5867, Loss: 0.2692\n",
      "Epoch 1, Batch 1330/5867, Loss: 0.2682\n",
      "Epoch 1, Batch 1340/5867, Loss: 0.1875\n",
      "Epoch 1, Batch 1350/5867, Loss: 0.5390\n",
      "Epoch 1, Batch 1360/5867, Loss: 0.4197\n",
      "Epoch 1, Batch 1370/5867, Loss: 0.1777\n",
      "Epoch 1, Batch 1380/5867, Loss: 0.2600\n",
      "Epoch 1, Batch 1390/5867, Loss: 0.2258\n",
      "Epoch 1, Batch 1400/5867, Loss: 0.2631\n",
      "Epoch 1, Batch 1410/5867, Loss: 0.2202\n",
      "Epoch 1, Batch 1420/5867, Loss: 0.2024\n",
      "Epoch 1, Batch 1430/5867, Loss: 0.2039\n",
      "Epoch 1, Batch 1440/5867, Loss: 0.3756\n",
      "Epoch 1, Batch 1450/5867, Loss: 0.2556\n",
      "Epoch 1, Batch 1460/5867, Loss: 0.2922\n",
      "Epoch 1, Batch 1470/5867, Loss: 0.3042\n",
      "Epoch 1, Batch 1480/5867, Loss: 0.2846\n",
      "Epoch 1, Batch 1490/5867, Loss: 0.0666\n",
      "Epoch 1, Batch 1500/5867, Loss: 0.1545\n",
      "Epoch 1, Batch 1510/5867, Loss: 0.3919\n",
      "Epoch 1, Batch 1520/5867, Loss: 0.2197\n",
      "Epoch 1, Batch 1530/5867, Loss: 0.1431\n",
      "Epoch 1, Batch 1540/5867, Loss: 0.4489\n",
      "Epoch 1, Batch 1550/5867, Loss: 0.2217\n",
      "Epoch 1, Batch 1560/5867, Loss: 0.2479\n",
      "Epoch 1, Batch 1570/5867, Loss: 0.0655\n",
      "Epoch 1, Batch 1580/5867, Loss: 0.2334\n",
      "Epoch 1, Batch 1590/5867, Loss: 0.2722\n",
      "Epoch 1, Batch 1600/5867, Loss: 0.1943\n",
      "Epoch 1, Batch 1610/5867, Loss: 0.1320\n",
      "Epoch 1, Batch 1620/5867, Loss: 0.1766\n",
      "Epoch 1, Batch 1630/5867, Loss: 0.2731\n",
      "Epoch 1, Batch 1640/5867, Loss: 0.2809\n",
      "Epoch 1, Batch 1650/5867, Loss: 0.4549\n",
      "Epoch 1, Batch 1660/5867, Loss: 0.5091\n",
      "Epoch 1, Batch 1670/5867, Loss: 0.3440\n",
      "Epoch 1, Batch 1680/5867, Loss: 0.2674\n",
      "Epoch 1, Batch 1690/5867, Loss: 0.2411\n",
      "Epoch 1, Batch 1700/5867, Loss: 0.2335\n",
      "Epoch 1, Batch 1710/5867, Loss: 0.1789\n",
      "Epoch 1, Batch 1720/5867, Loss: 0.3639\n",
      "Epoch 1, Batch 1730/5867, Loss: 0.1250\n",
      "Epoch 1, Batch 1740/5867, Loss: 0.2572\n",
      "Epoch 1, Batch 1750/5867, Loss: 0.4106\n",
      "Epoch 1, Batch 1760/5867, Loss: 0.4419\n",
      "Epoch 1, Batch 1770/5867, Loss: 0.2259\n",
      "Epoch 1, Batch 1780/5867, Loss: 0.2020\n",
      "Epoch 1, Batch 1790/5867, Loss: 0.3401\n",
      "Epoch 1, Batch 1800/5867, Loss: 0.2797\n",
      "Epoch 1, Batch 1810/5867, Loss: 0.2915\n",
      "Epoch 1, Batch 1820/5867, Loss: 0.2096\n",
      "Epoch 1, Batch 1830/5867, Loss: 0.1656\n",
      "Epoch 1, Batch 1840/5867, Loss: 0.2367\n",
      "Epoch 1, Batch 1850/5867, Loss: 0.1616\n",
      "Epoch 1, Batch 1860/5867, Loss: 0.3850\n",
      "Epoch 1, Batch 1870/5867, Loss: 0.1715\n",
      "Epoch 1, Batch 1880/5867, Loss: 0.4262\n",
      "Epoch 1, Batch 1890/5867, Loss: 0.2075\n",
      "Epoch 1, Batch 1900/5867, Loss: 0.3091\n",
      "Epoch 1, Batch 1910/5867, Loss: 0.4758\n",
      "Epoch 1, Batch 1920/5867, Loss: 0.5687\n",
      "Epoch 1, Batch 1930/5867, Loss: 0.3596\n",
      "Epoch 1, Batch 1940/5867, Loss: 0.2337\n",
      "Epoch 1, Batch 1950/5867, Loss: 0.3689\n",
      "Epoch 1, Batch 1960/5867, Loss: 0.1766\n",
      "Epoch 1, Batch 1970/5867, Loss: 0.2844\n",
      "Epoch 1, Batch 1980/5867, Loss: 0.3311\n",
      "Epoch 1, Batch 1990/5867, Loss: 0.2635\n",
      "Epoch 1, Batch 2000/5867, Loss: 0.2887\n",
      "Epoch 1, Batch 2010/5867, Loss: 0.4151\n",
      "Epoch 1, Batch 2020/5867, Loss: 0.3277\n",
      "Epoch 1, Batch 2030/5867, Loss: 0.3066\n",
      "Epoch 1, Batch 2040/5867, Loss: 0.3898\n",
      "Epoch 1, Batch 2050/5867, Loss: 0.2611\n",
      "Epoch 1, Batch 2060/5867, Loss: 0.3169\n",
      "Epoch 1, Batch 2070/5867, Loss: 0.2322\n",
      "Epoch 1, Batch 2080/5867, Loss: 0.3524\n",
      "Epoch 1, Batch 2090/5867, Loss: 0.1333\n",
      "Epoch 1, Batch 2100/5867, Loss: 0.3797\n",
      "Epoch 1, Batch 2110/5867, Loss: 0.2146\n",
      "Epoch 1, Batch 2120/5867, Loss: 0.2164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 2130/5867, Loss: 0.2348\n",
      "Epoch 1, Batch 2140/5867, Loss: 0.2706\n",
      "Epoch 1, Batch 2150/5867, Loss: 0.4409\n",
      "Epoch 1, Batch 2160/5867, Loss: 0.2852\n",
      "Epoch 1, Batch 2170/5867, Loss: 0.2376\n",
      "Epoch 1, Batch 2180/5867, Loss: 0.2983\n",
      "Epoch 1, Batch 2190/5867, Loss: 0.1850\n",
      "Epoch 1, Batch 2200/5867, Loss: 0.1804\n",
      "Epoch 1, Batch 2210/5867, Loss: 0.2808\n",
      "Epoch 1, Batch 2220/5867, Loss: 0.2408\n",
      "Epoch 1, Batch 2230/5867, Loss: 0.1908\n",
      "Epoch 1, Batch 2240/5867, Loss: 0.1659\n",
      "Epoch 1, Batch 2250/5867, Loss: 0.2375\n",
      "Epoch 1, Batch 2260/5867, Loss: 0.3021\n",
      "Epoch 1, Batch 2270/5867, Loss: 0.1369\n",
      "Epoch 1, Batch 2280/5867, Loss: 0.3562\n",
      "Epoch 1, Batch 2290/5867, Loss: 0.1469\n",
      "Epoch 1, Batch 2300/5867, Loss: 0.2182\n",
      "Epoch 1, Batch 2310/5867, Loss: 0.3015\n",
      "Epoch 1, Batch 2320/5867, Loss: 0.2482\n",
      "Epoch 1, Batch 2330/5867, Loss: 0.2021\n",
      "Epoch 1, Batch 2340/5867, Loss: 0.1811\n",
      "Epoch 1, Batch 2350/5867, Loss: 0.3048\n",
      "Epoch 1, Batch 2360/5867, Loss: 0.1631\n",
      "Epoch 1, Batch 2370/5867, Loss: 0.1163\n",
      "Epoch 1, Batch 2380/5867, Loss: 0.2429\n",
      "Epoch 1, Batch 2390/5867, Loss: 0.1589\n",
      "Epoch 1, Batch 2400/5867, Loss: 0.2169\n",
      "Epoch 1, Batch 2410/5867, Loss: 0.2886\n",
      "Epoch 1, Batch 2420/5867, Loss: 0.2133\n",
      "Epoch 1, Batch 2430/5867, Loss: 0.2342\n",
      "Epoch 1, Batch 2440/5867, Loss: 0.2745\n",
      "Epoch 1, Batch 2450/5867, Loss: 0.2852\n",
      "Epoch 1, Batch 2460/5867, Loss: 0.5335\n",
      "Epoch 1, Batch 2470/5867, Loss: 0.2377\n",
      "Epoch 1, Batch 2480/5867, Loss: 0.3166\n",
      "Epoch 1, Batch 2490/5867, Loss: 0.2839\n",
      "Epoch 1, Batch 2500/5867, Loss: 0.2356\n",
      "Epoch 1, Batch 2510/5867, Loss: 0.2527\n",
      "Epoch 1, Batch 2520/5867, Loss: 0.1317\n",
      "Epoch 1, Batch 2530/5867, Loss: 0.1097\n",
      "Epoch 1, Batch 2540/5867, Loss: 0.2727\n",
      "Epoch 1, Batch 2550/5867, Loss: 0.1690\n",
      "Epoch 1, Batch 2560/5867, Loss: 0.2000\n",
      "Epoch 1, Batch 2570/5867, Loss: 0.1674\n",
      "Epoch 1, Batch 2580/5867, Loss: 0.4007\n",
      "Epoch 1, Batch 2590/5867, Loss: 0.1318\n",
      "Epoch 1, Batch 2600/5867, Loss: 0.2616\n",
      "Epoch 1, Batch 2610/5867, Loss: 0.1869\n",
      "Epoch 1, Batch 2620/5867, Loss: 0.0961\n",
      "Epoch 1, Batch 2630/5867, Loss: 0.3983\n",
      "Epoch 1, Batch 2640/5867, Loss: 0.1525\n",
      "Epoch 1, Batch 2650/5867, Loss: 0.1407\n",
      "Epoch 1, Batch 2660/5867, Loss: 0.2118\n",
      "Epoch 1, Batch 2670/5867, Loss: 0.2697\n",
      "Epoch 1, Batch 2680/5867, Loss: 0.1937\n",
      "Epoch 1, Batch 2690/5867, Loss: 0.3534\n",
      "Epoch 1, Batch 2700/5867, Loss: 0.2560\n",
      "Epoch 1, Batch 2710/5867, Loss: 0.5059\n",
      "Epoch 1, Batch 2720/5867, Loss: 0.3243\n",
      "Epoch 1, Batch 2730/5867, Loss: 0.2243\n",
      "Epoch 1, Batch 2740/5867, Loss: 0.2336\n",
      "Epoch 1, Batch 2750/5867, Loss: 0.3057\n",
      "Epoch 1, Batch 2760/5867, Loss: 0.3397\n",
      "Epoch 1, Batch 2770/5867, Loss: 0.3029\n",
      "Epoch 1, Batch 2780/5867, Loss: 0.0702\n",
      "Epoch 1, Batch 2790/5867, Loss: 0.2746\n",
      "Epoch 1, Batch 2800/5867, Loss: 0.2342\n",
      "Epoch 1, Batch 2810/5867, Loss: 0.3607\n",
      "Epoch 1, Batch 2820/5867, Loss: 0.2616\n",
      "Epoch 1, Batch 2830/5867, Loss: 0.1981\n",
      "Epoch 1, Batch 2840/5867, Loss: 0.2419\n",
      "Epoch 1, Batch 2850/5867, Loss: 0.2616\n",
      "Epoch 1, Batch 2860/5867, Loss: 0.3437\n",
      "Epoch 1, Batch 2870/5867, Loss: 0.1756\n",
      "Epoch 1, Batch 2880/5867, Loss: 0.3743\n",
      "Epoch 1, Batch 2890/5867, Loss: 0.4749\n",
      "Epoch 1, Batch 2900/5867, Loss: 0.3128\n",
      "Epoch 1, Batch 2910/5867, Loss: 0.3470\n",
      "Epoch 1, Batch 2920/5867, Loss: 0.2165\n",
      "Epoch 1, Batch 2930/5867, Loss: 0.2434\n",
      "Epoch 1, Batch 2940/5867, Loss: 0.1543\n",
      "Epoch 1, Batch 2950/5867, Loss: 0.1247\n",
      "Epoch 1, Batch 2960/5867, Loss: 0.2104\n",
      "Epoch 1, Batch 2970/5867, Loss: 0.1723\n",
      "Epoch 1, Batch 2980/5867, Loss: 0.2689\n",
      "Epoch 1, Batch 2990/5867, Loss: 0.2169\n",
      "Epoch 1, Batch 3000/5867, Loss: 0.2747\n",
      "Epoch 1, Batch 3010/5867, Loss: 0.2643\n",
      "Epoch 1, Batch 3020/5867, Loss: 0.3217\n",
      "Epoch 1, Batch 3030/5867, Loss: 0.1256\n",
      "Epoch 1, Batch 3040/5867, Loss: 0.4293\n",
      "Epoch 1, Batch 3050/5867, Loss: 0.4577\n",
      "Epoch 1, Batch 3060/5867, Loss: 0.3167\n",
      "Epoch 1, Batch 3070/5867, Loss: 0.2777\n",
      "Epoch 1, Batch 3080/5867, Loss: 0.2513\n",
      "Epoch 1, Batch 3090/5867, Loss: 0.2291\n",
      "Epoch 1, Batch 3100/5867, Loss: 0.2008\n",
      "Epoch 1, Batch 3110/5867, Loss: 0.3327\n",
      "Epoch 1, Batch 3120/5867, Loss: 0.3503\n",
      "Epoch 1, Batch 3130/5867, Loss: 0.3696\n",
      "Epoch 1, Batch 3140/5867, Loss: 0.3466\n",
      "Epoch 1, Batch 3150/5867, Loss: 0.4390\n",
      "Epoch 1, Batch 3160/5867, Loss: 0.2499\n",
      "Epoch 1, Batch 3170/5867, Loss: 0.2926\n",
      "Epoch 1, Batch 3180/5867, Loss: 0.1701\n",
      "Epoch 1, Batch 3190/5867, Loss: 0.3812\n",
      "Epoch 1, Batch 3200/5867, Loss: 0.1957\n",
      "Epoch 1, Batch 3210/5867, Loss: 0.2059\n",
      "Epoch 1, Batch 3220/5867, Loss: 0.2557\n",
      "Epoch 1, Batch 3230/5867, Loss: 0.1945\n",
      "Epoch 1, Batch 3240/5867, Loss: 0.1860\n",
      "Epoch 1, Batch 3250/5867, Loss: 0.2912\n",
      "Epoch 1, Batch 3260/5867, Loss: 0.2056\n",
      "Epoch 1, Batch 3270/5867, Loss: 0.1646\n",
      "Epoch 1, Batch 3280/5867, Loss: 0.2159\n",
      "Epoch 1, Batch 3290/5867, Loss: 0.3213\n",
      "Epoch 1, Batch 3300/5867, Loss: 0.2361\n",
      "Epoch 1, Batch 3310/5867, Loss: 0.3409\n",
      "Epoch 1, Batch 3320/5867, Loss: 0.4104\n",
      "Epoch 1, Batch 3330/5867, Loss: 0.4772\n",
      "Epoch 1, Batch 3340/5867, Loss: 0.4876\n",
      "Epoch 1, Batch 3350/5867, Loss: 0.2729\n",
      "Epoch 1, Batch 3360/5867, Loss: 0.2173\n",
      "Epoch 1, Batch 3370/5867, Loss: 0.4222\n",
      "Epoch 1, Batch 3380/5867, Loss: 0.2287\n",
      "Epoch 1, Batch 3390/5867, Loss: 0.3747\n",
      "Epoch 1, Batch 3400/5867, Loss: 0.2723\n",
      "Epoch 1, Batch 3410/5867, Loss: 0.1788\n",
      "Epoch 1, Batch 3420/5867, Loss: 0.2841\n",
      "Epoch 1, Batch 3430/5867, Loss: 0.3446\n",
      "Epoch 1, Batch 3440/5867, Loss: 0.2632\n",
      "Epoch 1, Batch 3450/5867, Loss: 0.1094\n",
      "Epoch 1, Batch 3460/5867, Loss: 0.2696\n",
      "Epoch 1, Batch 3470/5867, Loss: 0.2310\n",
      "Epoch 1, Batch 3480/5867, Loss: 0.2659\n",
      "Epoch 1, Batch 3490/5867, Loss: 0.5066\n",
      "Epoch 1, Batch 3500/5867, Loss: 0.2691\n",
      "Epoch 1, Batch 3510/5867, Loss: 0.3200\n",
      "Epoch 1, Batch 3520/5867, Loss: 0.2528\n",
      "Epoch 1, Batch 3530/5867, Loss: 0.3078\n",
      "Epoch 1, Batch 3540/5867, Loss: 0.3166\n",
      "Epoch 1, Batch 3550/5867, Loss: 0.2187\n",
      "Epoch 1, Batch 3560/5867, Loss: 0.3256\n",
      "Epoch 1, Batch 3570/5867, Loss: 0.0865\n",
      "Epoch 1, Batch 3580/5867, Loss: 0.1970\n",
      "Epoch 1, Batch 3590/5867, Loss: 0.2717\n",
      "Epoch 1, Batch 3600/5867, Loss: 0.2176\n",
      "Epoch 1, Batch 3610/5867, Loss: 0.1407\n",
      "Epoch 1, Batch 3620/5867, Loss: 0.2333\n",
      "Epoch 1, Batch 3630/5867, Loss: 0.3627\n",
      "Epoch 1, Batch 3640/5867, Loss: 0.2496\n",
      "Epoch 1, Batch 3650/5867, Loss: 0.2174\n",
      "Epoch 1, Batch 3660/5867, Loss: 0.3401\n",
      "Epoch 1, Batch 3670/5867, Loss: 0.2748\n",
      "Epoch 1, Batch 3680/5867, Loss: 0.3533\n",
      "Epoch 1, Batch 3690/5867, Loss: 0.2464\n",
      "Epoch 1, Batch 3700/5867, Loss: 0.2585\n",
      "Epoch 1, Batch 3710/5867, Loss: 0.2318\n",
      "Epoch 1, Batch 3720/5867, Loss: 0.3773\n",
      "Epoch 1, Batch 3730/5867, Loss: 0.1390\n",
      "Epoch 1, Batch 3740/5867, Loss: 0.2279\n",
      "Epoch 1, Batch 3750/5867, Loss: 0.2378\n",
      "Epoch 1, Batch 3760/5867, Loss: 0.1940\n",
      "Epoch 1, Batch 3770/5867, Loss: 0.1091\n",
      "Epoch 1, Batch 3780/5867, Loss: 0.1700\n",
      "Epoch 1, Batch 3790/5867, Loss: 0.3674\n",
      "Epoch 1, Batch 3800/5867, Loss: 0.3499\n",
      "Epoch 1, Batch 3810/5867, Loss: 0.2025\n",
      "Epoch 1, Batch 3820/5867, Loss: 0.3382\n",
      "Epoch 1, Batch 3830/5867, Loss: 0.3444\n",
      "Epoch 1, Batch 3840/5867, Loss: 0.4828\n",
      "Epoch 1, Batch 3850/5867, Loss: 0.2619\n",
      "Epoch 1, Batch 3860/5867, Loss: 0.2490\n",
      "Epoch 1, Batch 3870/5867, Loss: 0.3168\n",
      "Epoch 1, Batch 3880/5867, Loss: 0.3321\n",
      "Epoch 1, Batch 3890/5867, Loss: 0.1975\n",
      "Epoch 1, Batch 3900/5867, Loss: 0.2815\n",
      "Epoch 1, Batch 3910/5867, Loss: 0.1133\n",
      "Epoch 1, Batch 3920/5867, Loss: 0.1913\n",
      "Epoch 1, Batch 3930/5867, Loss: 0.1786\n",
      "Epoch 1, Batch 3940/5867, Loss: 0.1679\n",
      "Epoch 1, Batch 3950/5867, Loss: 0.3984\n",
      "Epoch 1, Batch 3960/5867, Loss: 0.1997\n",
      "Epoch 1, Batch 3970/5867, Loss: 0.3495\n",
      "Epoch 1, Batch 3980/5867, Loss: 0.2896\n",
      "Epoch 1, Batch 3990/5867, Loss: 0.3265\n",
      "Epoch 1, Batch 4000/5867, Loss: 0.4127\n",
      "Epoch 1, Batch 4010/5867, Loss: 0.1968\n",
      "Epoch 1, Batch 4020/5867, Loss: 0.1925\n",
      "Epoch 1, Batch 4030/5867, Loss: 0.2842\n",
      "Epoch 1, Batch 4040/5867, Loss: 0.1960\n",
      "Epoch 1, Batch 4050/5867, Loss: 0.2189\n",
      "Epoch 1, Batch 4060/5867, Loss: 0.2084\n",
      "Epoch 1, Batch 4070/5867, Loss: 0.2076\n",
      "Epoch 1, Batch 4080/5867, Loss: 0.2365\n",
      "Epoch 1, Batch 4090/5867, Loss: 0.1513\n",
      "Epoch 1, Batch 4100/5867, Loss: 0.2486\n",
      "Epoch 1, Batch 4110/5867, Loss: 0.1790\n",
      "Epoch 1, Batch 4120/5867, Loss: 0.3433\n",
      "Epoch 1, Batch 4130/5867, Loss: 0.3010\n",
      "Epoch 1, Batch 4140/5867, Loss: 0.3502\n",
      "Epoch 1, Batch 4150/5867, Loss: 0.2908\n",
      "Epoch 1, Batch 4160/5867, Loss: 0.2185\n",
      "Epoch 1, Batch 4170/5867, Loss: 0.2283\n",
      "Epoch 1, Batch 4180/5867, Loss: 0.3370\n",
      "Epoch 1, Batch 4190/5867, Loss: 0.3202\n",
      "Epoch 1, Batch 4200/5867, Loss: 0.2900\n",
      "Epoch 1, Batch 4210/5867, Loss: 0.1986\n",
      "Epoch 1, Batch 4220/5867, Loss: 0.1948\n",
      "Epoch 1, Batch 4230/5867, Loss: 0.2462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 4240/5867, Loss: 0.1840\n",
      "Epoch 1, Batch 4250/5867, Loss: 0.3392\n",
      "Epoch 1, Batch 4260/5867, Loss: 0.1652\n",
      "Epoch 1, Batch 4270/5867, Loss: 0.2134\n",
      "Epoch 1, Batch 4280/5867, Loss: 0.2042\n",
      "Epoch 1, Batch 4290/5867, Loss: 0.0848\n",
      "Epoch 1, Batch 4300/5867, Loss: 0.1953\n",
      "Epoch 1, Batch 4310/5867, Loss: 0.1299\n",
      "Epoch 1, Batch 4320/5867, Loss: 0.2072\n",
      "Epoch 1, Batch 4330/5867, Loss: 0.2669\n",
      "Epoch 1, Batch 4340/5867, Loss: 0.2342\n",
      "Epoch 1, Batch 4350/5867, Loss: 0.3150\n",
      "Epoch 1, Batch 4360/5867, Loss: 0.3111\n",
      "Epoch 1, Batch 4370/5867, Loss: 0.1738\n",
      "Epoch 1, Batch 4380/5867, Loss: 0.1858\n",
      "Epoch 1, Batch 4390/5867, Loss: 0.3204\n",
      "Epoch 1, Batch 4400/5867, Loss: 0.4419\n",
      "Epoch 1, Batch 4410/5867, Loss: 0.2229\n",
      "Epoch 1, Batch 4420/5867, Loss: 0.2845\n",
      "Epoch 1, Batch 4430/5867, Loss: 0.2764\n",
      "Epoch 1, Batch 4440/5867, Loss: 0.5539\n",
      "Epoch 1, Batch 4450/5867, Loss: 0.4835\n",
      "Epoch 1, Batch 4460/5867, Loss: 0.3132\n",
      "Epoch 1, Batch 4470/5867, Loss: 0.2858\n",
      "Epoch 1, Batch 4480/5867, Loss: 0.2647\n",
      "Epoch 1, Batch 4490/5867, Loss: 0.2448\n",
      "Epoch 1, Batch 4500/5867, Loss: 0.2082\n",
      "Epoch 1, Batch 4510/5867, Loss: 0.2847\n",
      "Epoch 1, Batch 4520/5867, Loss: 0.3960\n",
      "Epoch 1, Batch 4530/5867, Loss: 0.3154\n",
      "Epoch 1, Batch 4540/5867, Loss: 0.3235\n",
      "Epoch 1, Batch 4550/5867, Loss: 0.3106\n",
      "Epoch 1, Batch 4560/5867, Loss: 0.3842\n",
      "Epoch 1, Batch 4570/5867, Loss: 0.1484\n",
      "Epoch 1, Batch 4580/5867, Loss: 0.4625\n",
      "Epoch 1, Batch 4590/5867, Loss: 0.3154\n",
      "Epoch 1, Batch 4600/5867, Loss: 0.2405\n",
      "Epoch 1, Batch 4610/5867, Loss: 0.1682\n",
      "Epoch 1, Batch 4620/5867, Loss: 0.2966\n",
      "Epoch 1, Batch 4630/5867, Loss: 0.2539\n",
      "Epoch 1, Batch 4640/5867, Loss: 0.1653\n",
      "Epoch 1, Batch 4650/5867, Loss: 0.3051\n",
      "Epoch 1, Batch 4660/5867, Loss: 0.4058\n",
      "Epoch 1, Batch 4670/5867, Loss: 0.3041\n",
      "Epoch 1, Batch 4680/5867, Loss: 0.2148\n",
      "Epoch 1, Batch 4690/5867, Loss: 0.5348\n",
      "Epoch 1, Batch 4700/5867, Loss: 0.1787\n",
      "Epoch 1, Batch 4710/5867, Loss: 0.2336\n",
      "Epoch 1, Batch 4720/5867, Loss: 0.2544\n",
      "Epoch 1, Batch 4730/5867, Loss: 0.3327\n",
      "Epoch 1, Batch 4740/5867, Loss: 0.3514\n",
      "Epoch 1, Batch 4750/5867, Loss: 0.3387\n",
      "Epoch 1, Batch 4760/5867, Loss: 0.3448\n",
      "Epoch 1, Batch 4770/5867, Loss: 0.1790\n",
      "Epoch 1, Batch 4780/5867, Loss: 0.4517\n",
      "Epoch 1, Batch 4790/5867, Loss: 0.2646\n",
      "Epoch 1, Batch 4800/5867, Loss: 0.2290\n",
      "Epoch 1, Batch 4810/5867, Loss: 0.1396\n",
      "Epoch 1, Batch 4820/5867, Loss: 0.3136\n",
      "Epoch 1, Batch 4830/5867, Loss: 0.1488\n",
      "Epoch 1, Batch 4840/5867, Loss: 0.2165\n",
      "Epoch 1, Batch 4850/5867, Loss: 0.2622\n",
      "Epoch 1, Batch 4860/5867, Loss: 0.2390\n",
      "Epoch 1, Batch 4870/5867, Loss: 0.2196\n",
      "Epoch 1, Batch 4880/5867, Loss: 0.3076\n",
      "Epoch 1, Batch 4890/5867, Loss: 0.3348\n",
      "Epoch 1, Batch 4900/5867, Loss: 0.2363\n",
      "Epoch 1, Batch 4910/5867, Loss: 0.1648\n",
      "Epoch 1, Batch 4920/5867, Loss: 0.4180\n",
      "Epoch 1, Batch 4930/5867, Loss: 0.2344\n",
      "Epoch 1, Batch 4940/5867, Loss: 0.2092\n",
      "Epoch 1, Batch 4950/5867, Loss: 0.1304\n",
      "Epoch 1, Batch 4960/5867, Loss: 0.4275\n",
      "Epoch 1, Batch 4970/5867, Loss: 0.2339\n",
      "Epoch 1, Batch 4980/5867, Loss: 0.2310\n",
      "Epoch 1, Batch 4990/5867, Loss: 0.1802\n",
      "Epoch 1, Batch 5000/5867, Loss: 0.2783\n",
      "Epoch 1, Batch 5010/5867, Loss: 0.1346\n",
      "Epoch 1, Batch 5020/5867, Loss: 0.2872\n",
      "Epoch 1, Batch 5030/5867, Loss: 0.1870\n",
      "Epoch 1, Batch 5040/5867, Loss: 0.2103\n",
      "Epoch 1, Batch 5050/5867, Loss: 0.2299\n",
      "Epoch 1, Batch 5060/5867, Loss: 0.1873\n",
      "Epoch 1, Batch 5070/5867, Loss: 0.1564\n",
      "Epoch 1, Batch 5080/5867, Loss: 0.2127\n",
      "Epoch 1, Batch 5090/5867, Loss: 0.2400\n",
      "Epoch 1, Batch 5100/5867, Loss: 0.2273\n",
      "Epoch 1, Batch 5110/5867, Loss: 0.1626\n",
      "Epoch 1, Batch 5120/5867, Loss: 0.3725\n",
      "Epoch 1, Batch 5130/5867, Loss: 0.2276\n",
      "Epoch 1, Batch 5140/5867, Loss: 0.1182\n",
      "Epoch 1, Batch 5150/5867, Loss: 0.2540\n",
      "Epoch 1, Batch 5160/5867, Loss: 0.1278\n",
      "Epoch 1, Batch 5170/5867, Loss: 0.2515\n",
      "Epoch 1, Batch 5180/5867, Loss: 0.1664\n",
      "Epoch 1, Batch 5190/5867, Loss: 0.2306\n",
      "Epoch 1, Batch 5200/5867, Loss: 0.1227\n",
      "Epoch 1, Batch 5210/5867, Loss: 0.2444\n",
      "Epoch 1, Batch 5220/5867, Loss: 0.3070\n",
      "Epoch 1, Batch 5230/5867, Loss: 0.2881\n",
      "Epoch 1, Batch 5240/5867, Loss: 0.2853\n",
      "Epoch 1, Batch 5250/5867, Loss: 0.1930\n",
      "Epoch 1, Batch 5260/5867, Loss: 0.2627\n",
      "Epoch 1, Batch 5270/5867, Loss: 0.2876\n",
      "Epoch 1, Batch 5280/5867, Loss: 0.2897\n",
      "Epoch 1, Batch 5290/5867, Loss: 0.2083\n",
      "Epoch 1, Batch 5300/5867, Loss: 0.3743\n",
      "Epoch 1, Batch 5310/5867, Loss: 0.1524\n",
      "Epoch 1, Batch 5320/5867, Loss: 0.3159\n",
      "Epoch 1, Batch 5330/5867, Loss: 0.1601\n",
      "Epoch 1, Batch 5340/5867, Loss: 0.3087\n",
      "Epoch 1, Batch 5350/5867, Loss: 0.1940\n",
      "Epoch 1, Batch 5360/5867, Loss: 0.2661\n",
      "Epoch 1, Batch 5370/5867, Loss: 0.3112\n",
      "Epoch 1, Batch 5380/5867, Loss: 0.4084\n",
      "Epoch 1, Batch 5390/5867, Loss: 0.2820\n",
      "Epoch 1, Batch 5400/5867, Loss: 0.4200\n",
      "Epoch 1, Batch 5410/5867, Loss: 0.1041\n",
      "Epoch 1, Batch 5420/5867, Loss: 0.3417\n",
      "Epoch 1, Batch 5430/5867, Loss: 0.1727\n",
      "Epoch 1, Batch 5440/5867, Loss: 0.1943\n",
      "Epoch 1, Batch 5450/5867, Loss: 0.4301\n",
      "Epoch 1, Batch 5460/5867, Loss: 0.2390\n",
      "Epoch 1, Batch 5470/5867, Loss: 0.1294\n",
      "Epoch 1, Batch 5480/5867, Loss: 0.4376\n",
      "Epoch 1, Batch 5490/5867, Loss: 0.4056\n",
      "Epoch 1, Batch 5500/5867, Loss: 0.1357\n",
      "Epoch 1, Batch 5510/5867, Loss: 0.2306\n",
      "Epoch 1, Batch 5520/5867, Loss: 0.2717\n",
      "Epoch 1, Batch 5530/5867, Loss: 0.3767\n",
      "Epoch 1, Batch 5540/5867, Loss: 0.2505\n",
      "Epoch 1, Batch 5550/5867, Loss: 0.1827\n",
      "Epoch 1, Batch 5560/5867, Loss: 0.2991\n",
      "Epoch 1, Batch 5570/5867, Loss: 0.3221\n",
      "Epoch 1, Batch 5580/5867, Loss: 0.1820\n",
      "Epoch 1, Batch 5590/5867, Loss: 0.3408\n",
      "Epoch 1, Batch 5600/5867, Loss: 0.1747\n",
      "Epoch 1, Batch 5610/5867, Loss: 0.1933\n",
      "Epoch 1, Batch 5620/5867, Loss: 0.3949\n",
      "Epoch 1, Batch 5630/5867, Loss: 0.3749\n",
      "Epoch 1, Batch 5640/5867, Loss: 0.2693\n",
      "Epoch 1, Batch 5650/5867, Loss: 0.3235\n",
      "Epoch 1, Batch 5660/5867, Loss: 0.2912\n",
      "Epoch 1, Batch 5670/5867, Loss: 0.2343\n",
      "Epoch 1, Batch 5680/5867, Loss: 0.2437\n",
      "Epoch 1, Batch 5690/5867, Loss: 0.1957\n",
      "Epoch 1, Batch 5700/5867, Loss: 0.2043\n",
      "Epoch 1, Batch 5710/5867, Loss: 0.2686\n",
      "Epoch 1, Batch 5720/5867, Loss: 0.2039\n",
      "Epoch 1, Batch 5730/5867, Loss: 0.4340\n",
      "Epoch 1, Batch 5740/5867, Loss: 0.2346\n",
      "Epoch 1, Batch 5750/5867, Loss: 0.2471\n",
      "Epoch 1, Batch 5760/5867, Loss: 0.2854\n",
      "Epoch 1, Batch 5770/5867, Loss: 0.3451\n",
      "Epoch 1, Batch 5780/5867, Loss: 0.1725\n",
      "Epoch 1, Batch 5790/5867, Loss: 0.3566\n",
      "Epoch 1, Batch 5800/5867, Loss: 0.3332\n",
      "Epoch 1, Batch 5810/5867, Loss: 0.2607\n",
      "Epoch 1, Batch 5820/5867, Loss: 0.0825\n",
      "Epoch 1, Batch 5830/5867, Loss: 0.1101\n",
      "Epoch 1, Batch 5840/5867, Loss: 0.2215\n",
      "Epoch 1, Batch 5850/5867, Loss: 0.1513\n",
      "Epoch 1, Batch 5860/5867, Loss: 0.0810\n",
      "Epoch 1, Training Loss: 0.2779, Validation Loss: 0.2289\n",
      "Starting epoch 2...\n",
      "Epoch 2, Batch 10/5867, Loss: 0.4254\n",
      "Epoch 2, Batch 20/5867, Loss: 0.2006\n",
      "Epoch 2, Batch 30/5867, Loss: 0.4708\n",
      "Epoch 2, Batch 40/5867, Loss: 0.2420\n",
      "Epoch 2, Batch 50/5867, Loss: 0.1927\n",
      "Epoch 2, Batch 60/5867, Loss: 0.2935\n",
      "Epoch 2, Batch 70/5867, Loss: 0.1807\n",
      "Epoch 2, Batch 80/5867, Loss: 0.1116\n",
      "Epoch 2, Batch 90/5867, Loss: 0.2072\n",
      "Epoch 2, Batch 100/5867, Loss: 0.1788\n",
      "Epoch 2, Batch 110/5867, Loss: 0.0785\n",
      "Epoch 2, Batch 120/5867, Loss: 0.0745\n",
      "Epoch 2, Batch 130/5867, Loss: 0.1781\n",
      "Epoch 2, Batch 140/5867, Loss: 0.2694\n",
      "Epoch 2, Batch 150/5867, Loss: 0.1570\n",
      "Epoch 2, Batch 160/5867, Loss: 0.2382\n",
      "Epoch 2, Batch 170/5867, Loss: 0.2479\n",
      "Epoch 2, Batch 180/5867, Loss: 0.1502\n",
      "Epoch 2, Batch 190/5867, Loss: 0.3987\n",
      "Epoch 2, Batch 200/5867, Loss: 0.2092\n",
      "Epoch 2, Batch 210/5867, Loss: 0.3545\n",
      "Epoch 2, Batch 220/5867, Loss: 0.2230\n",
      "Epoch 2, Batch 230/5867, Loss: 0.1449\n",
      "Epoch 2, Batch 240/5867, Loss: 0.2370\n",
      "Epoch 2, Batch 250/5867, Loss: 0.0987\n",
      "Epoch 2, Batch 260/5867, Loss: 0.3648\n",
      "Epoch 2, Batch 270/5867, Loss: 0.1632\n",
      "Epoch 2, Batch 280/5867, Loss: 0.3510\n",
      "Epoch 2, Batch 290/5867, Loss: 0.2483\n",
      "Epoch 2, Batch 300/5867, Loss: 0.3385\n",
      "Epoch 2, Batch 310/5867, Loss: 0.1442\n",
      "Epoch 2, Batch 320/5867, Loss: 0.1128\n",
      "Epoch 2, Batch 330/5867, Loss: 0.1831\n",
      "Epoch 2, Batch 340/5867, Loss: 0.0895\n",
      "Epoch 2, Batch 350/5867, Loss: 0.2378\n",
      "Epoch 2, Batch 360/5867, Loss: 0.2758\n",
      "Epoch 2, Batch 370/5867, Loss: 0.3880\n",
      "Epoch 2, Batch 380/5867, Loss: 0.2624\n",
      "Epoch 2, Batch 390/5867, Loss: 0.1749\n",
      "Epoch 2, Batch 400/5867, Loss: 0.3873\n",
      "Epoch 2, Batch 410/5867, Loss: 0.4063\n",
      "Epoch 2, Batch 420/5867, Loss: 0.2164\n",
      "Epoch 2, Batch 430/5867, Loss: 0.3930\n",
      "Epoch 2, Batch 440/5867, Loss: 0.2841\n",
      "Epoch 2, Batch 450/5867, Loss: 0.3790\n",
      "Epoch 2, Batch 460/5867, Loss: 0.3225\n",
      "Epoch 2, Batch 470/5867, Loss: 0.2824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 480/5867, Loss: 0.1697\n",
      "Epoch 2, Batch 490/5867, Loss: 0.2966\n",
      "Epoch 2, Batch 500/5867, Loss: 0.1140\n",
      "Epoch 2, Batch 510/5867, Loss: 0.1766\n",
      "Epoch 2, Batch 520/5867, Loss: 0.3326\n",
      "Epoch 2, Batch 530/5867, Loss: 0.1674\n",
      "Epoch 2, Batch 540/5867, Loss: 0.2198\n",
      "Epoch 2, Batch 550/5867, Loss: 0.3604\n",
      "Epoch 2, Batch 560/5867, Loss: 0.3063\n",
      "Epoch 2, Batch 570/5867, Loss: 0.1315\n",
      "Epoch 2, Batch 580/5867, Loss: 0.2140\n",
      "Epoch 2, Batch 590/5867, Loss: 0.1172\n",
      "Epoch 2, Batch 600/5867, Loss: 0.2540\n",
      "Epoch 2, Batch 610/5867, Loss: 0.3157\n",
      "Epoch 2, Batch 620/5867, Loss: 0.2690\n",
      "Epoch 2, Batch 630/5867, Loss: 0.1414\n",
      "Epoch 2, Batch 640/5867, Loss: 0.2739\n",
      "Epoch 2, Batch 650/5867, Loss: 0.1503\n",
      "Epoch 2, Batch 660/5867, Loss: 0.1479\n",
      "Epoch 2, Batch 670/5867, Loss: 0.4280\n",
      "Epoch 2, Batch 680/5867, Loss: 0.1011\n",
      "Epoch 2, Batch 690/5867, Loss: 0.1229\n",
      "Epoch 2, Batch 700/5867, Loss: 0.2284\n",
      "Epoch 2, Batch 710/5867, Loss: 0.1681\n",
      "Epoch 2, Batch 720/5867, Loss: 0.2845\n",
      "Epoch 2, Batch 730/5867, Loss: 0.3695\n",
      "Epoch 2, Batch 740/5867, Loss: 0.3095\n",
      "Epoch 2, Batch 750/5867, Loss: 0.2355\n",
      "Epoch 2, Batch 760/5867, Loss: 0.2887\n",
      "Epoch 2, Batch 770/5867, Loss: 0.1831\n",
      "Epoch 2, Batch 780/5867, Loss: 0.2653\n",
      "Epoch 2, Batch 790/5867, Loss: 0.1493\n",
      "Epoch 2, Batch 800/5867, Loss: 0.3401\n",
      "Epoch 2, Batch 810/5867, Loss: 0.4203\n",
      "Epoch 2, Batch 820/5867, Loss: 0.2847\n",
      "Epoch 2, Batch 830/5867, Loss: 0.1246\n",
      "Epoch 2, Batch 840/5867, Loss: 0.1510\n",
      "Epoch 2, Batch 850/5867, Loss: 0.2393\n",
      "Epoch 2, Batch 860/5867, Loss: 0.3192\n",
      "Epoch 2, Batch 870/5867, Loss: 0.2518\n",
      "Epoch 2, Batch 880/5867, Loss: 0.1728\n",
      "Epoch 2, Batch 890/5867, Loss: 0.2394\n",
      "Epoch 2, Batch 900/5867, Loss: 0.3852\n",
      "Epoch 2, Batch 910/5867, Loss: 0.1887\n",
      "Epoch 2, Batch 920/5867, Loss: 0.2084\n",
      "Epoch 2, Batch 930/5867, Loss: 0.3979\n",
      "Epoch 2, Batch 940/5867, Loss: 0.2023\n",
      "Epoch 2, Batch 950/5867, Loss: 0.1967\n",
      "Epoch 2, Batch 960/5867, Loss: 0.3371\n",
      "Epoch 2, Batch 970/5867, Loss: 0.1202\n",
      "Epoch 2, Batch 980/5867, Loss: 0.3617\n",
      "Epoch 2, Batch 990/5867, Loss: 0.2089\n",
      "Epoch 2, Batch 1000/5867, Loss: 0.0870\n",
      "Epoch 2, Batch 1010/5867, Loss: 0.1652\n",
      "Epoch 2, Batch 1020/5867, Loss: 0.1949\n",
      "Epoch 2, Batch 1030/5867, Loss: 0.1116\n",
      "Epoch 2, Batch 1040/5867, Loss: 0.0958\n",
      "Epoch 2, Batch 1050/5867, Loss: 0.3006\n",
      "Epoch 2, Batch 1060/5867, Loss: 0.1764\n",
      "Epoch 2, Batch 1070/5867, Loss: 0.6205\n",
      "Epoch 2, Batch 1080/5867, Loss: 0.1512\n",
      "Epoch 2, Batch 1090/5867, Loss: 0.2045\n",
      "Epoch 2, Batch 1100/5867, Loss: 0.2795\n",
      "Epoch 2, Batch 1110/5867, Loss: 0.2883\n",
      "Epoch 2, Batch 1120/5867, Loss: 0.2580\n",
      "Epoch 2, Batch 1130/5867, Loss: 0.2097\n",
      "Epoch 2, Batch 1140/5867, Loss: 0.2707\n",
      "Epoch 2, Batch 1150/5867, Loss: 0.1576\n",
      "Epoch 2, Batch 1160/5867, Loss: 0.1495\n",
      "Epoch 2, Batch 1170/5867, Loss: 0.1875\n",
      "Epoch 2, Batch 1180/5867, Loss: 0.1679\n",
      "Epoch 2, Batch 1190/5867, Loss: 0.2689\n",
      "Epoch 2, Batch 1200/5867, Loss: 0.2545\n",
      "Epoch 2, Batch 1210/5867, Loss: 0.1876\n",
      "Epoch 2, Batch 1220/5867, Loss: 0.3030\n",
      "Epoch 2, Batch 1230/5867, Loss: 0.2972\n",
      "Epoch 2, Batch 1240/5867, Loss: 0.2689\n",
      "Epoch 2, Batch 1250/5867, Loss: 0.2225\n",
      "Epoch 2, Batch 1260/5867, Loss: 0.2871\n",
      "Epoch 2, Batch 1270/5867, Loss: 0.2061\n",
      "Epoch 2, Batch 1280/5867, Loss: 0.1093\n",
      "Epoch 2, Batch 1290/5867, Loss: 0.1653\n",
      "Epoch 2, Batch 1300/5867, Loss: 0.2343\n",
      "Epoch 2, Batch 1310/5867, Loss: 0.0872\n",
      "Epoch 2, Batch 1320/5867, Loss: 0.1593\n",
      "Epoch 2, Batch 1330/5867, Loss: 0.1894\n",
      "Epoch 2, Batch 1340/5867, Loss: 0.2520\n",
      "Epoch 2, Batch 1350/5867, Loss: 0.2641\n",
      "Epoch 2, Batch 1360/5867, Loss: 0.3750\n",
      "Epoch 2, Batch 1370/5867, Loss: 0.2597\n",
      "Epoch 2, Batch 1380/5867, Loss: 0.2741\n",
      "Epoch 2, Batch 1390/5867, Loss: 0.2375\n",
      "Epoch 2, Batch 1400/5867, Loss: 0.2740\n",
      "Epoch 2, Batch 1410/5867, Loss: 0.1018\n",
      "Epoch 2, Batch 1420/5867, Loss: 0.0784\n",
      "Epoch 2, Batch 1430/5867, Loss: 0.1788\n",
      "Epoch 2, Batch 1440/5867, Loss: 0.1780\n",
      "Epoch 2, Batch 1450/5867, Loss: 0.2939\n",
      "Epoch 2, Batch 1460/5867, Loss: 0.2168\n",
      "Epoch 2, Batch 1470/5867, Loss: 0.2578\n",
      "Epoch 2, Batch 1480/5867, Loss: 0.3297\n",
      "Epoch 2, Batch 1490/5867, Loss: 0.1390\n",
      "Epoch 2, Batch 1500/5867, Loss: 0.3469\n",
      "Epoch 2, Batch 1510/5867, Loss: 0.2804\n",
      "Epoch 2, Batch 1520/5867, Loss: 0.2430\n",
      "Epoch 2, Batch 1530/5867, Loss: 0.2501\n",
      "Epoch 2, Batch 1540/5867, Loss: 0.1595\n",
      "Epoch 2, Batch 1550/5867, Loss: 0.2783\n",
      "Epoch 2, Batch 1560/5867, Loss: 0.3053\n",
      "Epoch 2, Batch 1570/5867, Loss: 0.4871\n",
      "Epoch 2, Batch 1580/5867, Loss: 0.2086\n",
      "Epoch 2, Batch 1590/5867, Loss: 0.0547\n",
      "Epoch 2, Batch 1600/5867, Loss: 0.3393\n",
      "Epoch 2, Batch 1610/5867, Loss: 0.2328\n",
      "Epoch 2, Batch 1620/5867, Loss: 0.0766\n",
      "Epoch 2, Batch 1630/5867, Loss: 0.3437\n",
      "Epoch 2, Batch 1640/5867, Loss: 0.2576\n",
      "Epoch 2, Batch 1650/5867, Loss: 0.1557\n",
      "Epoch 2, Batch 1660/5867, Loss: 0.2172\n",
      "Epoch 2, Batch 1670/5867, Loss: 0.2135\n",
      "Epoch 2, Batch 1680/5867, Loss: 0.1323\n",
      "Epoch 2, Batch 1690/5867, Loss: 0.1800\n",
      "Epoch 2, Batch 1700/5867, Loss: 0.4828\n",
      "Epoch 2, Batch 1710/5867, Loss: 0.1180\n",
      "Epoch 2, Batch 1720/5867, Loss: 0.2541\n",
      "Epoch 2, Batch 1730/5867, Loss: 0.2721\n",
      "Epoch 2, Batch 1740/5867, Loss: 0.0630\n",
      "Epoch 2, Batch 1750/5867, Loss: 0.2141\n",
      "Epoch 2, Batch 1760/5867, Loss: 0.1089\n",
      "Epoch 2, Batch 1770/5867, Loss: 0.1260\n",
      "Epoch 2, Batch 1780/5867, Loss: 0.2034\n",
      "Epoch 2, Batch 1790/5867, Loss: 0.2018\n",
      "Epoch 2, Batch 1800/5867, Loss: 0.0686\n",
      "Epoch 2, Batch 1810/5867, Loss: 0.1975\n",
      "Epoch 2, Batch 1820/5867, Loss: 0.2856\n",
      "Epoch 2, Batch 1830/5867, Loss: 0.1715\n",
      "Epoch 2, Batch 1840/5867, Loss: 0.2074\n",
      "Epoch 2, Batch 1850/5867, Loss: 0.0978\n",
      "Epoch 2, Batch 1860/5867, Loss: 0.1398\n",
      "Epoch 2, Batch 1870/5867, Loss: 0.1920\n",
      "Epoch 2, Batch 1880/5867, Loss: 0.4557\n",
      "Epoch 2, Batch 1890/5867, Loss: 0.1193\n",
      "Epoch 2, Batch 1900/5867, Loss: 0.4388\n",
      "Epoch 2, Batch 1910/5867, Loss: 0.2684\n",
      "Epoch 2, Batch 1920/5867, Loss: 0.1153\n",
      "Epoch 2, Batch 1930/5867, Loss: 0.1431\n",
      "Epoch 2, Batch 1940/5867, Loss: 0.4199\n",
      "Epoch 2, Batch 1950/5867, Loss: 0.2066\n",
      "Epoch 2, Batch 1960/5867, Loss: 0.1808\n",
      "Epoch 2, Batch 1970/5867, Loss: 0.2351\n",
      "Epoch 2, Batch 1980/5867, Loss: 0.1014\n",
      "Epoch 2, Batch 1990/5867, Loss: 0.2317\n",
      "Epoch 2, Batch 2000/5867, Loss: 0.3017\n",
      "Epoch 2, Batch 2010/5867, Loss: 0.1644\n",
      "Epoch 2, Batch 2020/5867, Loss: 0.2341\n",
      "Epoch 2, Batch 2030/5867, Loss: 0.1206\n",
      "Epoch 2, Batch 2040/5867, Loss: 0.2901\n",
      "Epoch 2, Batch 2050/5867, Loss: 0.3057\n",
      "Epoch 2, Batch 2060/5867, Loss: 0.0698\n",
      "Epoch 2, Batch 2070/5867, Loss: 0.1826\n",
      "Epoch 2, Batch 2080/5867, Loss: 0.0721\n",
      "Epoch 2, Batch 2090/5867, Loss: 0.2492\n",
      "Epoch 2, Batch 2100/5867, Loss: 0.3500\n",
      "Epoch 2, Batch 2110/5867, Loss: 0.2070\n",
      "Epoch 2, Batch 2120/5867, Loss: 0.1855\n",
      "Epoch 2, Batch 2130/5867, Loss: 0.1844\n",
      "Epoch 2, Batch 2140/5867, Loss: 0.2779\n",
      "Epoch 2, Batch 2150/5867, Loss: 0.2238\n",
      "Epoch 2, Batch 2160/5867, Loss: 0.4793\n",
      "Epoch 2, Batch 2170/5867, Loss: 0.3203\n",
      "Epoch 2, Batch 2180/5867, Loss: 0.2043\n",
      "Epoch 2, Batch 2190/5867, Loss: 0.1795\n",
      "Epoch 2, Batch 2200/5867, Loss: 0.2361\n",
      "Epoch 2, Batch 2210/5867, Loss: 0.2123\n",
      "Epoch 2, Batch 2220/5867, Loss: 0.2936\n",
      "Epoch 2, Batch 2230/5867, Loss: 0.2659\n",
      "Epoch 2, Batch 2240/5867, Loss: 0.4276\n",
      "Epoch 2, Batch 2250/5867, Loss: 0.1507\n",
      "Epoch 2, Batch 2260/5867, Loss: 0.1436\n",
      "Epoch 2, Batch 2270/5867, Loss: 0.2673\n",
      "Epoch 2, Batch 2280/5867, Loss: 0.2722\n",
      "Epoch 2, Batch 2290/5867, Loss: 0.0677\n",
      "Epoch 2, Batch 2300/5867, Loss: 0.2796\n",
      "Epoch 2, Batch 2310/5867, Loss: 0.3302\n",
      "Epoch 2, Batch 2320/5867, Loss: 0.3361\n",
      "Epoch 2, Batch 2330/5867, Loss: 0.2791\n",
      "Epoch 2, Batch 2340/5867, Loss: 0.2633\n",
      "Epoch 2, Batch 2350/5867, Loss: 0.1113\n",
      "Epoch 2, Batch 2360/5867, Loss: 0.2528\n",
      "Epoch 2, Batch 2370/5867, Loss: 0.1708\n",
      "Epoch 2, Batch 2380/5867, Loss: 0.1591\n",
      "Epoch 2, Batch 2390/5867, Loss: 0.3909\n",
      "Epoch 2, Batch 2400/5867, Loss: 0.1108\n",
      "Epoch 2, Batch 2410/5867, Loss: 0.2245\n",
      "Epoch 2, Batch 2420/5867, Loss: 0.1465\n",
      "Epoch 2, Batch 2430/5867, Loss: 0.1872\n",
      "Epoch 2, Batch 2440/5867, Loss: 0.3538\n",
      "Epoch 2, Batch 2450/5867, Loss: 0.1513\n",
      "Epoch 2, Batch 2460/5867, Loss: 0.1611\n",
      "Epoch 2, Batch 2470/5867, Loss: 0.1962\n",
      "Epoch 2, Batch 2480/5867, Loss: 0.4143\n",
      "Epoch 2, Batch 2490/5867, Loss: 0.1953\n",
      "Epoch 2, Batch 2500/5867, Loss: 0.1787\n",
      "Epoch 2, Batch 2510/5867, Loss: 0.2089\n",
      "Epoch 2, Batch 2520/5867, Loss: 0.1318\n",
      "Epoch 2, Batch 2530/5867, Loss: 0.2271\n",
      "Epoch 2, Batch 2540/5867, Loss: 0.1455\n",
      "Epoch 2, Batch 2550/5867, Loss: 0.1416\n",
      "Epoch 2, Batch 2560/5867, Loss: 0.2352\n",
      "Epoch 2, Batch 2570/5867, Loss: 0.3713\n",
      "Epoch 2, Batch 2580/5867, Loss: 0.1627\n",
      "Epoch 2, Batch 2590/5867, Loss: 0.2896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 2600/5867, Loss: 0.1723\n",
      "Epoch 2, Batch 2610/5867, Loss: 0.2382\n",
      "Epoch 2, Batch 2620/5867, Loss: 0.2026\n",
      "Epoch 2, Batch 2630/5867, Loss: 0.2614\n",
      "Epoch 2, Batch 2640/5867, Loss: 0.0760\n",
      "Epoch 2, Batch 2650/5867, Loss: 0.1453\n",
      "Epoch 2, Batch 2660/5867, Loss: 0.2149\n",
      "Epoch 2, Batch 2670/5867, Loss: 0.2335\n",
      "Epoch 2, Batch 2680/5867, Loss: 0.2329\n",
      "Epoch 2, Batch 2690/5867, Loss: 0.2086\n",
      "Epoch 2, Batch 2700/5867, Loss: 0.2989\n",
      "Epoch 2, Batch 2710/5867, Loss: 0.2771\n",
      "Epoch 2, Batch 2720/5867, Loss: 0.1731\n",
      "Epoch 2, Batch 2730/5867, Loss: 0.3106\n",
      "Epoch 2, Batch 2740/5867, Loss: 0.3680\n",
      "Epoch 2, Batch 2750/5867, Loss: 0.1473\n",
      "Epoch 2, Batch 2760/5867, Loss: 0.2230\n",
      "Epoch 2, Batch 2770/5867, Loss: 0.1305\n",
      "Epoch 2, Batch 2780/5867, Loss: 0.1975\n",
      "Epoch 2, Batch 2790/5867, Loss: 0.3302\n",
      "Epoch 2, Batch 2800/5867, Loss: 0.4164\n",
      "Epoch 2, Batch 2810/5867, Loss: 0.2388\n",
      "Epoch 2, Batch 2820/5867, Loss: 0.1900\n",
      "Epoch 2, Batch 2830/5867, Loss: 0.2569\n",
      "Epoch 2, Batch 2840/5867, Loss: 0.3201\n",
      "Epoch 2, Batch 2850/5867, Loss: 0.1492\n",
      "Epoch 2, Batch 2860/5867, Loss: 0.1425\n",
      "Epoch 2, Batch 2870/5867, Loss: 0.1300\n",
      "Epoch 2, Batch 2880/5867, Loss: 0.2694\n",
      "Epoch 2, Batch 2890/5867, Loss: 0.1057\n",
      "Epoch 2, Batch 2900/5867, Loss: 0.1441\n",
      "Epoch 2, Batch 2910/5867, Loss: 0.2171\n",
      "Epoch 2, Batch 2920/5867, Loss: 0.4133\n",
      "Epoch 2, Batch 2930/5867, Loss: 0.2605\n",
      "Epoch 2, Batch 2940/5867, Loss: 0.1281\n",
      "Epoch 2, Batch 2950/5867, Loss: 0.3502\n",
      "Epoch 2, Batch 2960/5867, Loss: 0.1478\n",
      "Epoch 2, Batch 2970/5867, Loss: 0.2102\n",
      "Epoch 2, Batch 2980/5867, Loss: 0.0833\n",
      "Epoch 2, Batch 2990/5867, Loss: 0.2035\n",
      "Epoch 2, Batch 3000/5867, Loss: 0.2353\n",
      "Epoch 2, Batch 3010/5867, Loss: 0.1986\n",
      "Epoch 2, Batch 3020/5867, Loss: 0.1149\n",
      "Epoch 2, Batch 3030/5867, Loss: 0.1079\n",
      "Epoch 2, Batch 3040/5867, Loss: 0.2510\n",
      "Epoch 2, Batch 3050/5867, Loss: 0.2284\n",
      "Epoch 2, Batch 3060/5867, Loss: 0.4050\n",
      "Epoch 2, Batch 3070/5867, Loss: 0.1488\n",
      "Epoch 2, Batch 3080/5867, Loss: 0.2114\n",
      "Epoch 2, Batch 3090/5867, Loss: 0.2970\n",
      "Epoch 2, Batch 3100/5867, Loss: 0.2634\n",
      "Epoch 2, Batch 3110/5867, Loss: 0.4537\n",
      "Epoch 2, Batch 3120/5867, Loss: 0.3036\n",
      "Epoch 2, Batch 3130/5867, Loss: 0.1529\n",
      "Epoch 2, Batch 3140/5867, Loss: 0.2005\n",
      "Epoch 2, Batch 3150/5867, Loss: 0.2187\n",
      "Epoch 2, Batch 3160/5867, Loss: 0.1269\n",
      "Epoch 2, Batch 3170/5867, Loss: 0.3032\n",
      "Epoch 2, Batch 3180/5867, Loss: 0.0961\n",
      "Epoch 2, Batch 3190/5867, Loss: 0.3400\n",
      "Epoch 2, Batch 3200/5867, Loss: 0.2112\n",
      "Epoch 2, Batch 3210/5867, Loss: 0.1794\n",
      "Epoch 2, Batch 3220/5867, Loss: 0.3558\n",
      "Epoch 2, Batch 3230/5867, Loss: 0.4688\n",
      "Epoch 2, Batch 3240/5867, Loss: 0.1351\n",
      "Epoch 2, Batch 3250/5867, Loss: 0.4348\n",
      "Epoch 2, Batch 3260/5867, Loss: 0.2969\n",
      "Epoch 2, Batch 3270/5867, Loss: 0.3131\n",
      "Epoch 2, Batch 3280/5867, Loss: 0.2510\n",
      "Epoch 2, Batch 3290/5867, Loss: 0.3227\n",
      "Epoch 2, Batch 3300/5867, Loss: 0.2650\n",
      "Epoch 2, Batch 3310/5867, Loss: 0.1941\n",
      "Epoch 2, Batch 3320/5867, Loss: 0.1417\n",
      "Epoch 2, Batch 3330/5867, Loss: 0.1603\n",
      "Epoch 2, Batch 3340/5867, Loss: 0.1219\n",
      "Epoch 2, Batch 3350/5867, Loss: 0.2304\n",
      "Epoch 2, Batch 3360/5867, Loss: 0.2382\n",
      "Epoch 2, Batch 3370/5867, Loss: 0.0887\n",
      "Epoch 2, Batch 3380/5867, Loss: 0.1809\n",
      "Epoch 2, Batch 3390/5867, Loss: 0.2443\n",
      "Epoch 2, Batch 3400/5867, Loss: 0.2188\n",
      "Epoch 2, Batch 3410/5867, Loss: 0.2233\n",
      "Epoch 2, Batch 3420/5867, Loss: 0.2596\n",
      "Epoch 2, Batch 3430/5867, Loss: 0.3017\n",
      "Epoch 2, Batch 3440/5867, Loss: 0.2812\n",
      "Epoch 2, Batch 3450/5867, Loss: 0.1496\n",
      "Epoch 2, Batch 3460/5867, Loss: 0.2912\n",
      "Epoch 2, Batch 3470/5867, Loss: 0.0859\n",
      "Epoch 2, Batch 3480/5867, Loss: 0.1234\n",
      "Epoch 2, Batch 3490/5867, Loss: 0.2123\n",
      "Epoch 2, Batch 3500/5867, Loss: 0.2067\n",
      "Epoch 2, Batch 3510/5867, Loss: 0.2091\n",
      "Epoch 2, Batch 3520/5867, Loss: 0.1947\n",
      "Epoch 2, Batch 3530/5867, Loss: 0.3029\n",
      "Epoch 2, Batch 3540/5867, Loss: 0.2256\n",
      "Epoch 2, Batch 3550/5867, Loss: 0.1114\n",
      "Epoch 2, Batch 3560/5867, Loss: 0.1441\n",
      "Epoch 2, Batch 3570/5867, Loss: 0.2815\n",
      "Epoch 2, Batch 3580/5867, Loss: 0.2867\n",
      "Epoch 2, Batch 3590/5867, Loss: 0.1670\n",
      "Epoch 2, Batch 3600/5867, Loss: 0.2483\n",
      "Epoch 2, Batch 3610/5867, Loss: 0.1278\n",
      "Epoch 2, Batch 3620/5867, Loss: 0.3092\n",
      "Epoch 2, Batch 3630/5867, Loss: 0.1113\n",
      "Epoch 2, Batch 3640/5867, Loss: 0.2766\n",
      "Epoch 2, Batch 3650/5867, Loss: 0.1274\n",
      "Epoch 2, Batch 3660/5867, Loss: 0.2948\n",
      "Epoch 2, Batch 3670/5867, Loss: 0.3503\n",
      "Epoch 2, Batch 3680/5867, Loss: 0.3076\n",
      "Epoch 2, Batch 3690/5867, Loss: 0.2194\n",
      "Epoch 2, Batch 3700/5867, Loss: 0.2853\n",
      "Epoch 2, Batch 3710/5867, Loss: 0.1226\n",
      "Epoch 2, Batch 3720/5867, Loss: 0.2380\n",
      "Epoch 2, Batch 3730/5867, Loss: 0.1556\n",
      "Epoch 2, Batch 3740/5867, Loss: 0.3526\n",
      "Epoch 2, Batch 3750/5867, Loss: 0.1649\n",
      "Epoch 2, Batch 3760/5867, Loss: 0.2689\n",
      "Epoch 2, Batch 3770/5867, Loss: 0.2815\n",
      "Epoch 2, Batch 3780/5867, Loss: 0.2747\n",
      "Epoch 2, Batch 3790/5867, Loss: 0.2108\n",
      "Epoch 2, Batch 3800/5867, Loss: 0.2269\n",
      "Epoch 2, Batch 3810/5867, Loss: 0.2665\n",
      "Epoch 2, Batch 3820/5867, Loss: 0.2271\n",
      "Epoch 2, Batch 3830/5867, Loss: 0.2418\n",
      "Epoch 2, Batch 3840/5867, Loss: 0.1398\n",
      "Epoch 2, Batch 3850/5867, Loss: 0.2174\n",
      "Epoch 2, Batch 3860/5867, Loss: 0.1420\n",
      "Epoch 2, Batch 3870/5867, Loss: 0.1661\n",
      "Epoch 2, Batch 3880/5867, Loss: 0.1602\n",
      "Epoch 2, Batch 3890/5867, Loss: 0.1874\n",
      "Epoch 2, Batch 3900/5867, Loss: 0.2956\n",
      "Epoch 2, Batch 3910/5867, Loss: 0.4283\n",
      "Epoch 2, Batch 3920/5867, Loss: 0.1352\n",
      "Epoch 2, Batch 3930/5867, Loss: 0.2394\n",
      "Epoch 2, Batch 3940/5867, Loss: 0.3357\n",
      "Epoch 2, Batch 3950/5867, Loss: 0.1145\n",
      "Epoch 2, Batch 3960/5867, Loss: 0.1982\n",
      "Epoch 2, Batch 3970/5867, Loss: 0.1075\n",
      "Epoch 2, Batch 3980/5867, Loss: 0.1269\n",
      "Epoch 2, Batch 3990/5867, Loss: 0.2543\n",
      "Epoch 2, Batch 4000/5867, Loss: 0.1090\n",
      "Epoch 2, Batch 4010/5867, Loss: 0.1519\n",
      "Epoch 2, Batch 4020/5867, Loss: 0.1562\n",
      "Epoch 2, Batch 4030/5867, Loss: 0.1855\n",
      "Epoch 2, Batch 4040/5867, Loss: 0.1179\n",
      "Epoch 2, Batch 4050/5867, Loss: 0.3745\n",
      "Epoch 2, Batch 4060/5867, Loss: 0.2681\n",
      "Epoch 2, Batch 4070/5867, Loss: 0.2376\n",
      "Epoch 2, Batch 4080/5867, Loss: 0.4108\n",
      "Epoch 2, Batch 4090/5867, Loss: 0.1906\n",
      "Epoch 2, Batch 4100/5867, Loss: 0.1195\n",
      "Epoch 2, Batch 4110/5867, Loss: 0.2177\n",
      "Epoch 2, Batch 4120/5867, Loss: 0.2998\n",
      "Epoch 2, Batch 4130/5867, Loss: 0.2927\n",
      "Epoch 2, Batch 4140/5867, Loss: 0.2397\n",
      "Epoch 2, Batch 4150/5867, Loss: 0.1315\n",
      "Epoch 2, Batch 4160/5867, Loss: 0.2830\n",
      "Epoch 2, Batch 4170/5867, Loss: 0.3730\n",
      "Epoch 2, Batch 4180/5867, Loss: 0.2459\n",
      "Epoch 2, Batch 4190/5867, Loss: 0.1913\n",
      "Epoch 2, Batch 4200/5867, Loss: 0.2761\n",
      "Epoch 2, Batch 4210/5867, Loss: 0.1643\n",
      "Epoch 2, Batch 4220/5867, Loss: 0.1609\n",
      "Epoch 2, Batch 4230/5867, Loss: 0.0931\n",
      "Epoch 2, Batch 4240/5867, Loss: 0.3197\n",
      "Epoch 2, Batch 4250/5867, Loss: 0.3461\n",
      "Epoch 2, Batch 4260/5867, Loss: 0.3876\n",
      "Epoch 2, Batch 4270/5867, Loss: 0.1954\n",
      "Epoch 2, Batch 4280/5867, Loss: 0.1540\n",
      "Epoch 2, Batch 4290/5867, Loss: 0.1680\n",
      "Epoch 2, Batch 4300/5867, Loss: 0.2826\n",
      "Epoch 2, Batch 4310/5867, Loss: 0.2343\n",
      "Epoch 2, Batch 4320/5867, Loss: 0.1137\n",
      "Epoch 2, Batch 4330/5867, Loss: 0.3298\n",
      "Epoch 2, Batch 4340/5867, Loss: 0.4338\n",
      "Epoch 2, Batch 4350/5867, Loss: 0.2343\n",
      "Epoch 2, Batch 4360/5867, Loss: 0.1544\n",
      "Epoch 2, Batch 4370/5867, Loss: 0.3201\n",
      "Epoch 2, Batch 4380/5867, Loss: 0.2761\n",
      "Epoch 2, Batch 4390/5867, Loss: 0.3103\n",
      "Epoch 2, Batch 4400/5867, Loss: 0.1869\n",
      "Epoch 2, Batch 4410/5867, Loss: 0.1285\n",
      "Epoch 2, Batch 4420/5867, Loss: 0.2889\n",
      "Epoch 2, Batch 4430/5867, Loss: 0.0997\n",
      "Epoch 2, Batch 4440/5867, Loss: 0.1449\n",
      "Epoch 2, Batch 4450/5867, Loss: 0.1655\n",
      "Epoch 2, Batch 4460/5867, Loss: 0.3063\n",
      "Epoch 2, Batch 4470/5867, Loss: 0.1220\n",
      "Epoch 2, Batch 4480/5867, Loss: 0.2723\n",
      "Epoch 2, Batch 4490/5867, Loss: 0.1977\n",
      "Epoch 2, Batch 4500/5867, Loss: 0.2696\n",
      "Epoch 2, Batch 4510/5867, Loss: 0.2334\n",
      "Epoch 2, Batch 4520/5867, Loss: 0.3036\n",
      "Epoch 2, Batch 4530/5867, Loss: 0.4888\n",
      "Epoch 2, Batch 4540/5867, Loss: 0.2608\n",
      "Epoch 2, Batch 4550/5867, Loss: 0.1344\n",
      "Epoch 2, Batch 4560/5867, Loss: 0.2116\n",
      "Epoch 2, Batch 4570/5867, Loss: 0.2317\n",
      "Epoch 2, Batch 4580/5867, Loss: 0.2712\n",
      "Epoch 2, Batch 4590/5867, Loss: 0.0784\n",
      "Epoch 2, Batch 4600/5867, Loss: 0.2527\n",
      "Epoch 2, Batch 4610/5867, Loss: 0.1784\n",
      "Epoch 2, Batch 4620/5867, Loss: 0.2637\n",
      "Epoch 2, Batch 4630/5867, Loss: 0.1963\n",
      "Epoch 2, Batch 4640/5867, Loss: 0.1977\n",
      "Epoch 2, Batch 4650/5867, Loss: 0.3559\n",
      "Epoch 2, Batch 4660/5867, Loss: 0.2041\n",
      "Epoch 2, Batch 4670/5867, Loss: 0.1079\n",
      "Epoch 2, Batch 4680/5867, Loss: 0.3697\n",
      "Epoch 2, Batch 4690/5867, Loss: 0.3434\n",
      "Epoch 2, Batch 4700/5867, Loss: 0.0751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 4710/5867, Loss: 0.3432\n",
      "Epoch 2, Batch 4720/5867, Loss: 0.3140\n",
      "Epoch 2, Batch 4730/5867, Loss: 0.2156\n",
      "Epoch 2, Batch 4740/5867, Loss: 0.2528\n",
      "Epoch 2, Batch 4750/5867, Loss: 0.2316\n",
      "Epoch 2, Batch 4760/5867, Loss: 0.1294\n",
      "Epoch 2, Batch 4770/5867, Loss: 0.2170\n",
      "Epoch 2, Batch 4780/5867, Loss: 0.1449\n",
      "Epoch 2, Batch 4790/5867, Loss: 0.1807\n",
      "Epoch 2, Batch 4800/5867, Loss: 0.3102\n",
      "Epoch 2, Batch 4810/5867, Loss: 0.2479\n",
      "Epoch 2, Batch 4820/5867, Loss: 0.1257\n",
      "Epoch 2, Batch 4830/5867, Loss: 0.2501\n",
      "Epoch 2, Batch 4840/5867, Loss: 0.1453\n",
      "Epoch 2, Batch 4850/5867, Loss: 0.2179\n",
      "Epoch 2, Batch 4860/5867, Loss: 0.2455\n",
      "Epoch 2, Batch 4870/5867, Loss: 0.1439\n",
      "Epoch 2, Batch 4880/5867, Loss: 0.1628\n",
      "Epoch 2, Batch 4890/5867, Loss: 0.2596\n",
      "Epoch 2, Batch 4900/5867, Loss: 0.1794\n",
      "Epoch 2, Batch 4910/5867, Loss: 0.1967\n",
      "Epoch 2, Batch 4920/5867, Loss: 0.1665\n",
      "Epoch 2, Batch 4930/5867, Loss: 0.3434\n",
      "Epoch 2, Batch 4940/5867, Loss: 0.3331\n",
      "Epoch 2, Batch 4950/5867, Loss: 0.3986\n",
      "Epoch 2, Batch 4960/5867, Loss: 0.1555\n",
      "Epoch 2, Batch 4970/5867, Loss: 0.1661\n",
      "Epoch 2, Batch 4980/5867, Loss: 0.2466\n",
      "Epoch 2, Batch 4990/5867, Loss: 0.1659\n",
      "Epoch 2, Batch 5000/5867, Loss: 0.2651\n",
      "Epoch 2, Batch 5010/5867, Loss: 0.1810\n",
      "Epoch 2, Batch 5020/5867, Loss: 0.3031\n",
      "Epoch 2, Batch 5030/5867, Loss: 0.1884\n",
      "Epoch 2, Batch 5040/5867, Loss: 0.1387\n",
      "Epoch 2, Batch 5050/5867, Loss: 0.2619\n",
      "Epoch 2, Batch 5060/5867, Loss: 0.1951\n",
      "Epoch 2, Batch 5070/5867, Loss: 0.1616\n",
      "Epoch 2, Batch 5080/5867, Loss: 0.3587\n",
      "Epoch 2, Batch 5090/5867, Loss: 0.2583\n",
      "Epoch 2, Batch 5100/5867, Loss: 0.0316\n",
      "Epoch 2, Batch 5110/5867, Loss: 0.2100\n",
      "Epoch 2, Batch 5120/5867, Loss: 0.1670\n",
      "Epoch 2, Batch 5130/5867, Loss: 0.2684\n",
      "Epoch 2, Batch 5140/5867, Loss: 0.2443\n",
      "Epoch 2, Batch 5150/5867, Loss: 0.2592\n",
      "Epoch 2, Batch 5160/5867, Loss: 0.1527\n",
      "Epoch 2, Batch 5170/5867, Loss: 0.1321\n",
      "Epoch 2, Batch 5180/5867, Loss: 0.1564\n",
      "Epoch 2, Batch 5190/5867, Loss: 0.3315\n",
      "Epoch 2, Batch 5200/5867, Loss: 0.3200\n",
      "Epoch 2, Batch 5210/5867, Loss: 0.2292\n",
      "Epoch 2, Batch 5220/5867, Loss: 0.1369\n",
      "Epoch 2, Batch 5230/5867, Loss: 0.1694\n",
      "Epoch 2, Batch 5240/5867, Loss: 0.3041\n",
      "Epoch 2, Batch 5250/5867, Loss: 0.2752\n",
      "Epoch 2, Batch 5260/5867, Loss: 0.3005\n",
      "Epoch 2, Batch 5270/5867, Loss: 0.1216\n",
      "Epoch 2, Batch 5280/5867, Loss: 0.2427\n",
      "Epoch 2, Batch 5290/5867, Loss: 0.1741\n",
      "Epoch 2, Batch 5300/5867, Loss: 0.1949\n",
      "Epoch 2, Batch 5310/5867, Loss: 0.5761\n",
      "Epoch 2, Batch 5320/5867, Loss: 0.1310\n",
      "Epoch 2, Batch 5330/5867, Loss: 0.1349\n",
      "Epoch 2, Batch 5340/5867, Loss: 0.2179\n",
      "Epoch 2, Batch 5350/5867, Loss: 0.1501\n",
      "Epoch 2, Batch 5360/5867, Loss: 0.3042\n",
      "Epoch 2, Batch 5370/5867, Loss: 0.1536\n",
      "Epoch 2, Batch 5380/5867, Loss: 0.1551\n",
      "Epoch 2, Batch 5390/5867, Loss: 0.1746\n",
      "Epoch 2, Batch 5400/5867, Loss: 0.2223\n",
      "Epoch 2, Batch 5410/5867, Loss: 0.2212\n",
      "Epoch 2, Batch 5420/5867, Loss: 0.1950\n",
      "Epoch 2, Batch 5430/5867, Loss: 0.3554\n",
      "Epoch 2, Batch 5440/5867, Loss: 0.1550\n",
      "Epoch 2, Batch 5450/5867, Loss: 0.3440\n",
      "Epoch 2, Batch 5460/5867, Loss: 0.1234\n",
      "Epoch 2, Batch 5470/5867, Loss: 0.3253\n",
      "Epoch 2, Batch 5480/5867, Loss: 0.1230\n",
      "Epoch 2, Batch 5490/5867, Loss: 0.1816\n",
      "Epoch 2, Batch 5500/5867, Loss: 0.2087\n",
      "Epoch 2, Batch 5510/5867, Loss: 0.1164\n",
      "Epoch 2, Batch 5520/5867, Loss: 0.2986\n",
      "Epoch 2, Batch 5530/5867, Loss: 0.1375\n",
      "Epoch 2, Batch 5540/5867, Loss: 0.2309\n",
      "Epoch 2, Batch 5550/5867, Loss: 0.1428\n",
      "Epoch 2, Batch 5560/5867, Loss: 0.3113\n",
      "Epoch 2, Batch 5570/5867, Loss: 0.3432\n",
      "Epoch 2, Batch 5580/5867, Loss: 0.2046\n",
      "Epoch 2, Batch 5590/5867, Loss: 0.2456\n",
      "Epoch 2, Batch 5600/5867, Loss: 0.1319\n",
      "Epoch 2, Batch 5610/5867, Loss: 0.0418\n",
      "Epoch 2, Batch 5620/5867, Loss: 0.2529\n",
      "Epoch 2, Batch 5630/5867, Loss: 0.0852\n",
      "Epoch 2, Batch 5640/5867, Loss: 0.1183\n",
      "Epoch 2, Batch 5650/5867, Loss: 0.1158\n",
      "Epoch 2, Batch 5660/5867, Loss: 0.1341\n",
      "Epoch 2, Batch 5670/5867, Loss: 0.4037\n",
      "Epoch 2, Batch 5680/5867, Loss: 0.1970\n",
      "Epoch 2, Batch 5690/5867, Loss: 0.2967\n",
      "Epoch 2, Batch 5700/5867, Loss: 0.3514\n",
      "Epoch 2, Batch 5710/5867, Loss: 0.2626\n",
      "Epoch 2, Batch 5720/5867, Loss: 0.2032\n",
      "Epoch 2, Batch 5730/5867, Loss: 0.3843\n",
      "Epoch 2, Batch 5740/5867, Loss: 0.3689\n",
      "Epoch 2, Batch 5750/5867, Loss: 0.1757\n",
      "Epoch 2, Batch 5760/5867, Loss: 0.1355\n",
      "Epoch 2, Batch 5770/5867, Loss: 0.0989\n",
      "Epoch 2, Batch 5780/5867, Loss: 0.2884\n",
      "Epoch 2, Batch 5790/5867, Loss: 0.2532\n",
      "Epoch 2, Batch 5800/5867, Loss: 0.2862\n",
      "Epoch 2, Batch 5810/5867, Loss: 0.2881\n",
      "Epoch 2, Batch 5820/5867, Loss: 0.1737\n",
      "Epoch 2, Batch 5830/5867, Loss: 0.1138\n",
      "Epoch 2, Batch 5840/5867, Loss: 0.2146\n",
      "Epoch 2, Batch 5850/5867, Loss: 0.1458\n",
      "Epoch 2, Batch 5860/5867, Loss: 0.2427\n",
      "Epoch 2, Training Loss: 0.2247, Validation Loss: 0.2022\n",
      "Starting epoch 3...\n",
      "Epoch 3, Batch 10/5867, Loss: 0.0744\n",
      "Epoch 3, Batch 20/5867, Loss: 0.0997\n",
      "Epoch 3, Batch 30/5867, Loss: 0.1663\n",
      "Epoch 3, Batch 40/5867, Loss: 0.3606\n",
      "Epoch 3, Batch 50/5867, Loss: 0.0937\n",
      "Epoch 3, Batch 60/5867, Loss: 0.1084\n",
      "Epoch 3, Batch 70/5867, Loss: 0.1554\n",
      "Epoch 3, Batch 80/5867, Loss: 0.1258\n",
      "Epoch 3, Batch 90/5867, Loss: 0.3324\n",
      "Epoch 3, Batch 100/5867, Loss: 0.2772\n",
      "Epoch 3, Batch 110/5867, Loss: 0.2217\n",
      "Epoch 3, Batch 120/5867, Loss: 0.3579\n",
      "Epoch 3, Batch 130/5867, Loss: 0.2373\n",
      "Epoch 3, Batch 140/5867, Loss: 0.3517\n",
      "Epoch 3, Batch 150/5867, Loss: 0.1963\n",
      "Epoch 3, Batch 160/5867, Loss: 0.1998\n",
      "Epoch 3, Batch 170/5867, Loss: 0.2515\n",
      "Epoch 3, Batch 180/5867, Loss: 0.1839\n",
      "Epoch 3, Batch 190/5867, Loss: 0.3443\n",
      "Epoch 3, Batch 200/5867, Loss: 0.3559\n",
      "Epoch 3, Batch 210/5867, Loss: 0.1091\n",
      "Epoch 3, Batch 220/5867, Loss: 0.2556\n",
      "Epoch 3, Batch 230/5867, Loss: 0.1855\n",
      "Epoch 3, Batch 240/5867, Loss: 0.1053\n",
      "Epoch 3, Batch 250/5867, Loss: 0.1217\n",
      "Epoch 3, Batch 260/5867, Loss: 0.2053\n",
      "Epoch 3, Batch 270/5867, Loss: 0.1749\n",
      "Epoch 3, Batch 280/5867, Loss: 0.0800\n",
      "Epoch 3, Batch 290/5867, Loss: 0.1935\n",
      "Epoch 3, Batch 300/5867, Loss: 0.1727\n",
      "Epoch 3, Batch 310/5867, Loss: 0.0722\n",
      "Epoch 3, Batch 320/5867, Loss: 0.1432\n",
      "Epoch 3, Batch 330/5867, Loss: 0.0917\n",
      "Epoch 3, Batch 340/5867, Loss: 0.1867\n",
      "Epoch 3, Batch 350/5867, Loss: 0.2351\n",
      "Epoch 3, Batch 360/5867, Loss: 0.5941\n",
      "Epoch 3, Batch 370/5867, Loss: 0.1602\n",
      "Epoch 3, Batch 380/5867, Loss: 0.1285\n",
      "Epoch 3, Batch 390/5867, Loss: 0.1302\n",
      "Epoch 3, Batch 400/5867, Loss: 0.2172\n",
      "Epoch 3, Batch 410/5867, Loss: 0.3022\n",
      "Epoch 3, Batch 420/5867, Loss: 0.1752\n",
      "Epoch 3, Batch 430/5867, Loss: 0.2125\n",
      "Epoch 3, Batch 440/5867, Loss: 0.2653\n",
      "Epoch 3, Batch 450/5867, Loss: 0.0989\n",
      "Epoch 3, Batch 460/5867, Loss: 0.2015\n",
      "Epoch 3, Batch 470/5867, Loss: 0.5952\n",
      "Epoch 3, Batch 480/5867, Loss: 0.3606\n",
      "Epoch 3, Batch 490/5867, Loss: 0.1785\n",
      "Epoch 3, Batch 500/5867, Loss: 0.0936\n",
      "Epoch 3, Batch 510/5867, Loss: 0.3280\n",
      "Epoch 3, Batch 520/5867, Loss: 0.2022\n",
      "Epoch 3, Batch 530/5867, Loss: 0.0874\n",
      "Epoch 3, Batch 540/5867, Loss: 0.2505\n",
      "Epoch 3, Batch 550/5867, Loss: 0.1603\n",
      "Epoch 3, Batch 560/5867, Loss: 0.2521\n",
      "Epoch 3, Batch 570/5867, Loss: 0.2625\n",
      "Epoch 3, Batch 580/5867, Loss: 0.1664\n",
      "Epoch 3, Batch 590/5867, Loss: 0.2350\n",
      "Epoch 3, Batch 600/5867, Loss: 0.1451\n",
      "Epoch 3, Batch 610/5867, Loss: 0.1809\n",
      "Epoch 3, Batch 620/5867, Loss: 0.2072\n",
      "Epoch 3, Batch 630/5867, Loss: 0.2286\n",
      "Epoch 3, Batch 640/5867, Loss: 0.3731\n",
      "Epoch 3, Batch 650/5867, Loss: 0.1059\n",
      "Epoch 3, Batch 660/5867, Loss: 0.2416\n",
      "Epoch 3, Batch 670/5867, Loss: 0.1954\n",
      "Epoch 3, Batch 680/5867, Loss: 0.2005\n",
      "Epoch 3, Batch 690/5867, Loss: 0.3173\n",
      "Epoch 3, Batch 700/5867, Loss: 0.1748\n",
      "Epoch 3, Batch 710/5867, Loss: 0.3439\n",
      "Epoch 3, Batch 720/5867, Loss: 0.2654\n",
      "Epoch 3, Batch 730/5867, Loss: 0.1457\n",
      "Epoch 3, Batch 740/5867, Loss: 0.0786\n",
      "Epoch 3, Batch 750/5867, Loss: 0.3031\n",
      "Epoch 3, Batch 760/5867, Loss: 0.1788\n",
      "Epoch 3, Batch 770/5867, Loss: 0.3667\n",
      "Epoch 3, Batch 780/5867, Loss: 0.3163\n",
      "Epoch 3, Batch 790/5867, Loss: 0.1852\n",
      "Epoch 3, Batch 800/5867, Loss: 0.3498\n",
      "Epoch 3, Batch 810/5867, Loss: 0.1255\n",
      "Epoch 3, Batch 820/5867, Loss: 0.1136\n",
      "Epoch 3, Batch 830/5867, Loss: 0.2600\n",
      "Epoch 3, Batch 840/5867, Loss: 0.1961\n",
      "Epoch 3, Batch 850/5867, Loss: 0.2024\n",
      "Epoch 3, Batch 860/5867, Loss: 0.3190\n",
      "Epoch 3, Batch 870/5867, Loss: 0.1481\n",
      "Epoch 3, Batch 880/5867, Loss: 0.2568\n",
      "Epoch 3, Batch 890/5867, Loss: 0.1284\n",
      "Epoch 3, Batch 900/5867, Loss: 0.1633\n",
      "Epoch 3, Batch 910/5867, Loss: 0.2205\n",
      "Epoch 3, Batch 920/5867, Loss: 0.3256\n",
      "Epoch 3, Batch 930/5867, Loss: 0.2215\n",
      "Epoch 3, Batch 940/5867, Loss: 0.0951\n",
      "Epoch 3, Batch 950/5867, Loss: 0.1550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 960/5867, Loss: 0.1190\n",
      "Epoch 3, Batch 970/5867, Loss: 0.1541\n",
      "Epoch 3, Batch 980/5867, Loss: 0.1557\n",
      "Epoch 3, Batch 990/5867, Loss: 0.2803\n",
      "Epoch 3, Batch 1000/5867, Loss: 0.3055\n",
      "Epoch 3, Batch 1010/5867, Loss: 0.1001\n",
      "Epoch 3, Batch 1020/5867, Loss: 0.1384\n",
      "Epoch 3, Batch 1030/5867, Loss: 0.0923\n",
      "Epoch 3, Batch 1040/5867, Loss: 0.1980\n",
      "Epoch 3, Batch 1050/5867, Loss: 0.2540\n",
      "Epoch 3, Batch 1060/5867, Loss: 0.2197\n",
      "Epoch 3, Batch 1070/5867, Loss: 0.2790\n",
      "Epoch 3, Batch 1080/5867, Loss: 0.1586\n",
      "Epoch 3, Batch 1090/5867, Loss: 0.2857\n",
      "Epoch 3, Batch 1100/5867, Loss: 0.1380\n",
      "Epoch 3, Batch 1110/5867, Loss: 0.2082\n",
      "Epoch 3, Batch 1120/5867, Loss: 0.0753\n",
      "Epoch 3, Batch 1130/5867, Loss: 0.2561\n",
      "Epoch 3, Batch 1140/5867, Loss: 0.1025\n",
      "Epoch 3, Batch 1150/5867, Loss: 0.2080\n",
      "Epoch 3, Batch 1160/5867, Loss: 0.3142\n",
      "Epoch 3, Batch 1170/5867, Loss: 0.0971\n",
      "Epoch 3, Batch 1180/5867, Loss: 0.1126\n",
      "Epoch 3, Batch 1190/5867, Loss: 0.2578\n",
      "Epoch 3, Batch 1200/5867, Loss: 0.3831\n",
      "Epoch 3, Batch 1210/5867, Loss: 0.1701\n",
      "Epoch 3, Batch 1220/5867, Loss: 0.1969\n",
      "Epoch 3, Batch 1230/5867, Loss: 0.2256\n",
      "Epoch 3, Batch 1240/5867, Loss: 0.1337\n",
      "Epoch 3, Batch 1250/5867, Loss: 0.2280\n",
      "Epoch 3, Batch 1260/5867, Loss: 0.2545\n",
      "Epoch 3, Batch 1270/5867, Loss: 0.3525\n",
      "Epoch 3, Batch 1280/5867, Loss: 0.1678\n",
      "Epoch 3, Batch 1290/5867, Loss: 0.0873\n",
      "Epoch 3, Batch 1300/5867, Loss: 0.2279\n",
      "Epoch 3, Batch 1310/5867, Loss: 0.1923\n",
      "Epoch 3, Batch 1320/5867, Loss: 0.1977\n",
      "Epoch 3, Batch 1330/5867, Loss: 0.1646\n",
      "Epoch 3, Batch 1340/5867, Loss: 0.1393\n",
      "Epoch 3, Batch 1350/5867, Loss: 0.3622\n",
      "Epoch 3, Batch 1360/5867, Loss: 0.0987\n",
      "Epoch 3, Batch 1370/5867, Loss: 0.0734\n",
      "Epoch 3, Batch 1380/5867, Loss: 0.2908\n",
      "Epoch 3, Batch 1390/5867, Loss: 0.1951\n",
      "Epoch 3, Batch 1400/5867, Loss: 0.1126\n",
      "Epoch 3, Batch 1410/5867, Loss: 0.1153\n",
      "Epoch 3, Batch 1420/5867, Loss: 0.3786\n",
      "Epoch 3, Batch 1430/5867, Loss: 0.1625\n",
      "Epoch 3, Batch 1440/5867, Loss: 0.1538\n",
      "Epoch 3, Batch 1450/5867, Loss: 0.2208\n",
      "Epoch 3, Batch 1460/5867, Loss: 0.1597\n",
      "Epoch 3, Batch 1470/5867, Loss: 0.2326\n",
      "Epoch 3, Batch 1480/5867, Loss: 0.0853\n",
      "Epoch 3, Batch 1490/5867, Loss: 0.1820\n",
      "Epoch 3, Batch 1500/5867, Loss: 0.1888\n",
      "Epoch 3, Batch 1510/5867, Loss: 0.3104\n",
      "Epoch 3, Batch 1520/5867, Loss: 0.2993\n",
      "Epoch 3, Batch 1530/5867, Loss: 0.1218\n",
      "Epoch 3, Batch 1540/5867, Loss: 0.3276\n",
      "Epoch 3, Batch 1550/5867, Loss: 0.2382\n",
      "Epoch 3, Batch 1560/5867, Loss: 0.1908\n",
      "Epoch 3, Batch 1570/5867, Loss: 0.0676\n",
      "Epoch 3, Batch 1580/5867, Loss: 0.2668\n",
      "Epoch 3, Batch 1590/5867, Loss: 0.0918\n",
      "Epoch 3, Batch 1600/5867, Loss: 0.1016\n",
      "Epoch 3, Batch 1610/5867, Loss: 0.1268\n",
      "Epoch 3, Batch 1620/5867, Loss: 0.2135\n",
      "Epoch 3, Batch 1630/5867, Loss: 0.0948\n",
      "Epoch 3, Batch 1640/5867, Loss: 0.2804\n",
      "Epoch 3, Batch 1650/5867, Loss: 0.1629\n",
      "Epoch 3, Batch 1660/5867, Loss: 0.1849\n",
      "Epoch 3, Batch 1670/5867, Loss: 0.1920\n",
      "Epoch 3, Batch 1680/5867, Loss: 0.1072\n",
      "Epoch 3, Batch 1690/5867, Loss: 0.2313\n",
      "Epoch 3, Batch 1700/5867, Loss: 0.1263\n",
      "Epoch 3, Batch 1710/5867, Loss: 0.1399\n",
      "Epoch 3, Batch 1720/5867, Loss: 0.2146\n",
      "Epoch 3, Batch 1730/5867, Loss: 0.1326\n",
      "Epoch 3, Batch 1740/5867, Loss: 0.0932\n",
      "Epoch 3, Batch 1750/5867, Loss: 0.1765\n",
      "Epoch 3, Batch 1760/5867, Loss: 0.2139\n",
      "Epoch 3, Batch 1770/5867, Loss: 0.1048\n",
      "Epoch 3, Batch 1780/5867, Loss: 0.1273\n",
      "Epoch 3, Batch 1790/5867, Loss: 0.1545\n",
      "Epoch 3, Batch 1800/5867, Loss: 0.1309\n",
      "Epoch 3, Batch 1810/5867, Loss: 0.3577\n",
      "Epoch 3, Batch 1820/5867, Loss: 0.1982\n",
      "Epoch 3, Batch 1830/5867, Loss: 0.1528\n",
      "Epoch 3, Batch 1840/5867, Loss: 0.1315\n",
      "Epoch 3, Batch 1850/5867, Loss: 0.1437\n",
      "Epoch 3, Batch 1860/5867, Loss: 0.1539\n",
      "Epoch 3, Batch 1870/5867, Loss: 0.1115\n",
      "Epoch 3, Batch 1880/5867, Loss: 0.0965\n",
      "Epoch 3, Batch 1890/5867, Loss: 0.1796\n",
      "Epoch 3, Batch 1900/5867, Loss: 0.0799\n",
      "Epoch 3, Batch 1910/5867, Loss: 0.2852\n",
      "Epoch 3, Batch 1920/5867, Loss: 0.1018\n",
      "Epoch 3, Batch 1930/5867, Loss: 0.2317\n",
      "Epoch 3, Batch 1940/5867, Loss: 0.1353\n",
      "Epoch 3, Batch 1950/5867, Loss: 0.1485\n",
      "Epoch 3, Batch 1960/5867, Loss: 0.2685\n",
      "Epoch 3, Batch 1970/5867, Loss: 0.0616\n",
      "Epoch 3, Batch 1980/5867, Loss: 0.3132\n",
      "Epoch 3, Batch 1990/5867, Loss: 0.2134\n",
      "Epoch 3, Batch 2000/5867, Loss: 0.3295\n",
      "Epoch 3, Batch 2010/5867, Loss: 0.2129\n",
      "Epoch 3, Batch 2020/5867, Loss: 0.0968\n",
      "Epoch 3, Batch 2030/5867, Loss: 0.2934\n",
      "Epoch 3, Batch 2040/5867, Loss: 0.1668\n",
      "Epoch 3, Batch 2050/5867, Loss: 0.1953\n",
      "Epoch 3, Batch 2060/5867, Loss: 0.1272\n",
      "Epoch 3, Batch 2070/5867, Loss: 0.2123\n",
      "Epoch 3, Batch 2080/5867, Loss: 0.2759\n",
      "Epoch 3, Batch 2090/5867, Loss: 0.1120\n",
      "Epoch 3, Batch 2100/5867, Loss: 0.1356\n",
      "Epoch 3, Batch 2110/5867, Loss: 0.3226\n",
      "Epoch 3, Batch 2120/5867, Loss: 0.1062\n",
      "Epoch 3, Batch 2130/5867, Loss: 0.1074\n",
      "Epoch 3, Batch 2140/5867, Loss: 0.1834\n",
      "Epoch 3, Batch 2150/5867, Loss: 0.0734\n",
      "Epoch 3, Batch 2160/5867, Loss: 0.1531\n",
      "Epoch 3, Batch 2170/5867, Loss: 0.3911\n",
      "Epoch 3, Batch 2180/5867, Loss: 0.3944\n",
      "Epoch 3, Batch 2190/5867, Loss: 0.4473\n",
      "Epoch 3, Batch 2200/5867, Loss: 0.1100\n",
      "Epoch 3, Batch 2210/5867, Loss: 0.2693\n",
      "Epoch 3, Batch 2220/5867, Loss: 0.1703\n",
      "Epoch 3, Batch 2230/5867, Loss: 0.2426\n",
      "Epoch 3, Batch 2240/5867, Loss: 0.2201\n",
      "Epoch 3, Batch 2250/5867, Loss: 0.0965\n",
      "Epoch 3, Batch 2260/5867, Loss: 0.2077\n",
      "Epoch 3, Batch 2270/5867, Loss: 0.2436\n",
      "Epoch 3, Batch 2280/5867, Loss: 0.2065\n",
      "Epoch 3, Batch 2290/5867, Loss: 0.2751\n",
      "Epoch 3, Batch 2300/5867, Loss: 0.1558\n",
      "Epoch 3, Batch 2310/5867, Loss: 0.1437\n",
      "Epoch 3, Batch 2320/5867, Loss: 0.2241\n",
      "Epoch 3, Batch 2330/5867, Loss: 0.1925\n",
      "Epoch 3, Batch 2340/5867, Loss: 0.6581\n",
      "Epoch 3, Batch 2350/5867, Loss: 0.2312\n",
      "Epoch 3, Batch 2360/5867, Loss: 0.1058\n",
      "Epoch 3, Batch 2370/5867, Loss: 0.2982\n",
      "Epoch 3, Batch 2380/5867, Loss: 0.3932\n",
      "Epoch 3, Batch 2390/5867, Loss: 0.1713\n",
      "Epoch 3, Batch 2400/5867, Loss: 0.1114\n",
      "Epoch 3, Batch 2410/5867, Loss: 0.1909\n",
      "Epoch 3, Batch 2420/5867, Loss: 0.1531\n",
      "Epoch 3, Batch 2430/5867, Loss: 0.1422\n",
      "Epoch 3, Batch 2440/5867, Loss: 0.0898\n",
      "Epoch 3, Batch 2450/5867, Loss: 0.2962\n",
      "Epoch 3, Batch 2460/5867, Loss: 0.0829\n",
      "Epoch 3, Batch 2470/5867, Loss: 0.1794\n",
      "Epoch 3, Batch 2480/5867, Loss: 0.2583\n",
      "Epoch 3, Batch 2490/5867, Loss: 0.1685\n",
      "Epoch 3, Batch 2500/5867, Loss: 0.2122\n",
      "Epoch 3, Batch 2510/5867, Loss: 0.2573\n",
      "Epoch 3, Batch 2520/5867, Loss: 0.1732\n",
      "Epoch 3, Batch 2530/5867, Loss: 0.2398\n",
      "Epoch 3, Batch 2540/5867, Loss: 0.1531\n",
      "Epoch 3, Batch 2550/5867, Loss: 0.2761\n",
      "Epoch 3, Batch 2560/5867, Loss: 0.0912\n",
      "Epoch 3, Batch 2570/5867, Loss: 0.0942\n",
      "Epoch 3, Batch 2580/5867, Loss: 0.1584\n",
      "Epoch 3, Batch 2590/5867, Loss: 0.0838\n",
      "Epoch 3, Batch 2600/5867, Loss: 0.1020\n",
      "Epoch 3, Batch 2610/5867, Loss: 0.4080\n",
      "Epoch 3, Batch 2620/5867, Loss: 0.1241\n",
      "Epoch 3, Batch 2630/5867, Loss: 0.1321\n",
      "Epoch 3, Batch 2640/5867, Loss: 0.2628\n",
      "Epoch 3, Batch 2650/5867, Loss: 0.1371\n",
      "Epoch 3, Batch 2660/5867, Loss: 0.2554\n",
      "Epoch 3, Batch 2670/5867, Loss: 0.3859\n",
      "Epoch 3, Batch 2680/5867, Loss: 0.2479\n",
      "Epoch 3, Batch 2690/5867, Loss: 0.1136\n",
      "Epoch 3, Batch 2700/5867, Loss: 0.2862\n",
      "Epoch 3, Batch 2710/5867, Loss: 0.1656\n",
      "Epoch 3, Batch 2720/5867, Loss: 0.1877\n",
      "Epoch 3, Batch 2730/5867, Loss: 0.1134\n",
      "Epoch 3, Batch 2740/5867, Loss: 0.1738\n",
      "Epoch 3, Batch 2750/5867, Loss: 0.2481\n",
      "Epoch 3, Batch 2760/5867, Loss: 0.1737\n",
      "Epoch 3, Batch 2770/5867, Loss: 0.3279\n",
      "Epoch 3, Batch 2780/5867, Loss: 0.1046\n",
      "Epoch 3, Batch 2790/5867, Loss: 0.0730\n",
      "Epoch 3, Batch 2800/5867, Loss: 0.2492\n",
      "Epoch 3, Batch 2810/5867, Loss: 0.1506\n",
      "Epoch 3, Batch 2820/5867, Loss: 0.2360\n",
      "Epoch 3, Batch 2830/5867, Loss: 0.3571\n",
      "Epoch 3, Batch 2840/5867, Loss: 0.1491\n",
      "Epoch 3, Batch 2850/5867, Loss: 0.1845\n",
      "Epoch 3, Batch 2860/5867, Loss: 0.2281\n",
      "Epoch 3, Batch 2870/5867, Loss: 0.1140\n",
      "Epoch 3, Batch 2880/5867, Loss: 0.2611\n",
      "Epoch 3, Batch 2890/5867, Loss: 0.1196\n",
      "Epoch 3, Batch 2900/5867, Loss: 0.2432\n",
      "Epoch 3, Batch 2910/5867, Loss: 0.1256\n",
      "Epoch 3, Batch 2920/5867, Loss: 0.1075\n",
      "Epoch 3, Batch 2930/5867, Loss: 0.2182\n",
      "Epoch 3, Batch 2940/5867, Loss: 0.1385\n",
      "Epoch 3, Batch 2950/5867, Loss: 0.1563\n",
      "Epoch 3, Batch 2960/5867, Loss: 0.2876\n",
      "Epoch 3, Batch 2970/5867, Loss: 0.2413\n",
      "Epoch 3, Batch 2980/5867, Loss: 0.2302\n",
      "Epoch 3, Batch 2990/5867, Loss: 0.1288\n",
      "Epoch 3, Batch 3000/5867, Loss: 0.3046\n",
      "Epoch 3, Batch 3010/5867, Loss: 0.1744\n",
      "Epoch 3, Batch 3020/5867, Loss: 0.2273\n",
      "Epoch 3, Batch 3030/5867, Loss: 0.2867\n",
      "Epoch 3, Batch 3040/5867, Loss: 0.1975\n",
      "Epoch 3, Batch 3050/5867, Loss: 0.1647\n",
      "Epoch 3, Batch 3060/5867, Loss: 0.1614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 3070/5867, Loss: 0.1835\n",
      "Epoch 3, Batch 3080/5867, Loss: 0.2716\n",
      "Epoch 3, Batch 3090/5867, Loss: 0.2531\n",
      "Epoch 3, Batch 3100/5867, Loss: 0.2006\n",
      "Epoch 3, Batch 3110/5867, Loss: 0.1543\n",
      "Epoch 3, Batch 3120/5867, Loss: 0.2732\n",
      "Epoch 3, Batch 3130/5867, Loss: 0.2689\n",
      "Epoch 3, Batch 3140/5867, Loss: 0.3064\n",
      "Epoch 3, Batch 3150/5867, Loss: 0.2892\n",
      "Epoch 3, Batch 3160/5867, Loss: 0.1348\n",
      "Epoch 3, Batch 3170/5867, Loss: 0.1309\n",
      "Epoch 3, Batch 3180/5867, Loss: 0.2657\n",
      "Epoch 3, Batch 3190/5867, Loss: 0.1315\n",
      "Epoch 3, Batch 3200/5867, Loss: 0.1267\n",
      "Epoch 3, Batch 3210/5867, Loss: 0.3738\n",
      "Epoch 3, Batch 3220/5867, Loss: 0.1825\n",
      "Epoch 3, Batch 3230/5867, Loss: 0.3109\n",
      "Epoch 3, Batch 3240/5867, Loss: 0.2578\n",
      "Epoch 3, Batch 3250/5867, Loss: 0.3529\n",
      "Epoch 3, Batch 3260/5867, Loss: 0.2037\n",
      "Epoch 3, Batch 3270/5867, Loss: 0.2038\n",
      "Epoch 3, Batch 3280/5867, Loss: 0.2191\n",
      "Epoch 3, Batch 3290/5867, Loss: 0.2067\n",
      "Epoch 3, Batch 3300/5867, Loss: 0.1853\n",
      "Epoch 3, Batch 3310/5867, Loss: 0.1849\n",
      "Epoch 3, Batch 3320/5867, Loss: 0.1291\n",
      "Epoch 3, Batch 3330/5867, Loss: 0.1548\n",
      "Epoch 3, Batch 3340/5867, Loss: 0.2196\n",
      "Epoch 3, Batch 3350/5867, Loss: 0.2693\n",
      "Epoch 3, Batch 3360/5867, Loss: 0.3367\n",
      "Epoch 3, Batch 3370/5867, Loss: 0.2446\n",
      "Epoch 3, Batch 3380/5867, Loss: 0.0796\n",
      "Epoch 3, Batch 3390/5867, Loss: 0.2380\n",
      "Epoch 3, Batch 3400/5867, Loss: 0.1611\n",
      "Epoch 3, Batch 3410/5867, Loss: 0.2285\n",
      "Epoch 3, Batch 3420/5867, Loss: 0.1519\n",
      "Epoch 3, Batch 3430/5867, Loss: 0.1556\n",
      "Epoch 3, Batch 3440/5867, Loss: 0.1934\n",
      "Epoch 3, Batch 3450/5867, Loss: 0.1439\n",
      "Epoch 3, Batch 3460/5867, Loss: 0.2668\n",
      "Epoch 3, Batch 3470/5867, Loss: 0.1367\n",
      "Epoch 3, Batch 3480/5867, Loss: 0.1587\n",
      "Epoch 3, Batch 3490/5867, Loss: 0.2118\n",
      "Epoch 3, Batch 3500/5867, Loss: 0.2214\n",
      "Epoch 3, Batch 3510/5867, Loss: 0.0923\n",
      "Epoch 3, Batch 3520/5867, Loss: 0.1681\n",
      "Epoch 3, Batch 3530/5867, Loss: 0.0829\n",
      "Epoch 3, Batch 3540/5867, Loss: 0.2792\n",
      "Epoch 3, Batch 3550/5867, Loss: 0.2753\n",
      "Epoch 3, Batch 3560/5867, Loss: 0.1647\n",
      "Epoch 3, Batch 3570/5867, Loss: 0.2818\n",
      "Epoch 3, Batch 3580/5867, Loss: 0.2222\n",
      "Epoch 3, Batch 3590/5867, Loss: 0.1193\n",
      "Epoch 3, Batch 3600/5867, Loss: 0.1806\n",
      "Epoch 3, Batch 3610/5867, Loss: 0.3467\n",
      "Epoch 3, Batch 3620/5867, Loss: 0.2533\n",
      "Epoch 3, Batch 3630/5867, Loss: 0.2065\n",
      "Epoch 3, Batch 3640/5867, Loss: 0.1827\n",
      "Epoch 3, Batch 3650/5867, Loss: 0.1838\n",
      "Epoch 3, Batch 3660/5867, Loss: 0.2686\n",
      "Epoch 3, Batch 3670/5867, Loss: 0.2568\n",
      "Epoch 3, Batch 3680/5867, Loss: 0.2263\n",
      "Epoch 3, Batch 3690/5867, Loss: 0.1628\n",
      "Epoch 3, Batch 3700/5867, Loss: 0.3999\n",
      "Epoch 3, Batch 3710/5867, Loss: 0.2558\n",
      "Epoch 3, Batch 3720/5867, Loss: 0.1457\n",
      "Epoch 3, Batch 3730/5867, Loss: 0.1592\n",
      "Epoch 3, Batch 3740/5867, Loss: 0.2456\n",
      "Epoch 3, Batch 3750/5867, Loss: 0.1746\n",
      "Epoch 3, Batch 3760/5867, Loss: 0.1579\n",
      "Epoch 3, Batch 3770/5867, Loss: 0.1802\n",
      "Epoch 3, Batch 3780/5867, Loss: 0.1336\n",
      "Epoch 3, Batch 3790/5867, Loss: 0.3098\n",
      "Epoch 3, Batch 3800/5867, Loss: 0.1851\n",
      "Epoch 3, Batch 3810/5867, Loss: 0.2467\n",
      "Epoch 3, Batch 3820/5867, Loss: 0.1853\n",
      "Epoch 3, Batch 3830/5867, Loss: 0.3320\n",
      "Epoch 3, Batch 3840/5867, Loss: 0.1082\n",
      "Epoch 3, Batch 3850/5867, Loss: 0.0810\n",
      "Epoch 3, Batch 3860/5867, Loss: 0.1498\n",
      "Epoch 3, Batch 3870/5867, Loss: 0.2140\n",
      "Epoch 3, Batch 3880/5867, Loss: 0.1884\n",
      "Epoch 3, Batch 3890/5867, Loss: 0.1878\n",
      "Epoch 3, Batch 3900/5867, Loss: 0.1760\n",
      "Epoch 3, Batch 3910/5867, Loss: 0.1552\n",
      "Epoch 3, Batch 3920/5867, Loss: 0.2985\n",
      "Epoch 3, Batch 3930/5867, Loss: 0.3075\n",
      "Epoch 3, Batch 3940/5867, Loss: 0.1687\n",
      "Epoch 3, Batch 3950/5867, Loss: 0.1615\n",
      "Epoch 3, Batch 3960/5867, Loss: 0.1352\n",
      "Epoch 3, Batch 3970/5867, Loss: 0.2978\n",
      "Epoch 3, Batch 3980/5867, Loss: 0.1505\n",
      "Epoch 3, Batch 3990/5867, Loss: 0.3423\n",
      "Epoch 3, Batch 4000/5867, Loss: 0.2581\n",
      "Epoch 3, Batch 4010/5867, Loss: 0.1534\n",
      "Epoch 3, Batch 4020/5867, Loss: 0.1645\n",
      "Epoch 3, Batch 4030/5867, Loss: 0.2273\n",
      "Epoch 3, Batch 4040/5867, Loss: 0.1742\n",
      "Epoch 3, Batch 4050/5867, Loss: 0.2079\n",
      "Epoch 3, Batch 4060/5867, Loss: 0.2072\n",
      "Epoch 3, Batch 4070/5867, Loss: 0.2117\n",
      "Epoch 3, Batch 4080/5867, Loss: 0.2701\n",
      "Epoch 3, Batch 4090/5867, Loss: 0.2608\n",
      "Epoch 3, Batch 4100/5867, Loss: 0.1553\n",
      "Epoch 3, Batch 4110/5867, Loss: 0.1600\n",
      "Epoch 3, Batch 4120/5867, Loss: 0.1638\n",
      "Epoch 3, Batch 4130/5867, Loss: 0.2272\n",
      "Epoch 3, Batch 4140/5867, Loss: 0.2602\n",
      "Epoch 3, Batch 4150/5867, Loss: 0.2188\n",
      "Epoch 3, Batch 4160/5867, Loss: 0.1504\n",
      "Epoch 3, Batch 4170/5867, Loss: 0.3004\n",
      "Epoch 3, Batch 4180/5867, Loss: 0.3134\n",
      "Epoch 3, Batch 4190/5867, Loss: 0.2399\n",
      "Epoch 3, Batch 4200/5867, Loss: 0.3972\n",
      "Epoch 3, Batch 4210/5867, Loss: 0.1683\n",
      "Epoch 3, Batch 4220/5867, Loss: 0.3686\n",
      "Epoch 3, Batch 4230/5867, Loss: 0.1207\n",
      "Epoch 3, Batch 4240/5867, Loss: 0.0896\n",
      "Epoch 3, Batch 4250/5867, Loss: 0.2911\n",
      "Epoch 3, Batch 4260/5867, Loss: 0.2388\n",
      "Epoch 3, Batch 4270/5867, Loss: 0.1981\n",
      "Epoch 3, Batch 4280/5867, Loss: 0.1634\n",
      "Epoch 3, Batch 4290/5867, Loss: 0.1935\n",
      "Epoch 3, Batch 4300/5867, Loss: 0.2415\n",
      "Epoch 3, Batch 4310/5867, Loss: 0.2642\n",
      "Epoch 3, Batch 4320/5867, Loss: 0.1303\n",
      "Epoch 3, Batch 4330/5867, Loss: 0.2969\n",
      "Epoch 3, Batch 4340/5867, Loss: 0.2541\n",
      "Epoch 3, Batch 4350/5867, Loss: 0.2217\n",
      "Epoch 3, Batch 4360/5867, Loss: 0.2773\n",
      "Epoch 3, Batch 4370/5867, Loss: 0.1012\n",
      "Epoch 3, Batch 4380/5867, Loss: 0.1670\n",
      "Epoch 3, Batch 4390/5867, Loss: 0.2563\n",
      "Epoch 3, Batch 4400/5867, Loss: 0.2862\n",
      "Epoch 3, Batch 4410/5867, Loss: 0.1659\n",
      "Epoch 3, Batch 4420/5867, Loss: 0.2015\n",
      "Epoch 3, Batch 4430/5867, Loss: 0.1706\n",
      "Epoch 3, Batch 4440/5867, Loss: 0.0639\n",
      "Epoch 3, Batch 4450/5867, Loss: 0.2464\n",
      "Epoch 3, Batch 4460/5867, Loss: 0.1376\n",
      "Epoch 3, Batch 4470/5867, Loss: 0.1001\n",
      "Epoch 3, Batch 4480/5867, Loss: 0.1904\n",
      "Epoch 3, Batch 4490/5867, Loss: 0.4257\n",
      "Epoch 3, Batch 4500/5867, Loss: 0.1306\n",
      "Epoch 3, Batch 4510/5867, Loss: 0.2745\n",
      "Epoch 3, Batch 4520/5867, Loss: 0.2679\n",
      "Epoch 3, Batch 4530/5867, Loss: 0.3885\n",
      "Epoch 3, Batch 4540/5867, Loss: 0.3769\n",
      "Epoch 3, Batch 4550/5867, Loss: 0.2588\n",
      "Epoch 3, Batch 4560/5867, Loss: 0.2986\n",
      "Epoch 3, Batch 4570/5867, Loss: 0.1599\n",
      "Epoch 3, Batch 4580/5867, Loss: 0.1701\n",
      "Epoch 3, Batch 4590/5867, Loss: 0.1256\n",
      "Epoch 3, Batch 4600/5867, Loss: 0.0582\n",
      "Epoch 3, Batch 4610/5867, Loss: 0.1815\n",
      "Epoch 3, Batch 4620/5867, Loss: 0.2395\n",
      "Epoch 3, Batch 4630/5867, Loss: 0.0734\n",
      "Epoch 3, Batch 4640/5867, Loss: 0.1345\n",
      "Epoch 3, Batch 4650/5867, Loss: 0.1738\n",
      "Epoch 3, Batch 4660/5867, Loss: 0.2031\n",
      "Epoch 3, Batch 4670/5867, Loss: 0.1528\n",
      "Epoch 3, Batch 4680/5867, Loss: 0.1989\n",
      "Epoch 3, Batch 4690/5867, Loss: 0.3081\n",
      "Epoch 3, Batch 4700/5867, Loss: 0.3458\n",
      "Epoch 3, Batch 4710/5867, Loss: 0.2060\n",
      "Epoch 3, Batch 4720/5867, Loss: 0.1904\n",
      "Epoch 3, Batch 4730/5867, Loss: 0.2097\n",
      "Epoch 3, Batch 4740/5867, Loss: 0.1611\n",
      "Epoch 3, Batch 4750/5867, Loss: 0.4030\n",
      "Epoch 3, Batch 4760/5867, Loss: 0.2048\n",
      "Epoch 3, Batch 4770/5867, Loss: 0.1212\n",
      "Epoch 3, Batch 4780/5867, Loss: 0.0445\n",
      "Epoch 3, Batch 4790/5867, Loss: 0.1368\n",
      "Epoch 3, Batch 4800/5867, Loss: 0.5160\n",
      "Epoch 3, Batch 4810/5867, Loss: 0.1203\n",
      "Epoch 3, Batch 4820/5867, Loss: 0.1633\n",
      "Epoch 3, Batch 4830/5867, Loss: 0.1354\n",
      "Epoch 3, Batch 4840/5867, Loss: 0.1277\n",
      "Epoch 3, Batch 4850/5867, Loss: 0.1642\n",
      "Epoch 3, Batch 4860/5867, Loss: 0.1095\n",
      "Epoch 3, Batch 4870/5867, Loss: 0.1371\n",
      "Epoch 3, Batch 4880/5867, Loss: 0.2376\n",
      "Epoch 3, Batch 4890/5867, Loss: 0.1644\n",
      "Epoch 3, Batch 4900/5867, Loss: 0.2295\n",
      "Epoch 3, Batch 4910/5867, Loss: 0.1220\n",
      "Epoch 3, Batch 4920/5867, Loss: 0.4220\n",
      "Epoch 3, Batch 4930/5867, Loss: 0.1405\n",
      "Epoch 3, Batch 4940/5867, Loss: 0.1208\n",
      "Epoch 3, Batch 4950/5867, Loss: 0.2079\n",
      "Epoch 3, Batch 4960/5867, Loss: 0.0575\n",
      "Epoch 3, Batch 4970/5867, Loss: 0.1445\n",
      "Epoch 3, Batch 4980/5867, Loss: 0.1491\n",
      "Epoch 3, Batch 4990/5867, Loss: 0.0792\n",
      "Epoch 3, Batch 5000/5867, Loss: 0.1697\n",
      "Epoch 3, Batch 5010/5867, Loss: 0.2271\n",
      "Epoch 3, Batch 5020/5867, Loss: 0.2505\n",
      "Epoch 3, Batch 5030/5867, Loss: 0.0697\n",
      "Epoch 3, Batch 5040/5867, Loss: 0.1227\n",
      "Epoch 3, Batch 5050/5867, Loss: 0.0919\n",
      "Epoch 3, Batch 5060/5867, Loss: 0.3031\n",
      "Epoch 3, Batch 5070/5867, Loss: 0.1848\n",
      "Epoch 3, Batch 5080/5867, Loss: 0.1722\n",
      "Epoch 3, Batch 5090/5867, Loss: 0.2640\n",
      "Epoch 3, Batch 5100/5867, Loss: 0.1991\n",
      "Epoch 3, Batch 5110/5867, Loss: 0.3097\n",
      "Epoch 3, Batch 5120/5867, Loss: 0.1745\n",
      "Epoch 3, Batch 5130/5867, Loss: 0.3062\n",
      "Epoch 3, Batch 5140/5867, Loss: 0.1483\n",
      "Epoch 3, Batch 5150/5867, Loss: 0.0575\n",
      "Epoch 3, Batch 5160/5867, Loss: 0.4215\n",
      "Epoch 3, Batch 5170/5867, Loss: 0.4095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 5180/5867, Loss: 0.1931\n",
      "Epoch 3, Batch 5190/5867, Loss: 0.1195\n",
      "Epoch 3, Batch 5200/5867, Loss: 0.1619\n",
      "Epoch 3, Batch 5210/5867, Loss: 0.2612\n",
      "Epoch 3, Batch 5220/5867, Loss: 0.2150\n",
      "Epoch 3, Batch 5230/5867, Loss: 0.4763\n",
      "Epoch 3, Batch 5240/5867, Loss: 0.1139\n",
      "Epoch 3, Batch 5250/5867, Loss: 0.2025\n",
      "Epoch 3, Batch 5260/5867, Loss: 0.4302\n",
      "Epoch 3, Batch 5270/5867, Loss: 0.3972\n",
      "Epoch 3, Batch 5280/5867, Loss: 0.1900\n",
      "Epoch 3, Batch 5290/5867, Loss: 0.1374\n",
      "Epoch 3, Batch 5300/5867, Loss: 0.1595\n",
      "Epoch 3, Batch 5310/5867, Loss: 0.3074\n",
      "Epoch 3, Batch 5320/5867, Loss: 0.1629\n",
      "Epoch 3, Batch 5330/5867, Loss: 0.1747\n",
      "Epoch 3, Batch 5340/5867, Loss: 0.1830\n",
      "Epoch 3, Batch 5350/5867, Loss: 0.2742\n",
      "Epoch 3, Batch 5360/5867, Loss: 0.3041\n",
      "Epoch 3, Batch 5370/5867, Loss: 0.2684\n",
      "Epoch 3, Batch 5380/5867, Loss: 0.1719\n",
      "Epoch 3, Batch 5390/5867, Loss: 0.3483\n",
      "Epoch 3, Batch 5400/5867, Loss: 0.1637\n",
      "Epoch 3, Batch 5410/5867, Loss: 0.1919\n",
      "Epoch 3, Batch 5420/5867, Loss: 0.2006\n",
      "Epoch 3, Batch 5430/5867, Loss: 0.1061\n",
      "Epoch 3, Batch 5440/5867, Loss: 0.1195\n",
      "Epoch 3, Batch 5450/5867, Loss: 0.1673\n",
      "Epoch 3, Batch 5460/5867, Loss: 0.1580\n",
      "Epoch 3, Batch 5470/5867, Loss: 0.2284\n",
      "Epoch 3, Batch 5480/5867, Loss: 0.2113\n",
      "Epoch 3, Batch 5490/5867, Loss: 0.1080\n",
      "Epoch 3, Batch 5500/5867, Loss: 0.2508\n",
      "Epoch 3, Batch 5510/5867, Loss: 0.1543\n",
      "Epoch 3, Batch 5520/5867, Loss: 0.2080\n",
      "Epoch 3, Batch 5530/5867, Loss: 0.3452\n",
      "Epoch 3, Batch 5540/5867, Loss: 0.1816\n",
      "Epoch 3, Batch 5550/5867, Loss: 0.2100\n",
      "Epoch 3, Batch 5560/5867, Loss: 0.2338\n",
      "Epoch 3, Batch 5570/5867, Loss: 0.1762\n",
      "Epoch 3, Batch 5580/5867, Loss: 0.1362\n",
      "Epoch 3, Batch 5590/5867, Loss: 0.2451\n",
      "Epoch 3, Batch 5600/5867, Loss: 0.2084\n",
      "Epoch 3, Batch 5610/5867, Loss: 0.2448\n",
      "Epoch 3, Batch 5620/5867, Loss: 0.1991\n",
      "Epoch 3, Batch 5630/5867, Loss: 0.1917\n",
      "Epoch 3, Batch 5640/5867, Loss: 0.2829\n",
      "Epoch 3, Batch 5650/5867, Loss: 0.2266\n",
      "Epoch 3, Batch 5660/5867, Loss: 0.1576\n",
      "Epoch 3, Batch 5670/5867, Loss: 0.2274\n",
      "Epoch 3, Batch 5680/5867, Loss: 0.1946\n",
      "Epoch 3, Batch 5690/5867, Loss: 0.2465\n",
      "Epoch 3, Batch 5700/5867, Loss: 0.2547\n",
      "Epoch 3, Batch 5710/5867, Loss: 0.2543\n",
      "Epoch 3, Batch 5720/5867, Loss: 0.2856\n",
      "Epoch 3, Batch 5730/5867, Loss: 0.4697\n",
      "Epoch 3, Batch 5740/5867, Loss: 0.1909\n",
      "Epoch 3, Batch 5750/5867, Loss: 0.0940\n",
      "Epoch 3, Batch 5760/5867, Loss: 0.2192\n",
      "Epoch 3, Batch 5770/5867, Loss: 0.0996\n",
      "Epoch 3, Batch 5780/5867, Loss: 0.2034\n",
      "Epoch 3, Batch 5790/5867, Loss: 0.3441\n",
      "Epoch 3, Batch 5800/5867, Loss: 0.1338\n",
      "Epoch 3, Batch 5810/5867, Loss: 0.1761\n",
      "Epoch 3, Batch 5820/5867, Loss: 0.2004\n",
      "Epoch 3, Batch 5830/5867, Loss: 0.1892\n",
      "Epoch 3, Batch 5840/5867, Loss: 0.2686\n",
      "Epoch 3, Batch 5850/5867, Loss: 0.3867\n",
      "Epoch 3, Batch 5860/5867, Loss: 0.2543\n",
      "Epoch 3, Training Loss: 0.2098, Validation Loss: 0.2003\n",
      "Starting epoch 4...\n",
      "Epoch 4, Batch 10/5867, Loss: 0.0415\n",
      "Epoch 4, Batch 20/5867, Loss: 0.0966\n",
      "Epoch 4, Batch 30/5867, Loss: 0.2063\n",
      "Epoch 4, Batch 40/5867, Loss: 0.1823\n",
      "Epoch 4, Batch 50/5867, Loss: 0.2300\n",
      "Epoch 4, Batch 60/5867, Loss: 0.2211\n",
      "Epoch 4, Batch 70/5867, Loss: 0.1757\n",
      "Epoch 4, Batch 80/5867, Loss: 0.3530\n",
      "Epoch 4, Batch 90/5867, Loss: 0.2244\n",
      "Epoch 4, Batch 100/5867, Loss: 0.2250\n",
      "Epoch 4, Batch 110/5867, Loss: 0.0710\n",
      "Epoch 4, Batch 120/5867, Loss: 0.2467\n",
      "Epoch 4, Batch 130/5867, Loss: 0.4016\n",
      "Epoch 4, Batch 140/5867, Loss: 0.1426\n",
      "Epoch 4, Batch 150/5867, Loss: 0.0782\n",
      "Epoch 4, Batch 160/5867, Loss: 0.1680\n",
      "Epoch 4, Batch 170/5867, Loss: 0.1409\n",
      "Epoch 4, Batch 180/5867, Loss: 0.0870\n",
      "Epoch 4, Batch 190/5867, Loss: 0.1163\n",
      "Epoch 4, Batch 200/5867, Loss: 0.2088\n",
      "Epoch 4, Batch 210/5867, Loss: 0.1866\n",
      "Epoch 4, Batch 220/5867, Loss: 0.3007\n",
      "Epoch 4, Batch 230/5867, Loss: 0.2772\n",
      "Epoch 4, Batch 240/5867, Loss: 0.2763\n",
      "Epoch 4, Batch 250/5867, Loss: 0.1333\n",
      "Epoch 4, Batch 260/5867, Loss: 0.1843\n",
      "Epoch 4, Batch 270/5867, Loss: 0.1719\n",
      "Epoch 4, Batch 280/5867, Loss: 0.0816\n",
      "Epoch 4, Batch 290/5867, Loss: 0.2195\n",
      "Epoch 4, Batch 300/5867, Loss: 0.1885\n",
      "Epoch 4, Batch 310/5867, Loss: 0.2402\n",
      "Epoch 4, Batch 320/5867, Loss: 0.0991\n",
      "Epoch 4, Batch 330/5867, Loss: 0.1632\n",
      "Epoch 4, Batch 340/5867, Loss: 0.1291\n",
      "Epoch 4, Batch 350/5867, Loss: 0.2878\n",
      "Epoch 4, Batch 360/5867, Loss: 0.3620\n",
      "Epoch 4, Batch 370/5867, Loss: 0.2615\n",
      "Epoch 4, Batch 380/5867, Loss: 0.3376\n",
      "Epoch 4, Batch 390/5867, Loss: 0.1059\n",
      "Epoch 4, Batch 400/5867, Loss: 0.2830\n",
      "Epoch 4, Batch 410/5867, Loss: 0.2220\n",
      "Epoch 4, Batch 420/5867, Loss: 0.1548\n",
      "Epoch 4, Batch 430/5867, Loss: 0.1161\n",
      "Epoch 4, Batch 440/5867, Loss: 0.0709\n",
      "Epoch 4, Batch 450/5867, Loss: 0.2564\n",
      "Epoch 4, Batch 460/5867, Loss: 0.2906\n",
      "Epoch 4, Batch 470/5867, Loss: 0.1506\n",
      "Epoch 4, Batch 480/5867, Loss: 0.1401\n",
      "Epoch 4, Batch 490/5867, Loss: 0.3158\n",
      "Epoch 4, Batch 500/5867, Loss: 0.1594\n",
      "Epoch 4, Batch 510/5867, Loss: 0.1467\n",
      "Epoch 4, Batch 520/5867, Loss: 0.2289\n",
      "Epoch 4, Batch 530/5867, Loss: 0.2277\n",
      "Epoch 4, Batch 540/5867, Loss: 0.2529\n",
      "Epoch 4, Batch 550/5867, Loss: 0.1919\n",
      "Epoch 4, Batch 560/5867, Loss: 0.1504\n",
      "Epoch 4, Batch 570/5867, Loss: 0.2352\n",
      "Epoch 4, Batch 580/5867, Loss: 0.1377\n",
      "Epoch 4, Batch 590/5867, Loss: 0.3213\n",
      "Epoch 4, Batch 600/5867, Loss: 0.1116\n",
      "Epoch 4, Batch 610/5867, Loss: 0.2271\n",
      "Epoch 4, Batch 620/5867, Loss: 0.3131\n",
      "Epoch 4, Batch 630/5867, Loss: 0.1150\n",
      "Epoch 4, Batch 640/5867, Loss: 0.1067\n",
      "Epoch 4, Batch 650/5867, Loss: 0.0879\n",
      "Epoch 4, Batch 660/5867, Loss: 0.0706\n",
      "Epoch 4, Batch 670/5867, Loss: 0.1318\n",
      "Epoch 4, Batch 680/5867, Loss: 0.3620\n",
      "Epoch 4, Batch 690/5867, Loss: 0.1216\n",
      "Epoch 4, Batch 700/5867, Loss: 0.1791\n",
      "Epoch 4, Batch 710/5867, Loss: 0.2499\n",
      "Epoch 4, Batch 720/5867, Loss: 0.1490\n",
      "Epoch 4, Batch 730/5867, Loss: 0.1091\n",
      "Epoch 4, Batch 740/5867, Loss: 0.1807\n",
      "Epoch 4, Batch 750/5867, Loss: 0.2167\n",
      "Epoch 4, Batch 760/5867, Loss: 0.1621\n",
      "Epoch 4, Batch 770/5867, Loss: 0.1525\n",
      "Epoch 4, Batch 780/5867, Loss: 0.1369\n",
      "Epoch 4, Batch 790/5867, Loss: 0.0550\n",
      "Epoch 4, Batch 800/5867, Loss: 0.2783\n",
      "Epoch 4, Batch 810/5867, Loss: 0.1121\n",
      "Epoch 4, Batch 820/5867, Loss: 0.2925\n",
      "Epoch 4, Batch 830/5867, Loss: 0.1247\n",
      "Epoch 4, Batch 840/5867, Loss: 0.1300\n",
      "Epoch 4, Batch 850/5867, Loss: 0.2193\n",
      "Epoch 4, Batch 860/5867, Loss: 0.1191\n",
      "Epoch 4, Batch 870/5867, Loss: 0.1178\n",
      "Epoch 4, Batch 880/5867, Loss: 0.1055\n",
      "Epoch 4, Batch 890/5867, Loss: 0.1377\n",
      "Epoch 4, Batch 900/5867, Loss: 0.3144\n",
      "Epoch 4, Batch 910/5867, Loss: 0.0639\n",
      "Epoch 4, Batch 920/5867, Loss: 0.1597\n",
      "Epoch 4, Batch 930/5867, Loss: 0.1262\n",
      "Epoch 4, Batch 940/5867, Loss: 0.2333\n",
      "Epoch 4, Batch 950/5867, Loss: 0.1742\n",
      "Epoch 4, Batch 960/5867, Loss: 0.1436\n",
      "Epoch 4, Batch 970/5867, Loss: 0.2953\n",
      "Epoch 4, Batch 980/5867, Loss: 0.1721\n",
      "Epoch 4, Batch 990/5867, Loss: 0.0686\n",
      "Epoch 4, Batch 1000/5867, Loss: 0.2151\n",
      "Epoch 4, Batch 1010/5867, Loss: 0.1803\n",
      "Epoch 4, Batch 1020/5867, Loss: 0.2277\n",
      "Epoch 4, Batch 1030/5867, Loss: 0.1024\n",
      "Epoch 4, Batch 1040/5867, Loss: 0.1316\n",
      "Epoch 4, Batch 1050/5867, Loss: 0.1510\n",
      "Epoch 4, Batch 1060/5867, Loss: 0.1139\n",
      "Epoch 4, Batch 1070/5867, Loss: 0.1849\n",
      "Epoch 4, Batch 1080/5867, Loss: 0.2106\n",
      "Epoch 4, Batch 1090/5867, Loss: 0.3368\n",
      "Epoch 4, Batch 1100/5867, Loss: 0.2398\n",
      "Epoch 4, Batch 1110/5867, Loss: 0.2747\n",
      "Epoch 4, Batch 1120/5867, Loss: 0.2065\n",
      "Epoch 4, Batch 1130/5867, Loss: 0.1459\n",
      "Epoch 4, Batch 1140/5867, Loss: 0.1193\n",
      "Epoch 4, Batch 1150/5867, Loss: 0.1999\n",
      "Epoch 4, Batch 1160/5867, Loss: 0.0927\n",
      "Epoch 4, Batch 1170/5867, Loss: 0.1796\n",
      "Epoch 4, Batch 1180/5867, Loss: 0.1079\n",
      "Epoch 4, Batch 1190/5867, Loss: 0.2807\n",
      "Epoch 4, Batch 1200/5867, Loss: 0.1638\n",
      "Epoch 4, Batch 1210/5867, Loss: 0.1313\n",
      "Epoch 4, Batch 1220/5867, Loss: 0.1218\n",
      "Epoch 4, Batch 1230/5867, Loss: 0.1033\n",
      "Epoch 4, Batch 1240/5867, Loss: 0.0792\n",
      "Epoch 4, Batch 1250/5867, Loss: 0.1881\n",
      "Epoch 4, Batch 1260/5867, Loss: 0.2271\n",
      "Epoch 4, Batch 1270/5867, Loss: 0.1909\n",
      "Epoch 4, Batch 1280/5867, Loss: 0.2080\n",
      "Epoch 4, Batch 1290/5867, Loss: 0.0922\n",
      "Epoch 4, Batch 1300/5867, Loss: 0.2438\n",
      "Epoch 4, Batch 1310/5867, Loss: 0.1827\n",
      "Epoch 4, Batch 1320/5867, Loss: 0.2614\n",
      "Epoch 4, Batch 1330/5867, Loss: 0.1507\n",
      "Epoch 4, Batch 1340/5867, Loss: 0.2614\n",
      "Epoch 4, Batch 1350/5867, Loss: 0.1599\n",
      "Epoch 4, Batch 1360/5867, Loss: 0.2812\n",
      "Epoch 4, Batch 1370/5867, Loss: 0.3778\n",
      "Epoch 4, Batch 1380/5867, Loss: 0.0330\n",
      "Epoch 4, Batch 1390/5867, Loss: 0.2828\n",
      "Epoch 4, Batch 1400/5867, Loss: 0.2003\n",
      "Epoch 4, Batch 1410/5867, Loss: 0.0745\n",
      "Epoch 4, Batch 1420/5867, Loss: 0.1611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 1430/5867, Loss: 0.1198\n",
      "Epoch 4, Batch 1440/5867, Loss: 0.1869\n",
      "Epoch 4, Batch 1450/5867, Loss: 0.1026\n",
      "Epoch 4, Batch 1460/5867, Loss: 0.3708\n",
      "Epoch 4, Batch 1470/5867, Loss: 0.3422\n",
      "Epoch 4, Batch 1480/5867, Loss: 0.2441\n",
      "Epoch 4, Batch 1490/5867, Loss: 0.0205\n",
      "Epoch 4, Batch 1500/5867, Loss: 0.1765\n",
      "Epoch 4, Batch 1510/5867, Loss: 0.1509\n",
      "Epoch 4, Batch 1520/5867, Loss: 0.2275\n",
      "Epoch 4, Batch 1530/5867, Loss: 0.1800\n",
      "Epoch 4, Batch 1540/5867, Loss: 0.0767\n",
      "Epoch 4, Batch 1550/5867, Loss: 0.2151\n",
      "Epoch 4, Batch 1560/5867, Loss: 0.1777\n",
      "Epoch 4, Batch 1570/5867, Loss: 0.3360\n",
      "Epoch 4, Batch 1580/5867, Loss: 0.1857\n",
      "Epoch 4, Batch 1590/5867, Loss: 0.1918\n",
      "Epoch 4, Batch 1600/5867, Loss: 0.1653\n",
      "Epoch 4, Batch 1610/5867, Loss: 0.1010\n",
      "Epoch 4, Batch 1620/5867, Loss: 0.1356\n",
      "Epoch 4, Batch 1630/5867, Loss: 0.0798\n",
      "Epoch 4, Batch 1640/5867, Loss: 0.2021\n",
      "Epoch 4, Batch 1650/5867, Loss: 0.1680\n",
      "Epoch 4, Batch 1660/5867, Loss: 0.1523\n",
      "Epoch 4, Batch 1670/5867, Loss: 0.1992\n",
      "Epoch 4, Batch 1680/5867, Loss: 0.0918\n",
      "Epoch 4, Batch 1690/5867, Loss: 0.2161\n",
      "Epoch 4, Batch 1700/5867, Loss: 0.1478\n",
      "Epoch 4, Batch 1710/5867, Loss: 0.1308\n",
      "Epoch 4, Batch 1720/5867, Loss: 0.2030\n",
      "Epoch 4, Batch 1730/5867, Loss: 0.3311\n",
      "Epoch 4, Batch 1740/5867, Loss: 0.2217\n",
      "Epoch 4, Batch 1750/5867, Loss: 0.2595\n",
      "Epoch 4, Batch 1760/5867, Loss: 0.1775\n",
      "Epoch 4, Batch 1770/5867, Loss: 0.1322\n",
      "Epoch 4, Batch 1780/5867, Loss: 0.1942\n",
      "Epoch 4, Batch 1790/5867, Loss: 0.0532\n",
      "Epoch 4, Batch 1800/5867, Loss: 0.2135\n",
      "Epoch 4, Batch 1810/5867, Loss: 0.1807\n",
      "Epoch 4, Batch 1820/5867, Loss: 0.2339\n",
      "Epoch 4, Batch 1830/5867, Loss: 0.1161\n",
      "Epoch 4, Batch 1840/5867, Loss: 0.1076\n",
      "Epoch 4, Batch 1850/5867, Loss: 0.3172\n",
      "Epoch 4, Batch 1860/5867, Loss: 0.1714\n",
      "Epoch 4, Batch 1870/5867, Loss: 0.3365\n",
      "Epoch 4, Batch 1880/5867, Loss: 0.2524\n",
      "Epoch 4, Batch 1890/5867, Loss: 0.5601\n",
      "Epoch 4, Batch 1900/5867, Loss: 0.1949\n",
      "Epoch 4, Batch 1910/5867, Loss: 0.1101\n",
      "Epoch 4, Batch 1920/5867, Loss: 0.2197\n",
      "Epoch 4, Batch 1930/5867, Loss: 0.1938\n",
      "Epoch 4, Batch 1940/5867, Loss: 0.2052\n",
      "Epoch 4, Batch 1950/5867, Loss: 0.1692\n",
      "Epoch 4, Batch 1960/5867, Loss: 0.1620\n",
      "Epoch 4, Batch 1970/5867, Loss: 0.1923\n",
      "Epoch 4, Batch 1980/5867, Loss: 0.1167\n",
      "Epoch 4, Batch 1990/5867, Loss: 0.1079\n",
      "Epoch 4, Batch 2000/5867, Loss: 0.4302\n",
      "Epoch 4, Batch 2010/5867, Loss: 0.1492\n",
      "Epoch 4, Batch 2020/5867, Loss: 0.3218\n",
      "Epoch 4, Batch 2030/5867, Loss: 0.3127\n",
      "Epoch 4, Batch 2040/5867, Loss: 0.3339\n",
      "Epoch 4, Batch 2050/5867, Loss: 0.1755\n",
      "Epoch 4, Batch 2060/5867, Loss: 0.2540\n",
      "Epoch 4, Batch 2070/5867, Loss: 0.1526\n",
      "Epoch 4, Batch 2080/5867, Loss: 0.3643\n",
      "Epoch 4, Batch 2090/5867, Loss: 0.2387\n",
      "Epoch 4, Batch 2100/5867, Loss: 0.1287\n",
      "Epoch 4, Batch 2110/5867, Loss: 0.1491\n",
      "Epoch 4, Batch 2120/5867, Loss: 0.1462\n",
      "Epoch 4, Batch 2130/5867, Loss: 0.1094\n",
      "Epoch 4, Batch 2140/5867, Loss: 0.3093\n",
      "Epoch 4, Batch 2150/5867, Loss: 0.1972\n",
      "Epoch 4, Batch 2160/5867, Loss: 0.1662\n",
      "Epoch 4, Batch 2170/5867, Loss: 0.3309\n",
      "Epoch 4, Batch 2180/5867, Loss: 0.2558\n",
      "Epoch 4, Batch 2190/5867, Loss: 0.1640\n",
      "Epoch 4, Batch 2200/5867, Loss: 0.2077\n",
      "Epoch 4, Batch 2210/5867, Loss: 0.1069\n",
      "Epoch 4, Batch 2220/5867, Loss: 0.3072\n",
      "Epoch 4, Batch 2230/5867, Loss: 0.1711\n",
      "Epoch 4, Batch 2240/5867, Loss: 0.2562\n",
      "Epoch 4, Batch 2250/5867, Loss: 0.2264\n",
      "Epoch 4, Batch 2260/5867, Loss: 0.3195\n",
      "Epoch 4, Batch 2270/5867, Loss: 0.1418\n",
      "Epoch 4, Batch 2280/5867, Loss: 0.1753\n",
      "Epoch 4, Batch 2290/5867, Loss: 0.1360\n",
      "Epoch 4, Batch 2300/5867, Loss: 0.2679\n",
      "Epoch 4, Batch 2310/5867, Loss: 0.1336\n",
      "Epoch 4, Batch 2320/5867, Loss: 0.3591\n",
      "Epoch 4, Batch 2330/5867, Loss: 0.1192\n",
      "Epoch 4, Batch 2340/5867, Loss: 0.1125\n",
      "Epoch 4, Batch 2350/5867, Loss: 0.2402\n",
      "Epoch 4, Batch 2360/5867, Loss: 0.1862\n",
      "Epoch 4, Batch 2370/5867, Loss: 0.1731\n",
      "Epoch 4, Batch 2380/5867, Loss: 0.2838\n",
      "Epoch 4, Batch 2390/5867, Loss: 0.1951\n",
      "Epoch 4, Batch 2400/5867, Loss: 0.2403\n",
      "Epoch 4, Batch 2410/5867, Loss: 0.0785\n",
      "Epoch 4, Batch 2420/5867, Loss: 0.2905\n",
      "Epoch 4, Batch 2430/5867, Loss: 0.2538\n",
      "Epoch 4, Batch 2440/5867, Loss: 0.2083\n",
      "Epoch 4, Batch 2450/5867, Loss: 0.1281\n",
      "Epoch 4, Batch 2460/5867, Loss: 0.2427\n",
      "Epoch 4, Batch 2470/5867, Loss: 0.3529\n",
      "Epoch 4, Batch 2480/5867, Loss: 0.3095\n",
      "Epoch 4, Batch 2490/5867, Loss: 0.1527\n",
      "Epoch 4, Batch 2500/5867, Loss: 0.1319\n",
      "Epoch 4, Batch 2510/5867, Loss: 0.1644\n",
      "Epoch 4, Batch 2520/5867, Loss: 0.1870\n",
      "Epoch 4, Batch 2530/5867, Loss: 0.1558\n",
      "Epoch 4, Batch 2540/5867, Loss: 0.1981\n",
      "Epoch 4, Batch 2550/5867, Loss: 0.2842\n",
      "Epoch 4, Batch 2560/5867, Loss: 0.3995\n",
      "Epoch 4, Batch 2570/5867, Loss: 0.1630\n",
      "Epoch 4, Batch 2580/5867, Loss: 0.1555\n",
      "Epoch 4, Batch 2590/5867, Loss: 0.2511\n",
      "Epoch 4, Batch 2600/5867, Loss: 0.2342\n",
      "Epoch 4, Batch 2610/5867, Loss: 0.3059\n",
      "Epoch 4, Batch 2620/5867, Loss: 0.2077\n",
      "Epoch 4, Batch 2630/5867, Loss: 0.1926\n",
      "Epoch 4, Batch 2640/5867, Loss: 0.1209\n",
      "Epoch 4, Batch 2650/5867, Loss: 0.2252\n",
      "Epoch 4, Batch 2660/5867, Loss: 0.1330\n",
      "Epoch 4, Batch 2670/5867, Loss: 0.1622\n",
      "Epoch 4, Batch 2680/5867, Loss: 0.3275\n",
      "Epoch 4, Batch 2690/5867, Loss: 0.1460\n",
      "Epoch 4, Batch 2700/5867, Loss: 0.0528\n",
      "Epoch 4, Batch 2710/5867, Loss: 0.2178\n",
      "Epoch 4, Batch 2720/5867, Loss: 0.2227\n",
      "Epoch 4, Batch 2730/5867, Loss: 0.2068\n",
      "Epoch 4, Batch 2740/5867, Loss: 0.1435\n",
      "Epoch 4, Batch 2750/5867, Loss: 0.1680\n",
      "Epoch 4, Batch 2760/5867, Loss: 0.1737\n",
      "Epoch 4, Batch 2770/5867, Loss: 0.4439\n",
      "Epoch 4, Batch 2780/5867, Loss: 0.1442\n",
      "Epoch 4, Batch 2790/5867, Loss: 0.1505\n",
      "Epoch 4, Batch 2800/5867, Loss: 0.1372\n",
      "Epoch 4, Batch 2810/5867, Loss: 0.1191\n",
      "Epoch 4, Batch 2820/5867, Loss: 0.1185\n",
      "Epoch 4, Batch 2830/5867, Loss: 0.2003\n",
      "Epoch 4, Batch 2840/5867, Loss: 0.2147\n",
      "Epoch 4, Batch 2850/5867, Loss: 0.1041\n",
      "Epoch 4, Batch 2860/5867, Loss: 0.2321\n",
      "Epoch 4, Batch 2870/5867, Loss: 0.2693\n",
      "Epoch 4, Batch 2880/5867, Loss: 0.2216\n",
      "Epoch 4, Batch 2890/5867, Loss: 0.2535\n",
      "Epoch 4, Batch 2900/5867, Loss: 0.1938\n",
      "Epoch 4, Batch 2910/5867, Loss: 0.1710\n",
      "Epoch 4, Batch 2920/5867, Loss: 0.1379\n",
      "Epoch 4, Batch 2930/5867, Loss: 0.2010\n",
      "Epoch 4, Batch 2940/5867, Loss: 0.1275\n",
      "Epoch 4, Batch 2950/5867, Loss: 0.1388\n",
      "Epoch 4, Batch 2960/5867, Loss: 0.2076\n",
      "Epoch 4, Batch 2970/5867, Loss: 0.1772\n",
      "Epoch 4, Batch 2980/5867, Loss: 0.3021\n",
      "Epoch 4, Batch 2990/5867, Loss: 0.2025\n",
      "Epoch 4, Batch 3000/5867, Loss: 0.2493\n",
      "Epoch 4, Batch 3010/5867, Loss: 0.1083\n",
      "Epoch 4, Batch 3020/5867, Loss: 0.2258\n",
      "Epoch 4, Batch 3030/5867, Loss: 0.2345\n",
      "Epoch 4, Batch 3040/5867, Loss: 0.1366\n",
      "Epoch 4, Batch 3050/5867, Loss: 0.2277\n",
      "Epoch 4, Batch 3060/5867, Loss: 0.2781\n",
      "Epoch 4, Batch 3070/5867, Loss: 0.1291\n",
      "Epoch 4, Batch 3080/5867, Loss: 0.2870\n",
      "Epoch 4, Batch 3090/5867, Loss: 0.1094\n",
      "Epoch 4, Batch 3100/5867, Loss: 0.2027\n",
      "Epoch 4, Batch 3110/5867, Loss: 0.3490\n",
      "Epoch 4, Batch 3120/5867, Loss: 0.1630\n",
      "Epoch 4, Batch 3130/5867, Loss: 0.2891\n",
      "Epoch 4, Batch 3140/5867, Loss: 0.1493\n",
      "Epoch 4, Batch 3150/5867, Loss: 0.1979\n",
      "Epoch 4, Batch 3160/5867, Loss: 0.3022\n",
      "Epoch 4, Batch 3170/5867, Loss: 0.1719\n",
      "Epoch 4, Batch 3180/5867, Loss: 0.1380\n",
      "Epoch 4, Batch 3190/5867, Loss: 0.1593\n",
      "Epoch 4, Batch 3200/5867, Loss: 0.2526\n",
      "Epoch 4, Batch 3210/5867, Loss: 0.3477\n",
      "Epoch 4, Batch 3220/5867, Loss: 0.1399\n",
      "Epoch 4, Batch 3230/5867, Loss: 0.0958\n",
      "Epoch 4, Batch 3240/5867, Loss: 0.1870\n",
      "Epoch 4, Batch 3250/5867, Loss: 0.1125\n",
      "Epoch 4, Batch 3260/5867, Loss: 0.1920\n",
      "Epoch 4, Batch 3270/5867, Loss: 0.2791\n",
      "Epoch 4, Batch 3280/5867, Loss: 0.1677\n",
      "Epoch 4, Batch 3290/5867, Loss: 0.1366\n",
      "Epoch 4, Batch 3300/5867, Loss: 0.3687\n",
      "Epoch 4, Batch 3310/5867, Loss: 0.1991\n",
      "Epoch 4, Batch 3320/5867, Loss: 0.2422\n",
      "Epoch 4, Batch 3330/5867, Loss: 0.0829\n",
      "Epoch 4, Batch 3340/5867, Loss: 0.2165\n",
      "Epoch 4, Batch 3350/5867, Loss: 0.1327\n",
      "Epoch 4, Batch 3360/5867, Loss: 0.1401\n",
      "Epoch 4, Batch 3370/5867, Loss: 0.2466\n",
      "Epoch 4, Batch 3380/5867, Loss: 0.2025\n",
      "Epoch 4, Batch 3390/5867, Loss: 0.0816\n",
      "Epoch 4, Batch 3400/5867, Loss: 0.1891\n",
      "Epoch 4, Batch 3410/5867, Loss: 0.0543\n",
      "Epoch 4, Batch 3420/5867, Loss: 0.2772\n",
      "Epoch 4, Batch 3430/5867, Loss: 0.1161\n",
      "Epoch 4, Batch 3440/5867, Loss: 0.1968\n",
      "Epoch 4, Batch 3450/5867, Loss: 0.3084\n",
      "Epoch 4, Batch 3460/5867, Loss: 0.2347\n",
      "Epoch 4, Batch 3470/5867, Loss: 0.1231\n",
      "Epoch 4, Batch 3480/5867, Loss: 0.1396\n",
      "Epoch 4, Batch 3490/5867, Loss: 0.1691\n",
      "Epoch 4, Batch 3500/5867, Loss: 0.1286\n",
      "Epoch 4, Batch 3510/5867, Loss: 0.1632\n",
      "Epoch 4, Batch 3520/5867, Loss: 0.2590\n",
      "Epoch 4, Batch 3530/5867, Loss: 0.1350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 3540/5867, Loss: 0.3056\n",
      "Epoch 4, Batch 3550/5867, Loss: 0.0829\n",
      "Epoch 4, Batch 3560/5867, Loss: 0.3828\n",
      "Epoch 4, Batch 3570/5867, Loss: 0.2018\n",
      "Epoch 4, Batch 3580/5867, Loss: 0.1761\n",
      "Epoch 4, Batch 3590/5867, Loss: 0.2237\n",
      "Epoch 4, Batch 3600/5867, Loss: 0.2914\n",
      "Epoch 4, Batch 3610/5867, Loss: 0.2623\n",
      "Epoch 4, Batch 3620/5867, Loss: 0.1620\n",
      "Epoch 4, Batch 3630/5867, Loss: 0.1525\n",
      "Epoch 4, Batch 3640/5867, Loss: 0.4112\n",
      "Epoch 4, Batch 3650/5867, Loss: 0.2724\n",
      "Epoch 4, Batch 3660/5867, Loss: 0.0883\n",
      "Epoch 4, Batch 3670/5867, Loss: 0.1156\n",
      "Epoch 4, Batch 3680/5867, Loss: 0.2119\n",
      "Epoch 4, Batch 3690/5867, Loss: 0.1650\n",
      "Epoch 4, Batch 3700/5867, Loss: 0.1638\n",
      "Epoch 4, Batch 3710/5867, Loss: 0.0991\n",
      "Epoch 4, Batch 3720/5867, Loss: 0.1974\n",
      "Epoch 4, Batch 3730/5867, Loss: 0.1551\n",
      "Epoch 4, Batch 3740/5867, Loss: 0.3203\n",
      "Epoch 4, Batch 3750/5867, Loss: 0.1587\n",
      "Epoch 4, Batch 3760/5867, Loss: 0.1277\n",
      "Epoch 4, Batch 3770/5867, Loss: 0.2673\n",
      "Epoch 4, Batch 3780/5867, Loss: 0.2704\n",
      "Epoch 4, Batch 3790/5867, Loss: 0.1856\n",
      "Epoch 4, Batch 3800/5867, Loss: 0.1994\n",
      "Epoch 4, Batch 3810/5867, Loss: 0.1705\n",
      "Epoch 4, Batch 3820/5867, Loss: 0.2575\n",
      "Epoch 4, Batch 3830/5867, Loss: 0.2986\n",
      "Epoch 4, Batch 3840/5867, Loss: 0.1177\n",
      "Epoch 4, Batch 3850/5867, Loss: 0.1240\n",
      "Epoch 4, Batch 3860/5867, Loss: 0.1293\n",
      "Epoch 4, Batch 3870/5867, Loss: 0.3427\n",
      "Epoch 4, Batch 3880/5867, Loss: 0.0957\n",
      "Epoch 4, Batch 3890/5867, Loss: 0.1267\n",
      "Epoch 4, Batch 3900/5867, Loss: 0.1188\n",
      "Epoch 4, Batch 3910/5867, Loss: 0.2030\n",
      "Epoch 4, Batch 3920/5867, Loss: 0.1163\n",
      "Epoch 4, Batch 3930/5867, Loss: 0.2355\n",
      "Epoch 4, Batch 3940/5867, Loss: 0.1281\n",
      "Epoch 4, Batch 3950/5867, Loss: 0.1903\n",
      "Epoch 4, Batch 3960/5867, Loss: 0.1111\n",
      "Epoch 4, Batch 3970/5867, Loss: 0.2807\n",
      "Epoch 4, Batch 3980/5867, Loss: 0.1088\n",
      "Epoch 4, Batch 3990/5867, Loss: 0.4390\n",
      "Epoch 4, Batch 4000/5867, Loss: 0.1606\n",
      "Epoch 4, Batch 4010/5867, Loss: 0.2173\n",
      "Epoch 4, Batch 4020/5867, Loss: 0.3422\n",
      "Epoch 4, Batch 4030/5867, Loss: 0.3437\n",
      "Epoch 4, Batch 4040/5867, Loss: 0.2049\n",
      "Epoch 4, Batch 4050/5867, Loss: 0.2208\n",
      "Epoch 4, Batch 4060/5867, Loss: 0.2898\n",
      "Epoch 4, Batch 4070/5867, Loss: 0.2529\n",
      "Epoch 4, Batch 4080/5867, Loss: 0.2740\n",
      "Epoch 4, Batch 4090/5867, Loss: 0.2350\n",
      "Epoch 4, Batch 4100/5867, Loss: 0.3661\n",
      "Epoch 4, Batch 4110/5867, Loss: 0.1357\n",
      "Epoch 4, Batch 4120/5867, Loss: 0.1191\n",
      "Epoch 4, Batch 4130/5867, Loss: 0.0709\n",
      "Epoch 4, Batch 4140/5867, Loss: 0.3487\n",
      "Epoch 4, Batch 4150/5867, Loss: 0.1729\n",
      "Epoch 4, Batch 4160/5867, Loss: 0.3280\n",
      "Epoch 4, Batch 4170/5867, Loss: 0.1940\n",
      "Epoch 4, Batch 4180/5867, Loss: 0.3803\n",
      "Epoch 4, Batch 4190/5867, Loss: 0.3123\n",
      "Epoch 4, Batch 4200/5867, Loss: 0.1087\n",
      "Epoch 4, Batch 4210/5867, Loss: 0.1921\n",
      "Epoch 4, Batch 4220/5867, Loss: 0.1693\n",
      "Epoch 4, Batch 4230/5867, Loss: 0.1666\n",
      "Epoch 4, Batch 4240/5867, Loss: 0.1653\n",
      "Epoch 4, Batch 4250/5867, Loss: 0.1085\n",
      "Epoch 4, Batch 4260/5867, Loss: 0.1811\n",
      "Epoch 4, Batch 4270/5867, Loss: 0.3512\n",
      "Epoch 4, Batch 4280/5867, Loss: 0.1218\n",
      "Epoch 4, Batch 4290/5867, Loss: 0.1624\n",
      "Epoch 4, Batch 4300/5867, Loss: 0.1797\n",
      "Epoch 4, Batch 4310/5867, Loss: 0.2242\n",
      "Epoch 4, Batch 4320/5867, Loss: 0.1795\n",
      "Epoch 4, Batch 4330/5867, Loss: 0.1217\n",
      "Epoch 4, Batch 4340/5867, Loss: 0.0850\n",
      "Epoch 4, Batch 4350/5867, Loss: 0.1981\n",
      "Epoch 4, Batch 4360/5867, Loss: 0.2357\n",
      "Epoch 4, Batch 4370/5867, Loss: 0.1480\n",
      "Epoch 4, Batch 4380/5867, Loss: 0.2735\n",
      "Epoch 4, Batch 4390/5867, Loss: 0.2000\n",
      "Epoch 4, Batch 4400/5867, Loss: 0.2371\n",
      "Epoch 4, Batch 4410/5867, Loss: 0.1292\n",
      "Epoch 4, Batch 4420/5867, Loss: 0.4087\n",
      "Epoch 4, Batch 4430/5867, Loss: 0.0582\n",
      "Epoch 4, Batch 4440/5867, Loss: 0.2519\n",
      "Epoch 4, Batch 4450/5867, Loss: 0.0587\n",
      "Epoch 4, Batch 4460/5867, Loss: 0.2478\n",
      "Epoch 4, Batch 4470/5867, Loss: 0.4092\n",
      "Epoch 4, Batch 4480/5867, Loss: 0.2599\n",
      "Epoch 4, Batch 4490/5867, Loss: 0.2026\n",
      "Epoch 4, Batch 4500/5867, Loss: 0.1690\n",
      "Epoch 4, Batch 4510/5867, Loss: 0.2566\n",
      "Epoch 4, Batch 4520/5867, Loss: 0.1777\n",
      "Epoch 4, Batch 4530/5867, Loss: 0.2356\n",
      "Epoch 4, Batch 4540/5867, Loss: 0.1391\n",
      "Epoch 4, Batch 4550/5867, Loss: 0.1061\n",
      "Epoch 4, Batch 4560/5867, Loss: 0.0843\n",
      "Epoch 4, Batch 4570/5867, Loss: 0.2947\n",
      "Epoch 4, Batch 4580/5867, Loss: 0.1265\n",
      "Epoch 4, Batch 4590/5867, Loss: 0.3272\n",
      "Epoch 4, Batch 4600/5867, Loss: 0.1129\n",
      "Epoch 4, Batch 4610/5867, Loss: 0.1491\n",
      "Epoch 4, Batch 4620/5867, Loss: 0.1074\n",
      "Epoch 4, Batch 4630/5867, Loss: 0.3347\n",
      "Epoch 4, Batch 4640/5867, Loss: 0.1422\n",
      "Epoch 4, Batch 4650/5867, Loss: 0.1514\n",
      "Epoch 4, Batch 4660/5867, Loss: 0.2741\n",
      "Epoch 4, Batch 4670/5867, Loss: 0.1783\n",
      "Epoch 4, Batch 4680/5867, Loss: 0.1619\n",
      "Epoch 4, Batch 4690/5867, Loss: 0.1704\n",
      "Epoch 4, Batch 4700/5867, Loss: 0.1323\n",
      "Epoch 4, Batch 4710/5867, Loss: 0.2671\n",
      "Epoch 4, Batch 4720/5867, Loss: 0.3530\n",
      "Epoch 4, Batch 4730/5867, Loss: 0.3817\n",
      "Epoch 4, Batch 4740/5867, Loss: 0.1957\n",
      "Epoch 4, Batch 4750/5867, Loss: 0.4863\n",
      "Epoch 4, Batch 4760/5867, Loss: 0.3125\n",
      "Epoch 4, Batch 4770/5867, Loss: 0.2428\n",
      "Epoch 4, Batch 4780/5867, Loss: 0.1482\n",
      "Epoch 4, Batch 4790/5867, Loss: 0.2738\n",
      "Epoch 4, Batch 4800/5867, Loss: 0.1276\n",
      "Epoch 4, Batch 4810/5867, Loss: 0.2784\n",
      "Epoch 4, Batch 4820/5867, Loss: 0.1212\n",
      "Epoch 4, Batch 4830/5867, Loss: 0.2006\n",
      "Epoch 4, Batch 4840/5867, Loss: 0.1375\n",
      "Epoch 4, Batch 4850/5867, Loss: 0.2207\n",
      "Epoch 4, Batch 4860/5867, Loss: 0.1416\n",
      "Epoch 4, Batch 4870/5867, Loss: 0.1042\n",
      "Epoch 4, Batch 4880/5867, Loss: 0.1513\n",
      "Epoch 4, Batch 4890/5867, Loss: 0.2868\n",
      "Epoch 4, Batch 4900/5867, Loss: 0.2088\n",
      "Epoch 4, Batch 4910/5867, Loss: 0.1377\n",
      "Epoch 4, Batch 4920/5867, Loss: 0.3227\n",
      "Epoch 4, Batch 4930/5867, Loss: 0.2865\n",
      "Epoch 4, Batch 4940/5867, Loss: 0.3366\n",
      "Epoch 4, Batch 4950/5867, Loss: 0.1297\n",
      "Epoch 4, Batch 4960/5867, Loss: 0.0962\n",
      "Epoch 4, Batch 4970/5867, Loss: 0.1908\n",
      "Epoch 4, Batch 4980/5867, Loss: 0.2145\n",
      "Epoch 4, Batch 4990/5867, Loss: 0.0619\n",
      "Epoch 4, Batch 5000/5867, Loss: 0.2110\n",
      "Epoch 4, Batch 5010/5867, Loss: 0.2289\n",
      "Epoch 4, Batch 5020/5867, Loss: 0.2260\n",
      "Epoch 4, Batch 5030/5867, Loss: 0.2681\n",
      "Epoch 4, Batch 5040/5867, Loss: 0.2491\n",
      "Epoch 4, Batch 5050/5867, Loss: 0.1709\n",
      "Epoch 4, Batch 5060/5867, Loss: 0.1391\n",
      "Epoch 4, Batch 5070/5867, Loss: 0.2450\n",
      "Epoch 4, Batch 5080/5867, Loss: 0.0608\n",
      "Epoch 4, Batch 5090/5867, Loss: 0.2495\n",
      "Epoch 4, Batch 5100/5867, Loss: 0.2393\n",
      "Epoch 4, Batch 5110/5867, Loss: 0.2664\n",
      "Epoch 4, Batch 5120/5867, Loss: 0.1978\n",
      "Epoch 4, Batch 5130/5867, Loss: 0.1421\n",
      "Epoch 4, Batch 5140/5867, Loss: 0.0770\n",
      "Epoch 4, Batch 5150/5867, Loss: 0.2673\n",
      "Epoch 4, Batch 5160/5867, Loss: 0.0767\n",
      "Epoch 4, Batch 5170/5867, Loss: 0.3423\n",
      "Epoch 4, Batch 5180/5867, Loss: 0.2432\n",
      "Epoch 4, Batch 5190/5867, Loss: 0.0989\n",
      "Epoch 4, Batch 5200/5867, Loss: 0.1625\n",
      "Epoch 4, Batch 5210/5867, Loss: 0.1992\n",
      "Epoch 4, Batch 5220/5867, Loss: 0.1233\n",
      "Epoch 4, Batch 5230/5867, Loss: 0.2757\n",
      "Epoch 4, Batch 5240/5867, Loss: 0.2603\n",
      "Epoch 4, Batch 5250/5867, Loss: 0.3401\n",
      "Epoch 4, Batch 5260/5867, Loss: 0.3069\n",
      "Epoch 4, Batch 5270/5867, Loss: 0.3331\n",
      "Epoch 4, Batch 5280/5867, Loss: 0.2290\n",
      "Epoch 4, Batch 5290/5867, Loss: 0.3153\n",
      "Epoch 4, Batch 5300/5867, Loss: 0.0777\n",
      "Epoch 4, Batch 5310/5867, Loss: 0.1840\n",
      "Epoch 4, Batch 5320/5867, Loss: 0.2458\n",
      "Epoch 4, Batch 5330/5867, Loss: 0.3314\n",
      "Epoch 4, Batch 5340/5867, Loss: 0.1244\n",
      "Epoch 4, Batch 5350/5867, Loss: 0.2504\n",
      "Epoch 4, Batch 5360/5867, Loss: 0.1032\n",
      "Epoch 4, Batch 5370/5867, Loss: 0.1845\n",
      "Epoch 4, Batch 5380/5867, Loss: 0.2316\n",
      "Epoch 4, Batch 5390/5867, Loss: 0.0847\n",
      "Epoch 4, Batch 5400/5867, Loss: 0.2821\n",
      "Epoch 4, Batch 5410/5867, Loss: 0.2188\n",
      "Epoch 4, Batch 5420/5867, Loss: 0.3036\n",
      "Epoch 4, Batch 5430/5867, Loss: 0.2329\n",
      "Epoch 4, Batch 5440/5867, Loss: 0.1749\n",
      "Epoch 4, Batch 5450/5867, Loss: 0.1794\n",
      "Epoch 4, Batch 5460/5867, Loss: 0.1497\n",
      "Epoch 4, Batch 5470/5867, Loss: 0.1485\n",
      "Epoch 4, Batch 5480/5867, Loss: 0.2615\n",
      "Epoch 4, Batch 5490/5867, Loss: 0.1390\n",
      "Epoch 4, Batch 5500/5867, Loss: 0.4249\n",
      "Epoch 4, Batch 5510/5867, Loss: 0.1867\n",
      "Epoch 4, Batch 5520/5867, Loss: 0.3485\n",
      "Epoch 4, Batch 5530/5867, Loss: 0.4743\n",
      "Epoch 4, Batch 5540/5867, Loss: 0.1279\n",
      "Epoch 4, Batch 5550/5867, Loss: 0.1267\n",
      "Epoch 4, Batch 5560/5867, Loss: 0.2227\n",
      "Epoch 4, Batch 5570/5867, Loss: 0.0877\n",
      "Epoch 4, Batch 5580/5867, Loss: 0.2915\n",
      "Epoch 4, Batch 5590/5867, Loss: 0.1506\n",
      "Epoch 4, Batch 5600/5867, Loss: 0.3068\n",
      "Epoch 4, Batch 5610/5867, Loss: 0.1819\n",
      "Epoch 4, Batch 5620/5867, Loss: 0.1966\n",
      "Epoch 4, Batch 5630/5867, Loss: 0.1610\n",
      "Epoch 4, Batch 5640/5867, Loss: 0.2234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 5650/5867, Loss: 0.1548\n",
      "Epoch 4, Batch 5660/5867, Loss: 0.3159\n",
      "Epoch 4, Batch 5670/5867, Loss: 0.3726\n",
      "Epoch 4, Batch 5680/5867, Loss: 0.1645\n",
      "Epoch 4, Batch 5690/5867, Loss: 0.1789\n",
      "Epoch 4, Batch 5700/5867, Loss: 0.1528\n",
      "Epoch 4, Batch 5710/5867, Loss: 0.2938\n",
      "Epoch 4, Batch 5720/5867, Loss: 0.1986\n",
      "Epoch 4, Batch 5730/5867, Loss: 0.2337\n",
      "Epoch 4, Batch 5740/5867, Loss: 0.1815\n",
      "Epoch 4, Batch 5750/5867, Loss: 0.1323\n",
      "Epoch 4, Batch 5760/5867, Loss: 0.1144\n",
      "Epoch 4, Batch 5770/5867, Loss: 0.4745\n",
      "Epoch 4, Batch 5780/5867, Loss: 0.2205\n",
      "Epoch 4, Batch 5790/5867, Loss: 0.1861\n",
      "Epoch 4, Batch 5800/5867, Loss: 0.2342\n",
      "Epoch 4, Batch 5810/5867, Loss: 0.1551\n",
      "Epoch 4, Batch 5820/5867, Loss: 0.1045\n",
      "Epoch 4, Batch 5830/5867, Loss: 0.0531\n",
      "Epoch 4, Batch 5840/5867, Loss: 0.1895\n",
      "Epoch 4, Batch 5850/5867, Loss: 0.1744\n",
      "Epoch 4, Batch 5860/5867, Loss: 0.4458\n",
      "Epoch 4, Training Loss: 0.2018, Validation Loss: 0.1961\n",
      "Starting epoch 5...\n",
      "Epoch 5, Batch 10/5867, Loss: 0.2694\n",
      "Epoch 5, Batch 20/5867, Loss: 0.1037\n",
      "Epoch 5, Batch 30/5867, Loss: 0.2480\n",
      "Epoch 5, Batch 40/5867, Loss: 0.0728\n",
      "Epoch 5, Batch 50/5867, Loss: 0.2037\n",
      "Epoch 5, Batch 60/5867, Loss: 0.3323\n",
      "Epoch 5, Batch 70/5867, Loss: 0.1695\n",
      "Epoch 5, Batch 80/5867, Loss: 0.2198\n",
      "Epoch 5, Batch 90/5867, Loss: 0.2389\n",
      "Epoch 5, Batch 100/5867, Loss: 0.0923\n",
      "Epoch 5, Batch 110/5867, Loss: 0.2485\n",
      "Epoch 5, Batch 120/5867, Loss: 0.1476\n",
      "Epoch 5, Batch 130/5867, Loss: 0.1593\n",
      "Epoch 5, Batch 140/5867, Loss: 0.3264\n",
      "Epoch 5, Batch 150/5867, Loss: 0.2212\n",
      "Epoch 5, Batch 160/5867, Loss: 0.2320\n",
      "Epoch 5, Batch 170/5867, Loss: 0.3731\n",
      "Epoch 5, Batch 180/5867, Loss: 0.2473\n",
      "Epoch 5, Batch 190/5867, Loss: 0.0669\n",
      "Epoch 5, Batch 200/5867, Loss: 0.0766\n",
      "Epoch 5, Batch 210/5867, Loss: 0.1440\n",
      "Epoch 5, Batch 220/5867, Loss: 0.1523\n",
      "Epoch 5, Batch 230/5867, Loss: 0.1811\n",
      "Epoch 5, Batch 240/5867, Loss: 0.0784\n",
      "Epoch 5, Batch 250/5867, Loss: 0.0985\n",
      "Epoch 5, Batch 260/5867, Loss: 0.2639\n",
      "Epoch 5, Batch 270/5867, Loss: 0.1248\n",
      "Epoch 5, Batch 280/5867, Loss: 0.1433\n",
      "Epoch 5, Batch 290/5867, Loss: 0.2252\n",
      "Epoch 5, Batch 300/5867, Loss: 0.1461\n",
      "Epoch 5, Batch 310/5867, Loss: 0.3630\n",
      "Epoch 5, Batch 320/5867, Loss: 0.0935\n",
      "Epoch 5, Batch 330/5867, Loss: 0.0990\n",
      "Epoch 5, Batch 340/5867, Loss: 0.3597\n",
      "Epoch 5, Batch 350/5867, Loss: 0.2255\n",
      "Epoch 5, Batch 360/5867, Loss: 0.1902\n",
      "Epoch 5, Batch 370/5867, Loss: 0.1590\n",
      "Epoch 5, Batch 380/5867, Loss: 0.2289\n",
      "Epoch 5, Batch 390/5867, Loss: 0.2563\n",
      "Epoch 5, Batch 400/5867, Loss: 0.0803\n",
      "Epoch 5, Batch 410/5867, Loss: 0.1505\n",
      "Epoch 5, Batch 420/5867, Loss: 0.1341\n",
      "Epoch 5, Batch 430/5867, Loss: 0.2181\n",
      "Epoch 5, Batch 440/5867, Loss: 0.1972\n",
      "Epoch 5, Batch 450/5867, Loss: 0.1646\n",
      "Epoch 5, Batch 460/5867, Loss: 0.1268\n",
      "Epoch 5, Batch 470/5867, Loss: 0.1623\n",
      "Epoch 5, Batch 480/5867, Loss: 0.0839\n",
      "Epoch 5, Batch 490/5867, Loss: 0.0931\n",
      "Epoch 5, Batch 500/5867, Loss: 0.2032\n",
      "Epoch 5, Batch 510/5867, Loss: 0.3631\n",
      "Epoch 5, Batch 520/5867, Loss: 0.2428\n",
      "Epoch 5, Batch 530/5867, Loss: 0.2887\n",
      "Epoch 5, Batch 540/5867, Loss: 0.1044\n",
      "Epoch 5, Batch 550/5867, Loss: 0.1654\n",
      "Epoch 5, Batch 560/5867, Loss: 0.1630\n",
      "Epoch 5, Batch 570/5867, Loss: 0.2052\n",
      "Epoch 5, Batch 580/5867, Loss: 0.1410\n",
      "Epoch 5, Batch 590/5867, Loss: 0.1242\n",
      "Epoch 5, Batch 600/5867, Loss: 0.1775\n",
      "Epoch 5, Batch 610/5867, Loss: 0.2004\n",
      "Epoch 5, Batch 620/5867, Loss: 0.1063\n",
      "Epoch 5, Batch 630/5867, Loss: 0.2294\n",
      "Epoch 5, Batch 640/5867, Loss: 0.1259\n",
      "Epoch 5, Batch 650/5867, Loss: 0.1920\n",
      "Epoch 5, Batch 660/5867, Loss: 0.2229\n",
      "Epoch 5, Batch 670/5867, Loss: 0.1995\n",
      "Epoch 5, Batch 680/5867, Loss: 0.3543\n",
      "Epoch 5, Batch 690/5867, Loss: 0.1556\n",
      "Epoch 5, Batch 700/5867, Loss: 0.1759\n",
      "Epoch 5, Batch 710/5867, Loss: 0.2711\n",
      "Epoch 5, Batch 720/5867, Loss: 0.2419\n",
      "Epoch 5, Batch 730/5867, Loss: 0.0873\n",
      "Epoch 5, Batch 740/5867, Loss: 0.0239\n",
      "Epoch 5, Batch 750/5867, Loss: 0.1763\n",
      "Epoch 5, Batch 760/5867, Loss: 0.0583\n",
      "Epoch 5, Batch 770/5867, Loss: 0.1908\n",
      "Epoch 5, Batch 780/5867, Loss: 0.1248\n",
      "Epoch 5, Batch 790/5867, Loss: 0.2214\n",
      "Epoch 5, Batch 800/5867, Loss: 0.1878\n",
      "Epoch 5, Batch 810/5867, Loss: 0.1913\n",
      "Epoch 5, Batch 820/5867, Loss: 0.2467\n",
      "Epoch 5, Batch 830/5867, Loss: 0.0884\n",
      "Epoch 5, Batch 840/5867, Loss: 0.2410\n",
      "Epoch 5, Batch 850/5867, Loss: 0.2343\n",
      "Epoch 5, Batch 860/5867, Loss: 0.3308\n",
      "Epoch 5, Batch 870/5867, Loss: 0.3028\n",
      "Epoch 5, Batch 880/5867, Loss: 0.2059\n",
      "Epoch 5, Batch 890/5867, Loss: 0.1809\n",
      "Epoch 5, Batch 900/5867, Loss: 0.1064\n",
      "Epoch 5, Batch 910/5867, Loss: 0.1459\n",
      "Epoch 5, Batch 920/5867, Loss: 0.1707\n",
      "Epoch 5, Batch 930/5867, Loss: 0.1139\n",
      "Epoch 5, Batch 940/5867, Loss: 0.1749\n",
      "Epoch 5, Batch 950/5867, Loss: 0.3175\n",
      "Epoch 5, Batch 960/5867, Loss: 0.2502\n",
      "Epoch 5, Batch 970/5867, Loss: 0.1123\n",
      "Epoch 5, Batch 980/5867, Loss: 0.4763\n",
      "Epoch 5, Batch 990/5867, Loss: 0.2146\n",
      "Epoch 5, Batch 1000/5867, Loss: 0.1444\n",
      "Epoch 5, Batch 1010/5867, Loss: 0.1314\n",
      "Epoch 5, Batch 1020/5867, Loss: 0.1703\n",
      "Epoch 5, Batch 1030/5867, Loss: 0.1011\n",
      "Epoch 5, Batch 1040/5867, Loss: 0.1507\n",
      "Epoch 5, Batch 1050/5867, Loss: 0.2880\n",
      "Epoch 5, Batch 1060/5867, Loss: 0.3166\n",
      "Epoch 5, Batch 1070/5867, Loss: 0.1903\n",
      "Epoch 5, Batch 1080/5867, Loss: 0.1257\n",
      "Epoch 5, Batch 1090/5867, Loss: 0.1513\n",
      "Epoch 5, Batch 1100/5867, Loss: 0.0403\n",
      "Epoch 5, Batch 1110/5867, Loss: 0.1934\n",
      "Epoch 5, Batch 1120/5867, Loss: 0.3820\n",
      "Epoch 5, Batch 1130/5867, Loss: 0.0820\n",
      "Epoch 5, Batch 1140/5867, Loss: 0.1546\n",
      "Epoch 5, Batch 1150/5867, Loss: 0.2551\n",
      "Epoch 5, Batch 1160/5867, Loss: 0.1319\n",
      "Epoch 5, Batch 1170/5867, Loss: 0.3614\n",
      "Epoch 5, Batch 1180/5867, Loss: 0.3324\n",
      "Epoch 5, Batch 1190/5867, Loss: 0.2390\n",
      "Epoch 5, Batch 1200/5867, Loss: 0.1252\n",
      "Epoch 5, Batch 1210/5867, Loss: 0.2886\n",
      "Epoch 5, Batch 1220/5867, Loss: 0.3616\n",
      "Epoch 5, Batch 1230/5867, Loss: 0.0949\n",
      "Epoch 5, Batch 1240/5867, Loss: 0.2469\n",
      "Epoch 5, Batch 1250/5867, Loss: 0.2913\n",
      "Epoch 5, Batch 1260/5867, Loss: 0.1341\n",
      "Epoch 5, Batch 1270/5867, Loss: 0.1245\n",
      "Epoch 5, Batch 1280/5867, Loss: 0.4118\n",
      "Epoch 5, Batch 1290/5867, Loss: 0.1818\n",
      "Epoch 5, Batch 1300/5867, Loss: 0.2664\n",
      "Epoch 5, Batch 1310/5867, Loss: 0.2115\n",
      "Epoch 5, Batch 1320/5867, Loss: 0.4125\n",
      "Epoch 5, Batch 1330/5867, Loss: 0.1594\n",
      "Epoch 5, Batch 1340/5867, Loss: 0.1345\n",
      "Epoch 5, Batch 1350/5867, Loss: 0.0967\n",
      "Epoch 5, Batch 1360/5867, Loss: 0.1463\n",
      "Epoch 5, Batch 1370/5867, Loss: 0.1994\n",
      "Epoch 5, Batch 1380/5867, Loss: 0.1525\n",
      "Epoch 5, Batch 1390/5867, Loss: 0.2482\n",
      "Epoch 5, Batch 1400/5867, Loss: 0.1574\n",
      "Epoch 5, Batch 1410/5867, Loss: 0.2156\n",
      "Epoch 5, Batch 1420/5867, Loss: 0.2565\n",
      "Epoch 5, Batch 1430/5867, Loss: 0.2936\n",
      "Epoch 5, Batch 1440/5867, Loss: 0.1695\n",
      "Epoch 5, Batch 1450/5867, Loss: 0.1249\n",
      "Epoch 5, Batch 1460/5867, Loss: 0.1118\n",
      "Epoch 5, Batch 1470/5867, Loss: 0.3240\n",
      "Epoch 5, Batch 1480/5867, Loss: 0.3265\n",
      "Epoch 5, Batch 1490/5867, Loss: 0.0864\n",
      "Epoch 5, Batch 1500/5867, Loss: 0.0598\n",
      "Epoch 5, Batch 1510/5867, Loss: 0.1274\n",
      "Epoch 5, Batch 1520/5867, Loss: 0.1333\n",
      "Epoch 5, Batch 1530/5867, Loss: 0.1347\n",
      "Epoch 5, Batch 1540/5867, Loss: 0.0470\n",
      "Epoch 5, Batch 1550/5867, Loss: 0.1696\n",
      "Epoch 5, Batch 1560/5867, Loss: 0.0621\n",
      "Epoch 5, Batch 1570/5867, Loss: 0.2036\n",
      "Epoch 5, Batch 1580/5867, Loss: 0.2636\n",
      "Epoch 5, Batch 1590/5867, Loss: 0.3189\n",
      "Epoch 5, Batch 1600/5867, Loss: 0.2066\n",
      "Epoch 5, Batch 1610/5867, Loss: 0.2784\n",
      "Epoch 5, Batch 1620/5867, Loss: 0.3395\n",
      "Epoch 5, Batch 1630/5867, Loss: 0.1106\n",
      "Epoch 5, Batch 1640/5867, Loss: 0.2001\n",
      "Epoch 5, Batch 1650/5867, Loss: 0.1212\n",
      "Epoch 5, Batch 1660/5867, Loss: 0.2099\n",
      "Epoch 5, Batch 1670/5867, Loss: 0.0761\n",
      "Epoch 5, Batch 1680/5867, Loss: 0.0948\n",
      "Epoch 5, Batch 1690/5867, Loss: 0.4836\n",
      "Epoch 5, Batch 1700/5867, Loss: 0.1846\n",
      "Epoch 5, Batch 1710/5867, Loss: 0.1150\n",
      "Epoch 5, Batch 1720/5867, Loss: 0.2611\n",
      "Epoch 5, Batch 1730/5867, Loss: 0.1445\n",
      "Epoch 5, Batch 1740/5867, Loss: 0.2715\n",
      "Epoch 5, Batch 1750/5867, Loss: 0.1531\n",
      "Epoch 5, Batch 1760/5867, Loss: 0.1509\n",
      "Epoch 5, Batch 1770/5867, Loss: 0.3091\n",
      "Epoch 5, Batch 1780/5867, Loss: 0.2051\n",
      "Epoch 5, Batch 1790/5867, Loss: 0.1881\n",
      "Epoch 5, Batch 1800/5867, Loss: 0.0836\n",
      "Epoch 5, Batch 1810/5867, Loss: 0.3527\n",
      "Epoch 5, Batch 1820/5867, Loss: 0.1657\n",
      "Epoch 5, Batch 1830/5867, Loss: 0.1919\n",
      "Epoch 5, Batch 1840/5867, Loss: 0.1957\n",
      "Epoch 5, Batch 1850/5867, Loss: 0.1858\n",
      "Epoch 5, Batch 1860/5867, Loss: 0.1592\n",
      "Epoch 5, Batch 1870/5867, Loss: 0.0880\n",
      "Epoch 5, Batch 1880/5867, Loss: 0.2218\n",
      "Epoch 5, Batch 1890/5867, Loss: 0.1959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 1900/5867, Loss: 0.2853\n",
      "Epoch 5, Batch 1910/5867, Loss: 0.2262\n",
      "Epoch 5, Batch 1920/5867, Loss: 0.2301\n",
      "Epoch 5, Batch 1930/5867, Loss: 0.1759\n",
      "Epoch 5, Batch 1940/5867, Loss: 0.2170\n",
      "Epoch 5, Batch 1950/5867, Loss: 0.2690\n",
      "Epoch 5, Batch 1960/5867, Loss: 0.1663\n",
      "Epoch 5, Batch 1970/5867, Loss: 0.0922\n",
      "Epoch 5, Batch 1980/5867, Loss: 0.3740\n",
      "Epoch 5, Batch 1990/5867, Loss: 0.0970\n",
      "Epoch 5, Batch 2000/5867, Loss: 0.4238\n",
      "Epoch 5, Batch 2010/5867, Loss: 0.1619\n",
      "Epoch 5, Batch 2020/5867, Loss: 0.1167\n",
      "Epoch 5, Batch 2030/5867, Loss: 0.2206\n",
      "Epoch 5, Batch 2040/5867, Loss: 0.2193\n",
      "Epoch 5, Batch 2050/5867, Loss: 0.1605\n",
      "Epoch 5, Batch 2060/5867, Loss: 0.2200\n",
      "Epoch 5, Batch 2070/5867, Loss: 0.2539\n",
      "Epoch 5, Batch 2080/5867, Loss: 0.2079\n",
      "Epoch 5, Batch 2090/5867, Loss: 0.3716\n",
      "Epoch 5, Batch 2100/5867, Loss: 0.1716\n",
      "Epoch 5, Batch 2110/5867, Loss: 0.0903\n",
      "Epoch 5, Batch 2120/5867, Loss: 0.1650\n",
      "Epoch 5, Batch 2130/5867, Loss: 0.1035\n",
      "Epoch 5, Batch 2140/5867, Loss: 0.1966\n",
      "Epoch 5, Batch 2150/5867, Loss: 0.2025\n",
      "Epoch 5, Batch 2160/5867, Loss: 0.0813\n",
      "Epoch 5, Batch 2170/5867, Loss: 0.1232\n",
      "Epoch 5, Batch 2180/5867, Loss: 0.1921\n",
      "Epoch 5, Batch 2190/5867, Loss: 0.4188\n",
      "Epoch 5, Batch 2200/5867, Loss: 0.2231\n",
      "Epoch 5, Batch 2210/5867, Loss: 0.2310\n",
      "Epoch 5, Batch 2220/5867, Loss: 0.1168\n",
      "Epoch 5, Batch 2230/5867, Loss: 0.1602\n",
      "Epoch 5, Batch 2240/5867, Loss: 0.3007\n",
      "Epoch 5, Batch 2250/5867, Loss: 0.2877\n",
      "Epoch 5, Batch 2260/5867, Loss: 0.1893\n",
      "Epoch 5, Batch 2270/5867, Loss: 0.1840\n",
      "Epoch 5, Batch 2280/5867, Loss: 0.2060\n",
      "Epoch 5, Batch 2290/5867, Loss: 0.1137\n",
      "Epoch 5, Batch 2300/5867, Loss: 0.3535\n",
      "Epoch 5, Batch 2310/5867, Loss: 0.1042\n",
      "Epoch 5, Batch 2320/5867, Loss: 0.1250\n",
      "Epoch 5, Batch 2330/5867, Loss: 0.4494\n",
      "Epoch 5, Batch 2340/5867, Loss: 0.1789\n",
      "Epoch 5, Batch 2350/5867, Loss: 0.1102\n",
      "Epoch 5, Batch 2360/5867, Loss: 0.2949\n",
      "Epoch 5, Batch 2370/5867, Loss: 0.2417\n",
      "Epoch 5, Batch 2380/5867, Loss: 0.1978\n",
      "Epoch 5, Batch 2390/5867, Loss: 0.2271\n",
      "Epoch 5, Batch 2400/5867, Loss: 0.1899\n",
      "Epoch 5, Batch 2410/5867, Loss: 0.3515\n",
      "Epoch 5, Batch 2420/5867, Loss: 0.2457\n",
      "Epoch 5, Batch 2430/5867, Loss: 0.1432\n",
      "Epoch 5, Batch 2440/5867, Loss: 0.3589\n",
      "Epoch 5, Batch 2450/5867, Loss: 0.2031\n",
      "Epoch 5, Batch 2460/5867, Loss: 0.2688\n",
      "Epoch 5, Batch 2470/5867, Loss: 0.2972\n",
      "Epoch 5, Batch 2480/5867, Loss: 0.2411\n",
      "Epoch 5, Batch 2490/5867, Loss: 0.2027\n",
      "Epoch 5, Batch 2500/5867, Loss: 0.2700\n",
      "Epoch 5, Batch 2510/5867, Loss: 0.1556\n",
      "Epoch 5, Batch 2520/5867, Loss: 0.2071\n",
      "Epoch 5, Batch 2530/5867, Loss: 0.1402\n",
      "Epoch 5, Batch 2540/5867, Loss: 0.1779\n",
      "Epoch 5, Batch 2550/5867, Loss: 0.0472\n",
      "Epoch 5, Batch 2560/5867, Loss: 0.2146\n",
      "Epoch 5, Batch 2570/5867, Loss: 0.1684\n",
      "Epoch 5, Batch 2580/5867, Loss: 0.1150\n",
      "Epoch 5, Batch 2590/5867, Loss: 0.1592\n",
      "Epoch 5, Batch 2600/5867, Loss: 0.1743\n",
      "Epoch 5, Batch 2610/5867, Loss: 0.1672\n",
      "Epoch 5, Batch 2620/5867, Loss: 0.2256\n",
      "Epoch 5, Batch 2630/5867, Loss: 0.1309\n",
      "Epoch 5, Batch 2640/5867, Loss: 0.1185\n",
      "Epoch 5, Batch 2650/5867, Loss: 0.1844\n",
      "Epoch 5, Batch 2660/5867, Loss: 0.2045\n",
      "Epoch 5, Batch 2670/5867, Loss: 0.3522\n",
      "Epoch 5, Batch 2680/5867, Loss: 0.2375\n",
      "Epoch 5, Batch 2690/5867, Loss: 0.2812\n",
      "Epoch 5, Batch 2700/5867, Loss: 0.3630\n",
      "Epoch 5, Batch 2710/5867, Loss: 0.1595\n",
      "Epoch 5, Batch 2720/5867, Loss: 0.0630\n",
      "Epoch 5, Batch 2730/5867, Loss: 0.2002\n",
      "Epoch 5, Batch 2740/5867, Loss: 0.1331\n",
      "Epoch 5, Batch 2750/5867, Loss: 0.1611\n",
      "Epoch 5, Batch 2760/5867, Loss: 0.1986\n",
      "Epoch 5, Batch 2770/5867, Loss: 0.1521\n",
      "Epoch 5, Batch 2780/5867, Loss: 0.3260\n",
      "Epoch 5, Batch 2790/5867, Loss: 0.0742\n",
      "Epoch 5, Batch 2800/5867, Loss: 0.2261\n",
      "Epoch 5, Batch 2810/5867, Loss: 0.3473\n",
      "Epoch 5, Batch 2820/5867, Loss: 0.1342\n",
      "Epoch 5, Batch 2830/5867, Loss: 0.1359\n",
      "Epoch 5, Batch 2840/5867, Loss: 0.1818\n",
      "Epoch 5, Batch 2850/5867, Loss: 0.1465\n",
      "Epoch 5, Batch 2860/5867, Loss: 0.4451\n",
      "Epoch 5, Batch 2870/5867, Loss: 0.1288\n",
      "Epoch 5, Batch 2880/5867, Loss: 0.0990\n",
      "Epoch 5, Batch 2890/5867, Loss: 0.2522\n",
      "Epoch 5, Batch 2900/5867, Loss: 0.2951\n",
      "Epoch 5, Batch 2910/5867, Loss: 0.1417\n",
      "Epoch 5, Batch 2920/5867, Loss: 0.1551\n",
      "Epoch 5, Batch 2930/5867, Loss: 0.1865\n",
      "Epoch 5, Batch 2940/5867, Loss: 0.2537\n",
      "Epoch 5, Batch 2950/5867, Loss: 0.1738\n",
      "Epoch 5, Batch 2960/5867, Loss: 0.1835\n",
      "Epoch 5, Batch 2970/5867, Loss: 0.1595\n",
      "Epoch 5, Batch 2980/5867, Loss: 0.1463\n",
      "Epoch 5, Batch 2990/5867, Loss: 0.0670\n",
      "Epoch 5, Batch 3000/5867, Loss: 0.2725\n",
      "Epoch 5, Batch 3010/5867, Loss: 0.1329\n",
      "Epoch 5, Batch 3020/5867, Loss: 0.0982\n",
      "Epoch 5, Batch 3030/5867, Loss: 0.3004\n",
      "Epoch 5, Batch 3040/5867, Loss: 0.3197\n",
      "Epoch 5, Batch 3050/5867, Loss: 0.2167\n",
      "Epoch 5, Batch 3060/5867, Loss: 0.1646\n",
      "Epoch 5, Batch 3070/5867, Loss: 0.1572\n",
      "Epoch 5, Batch 3080/5867, Loss: 0.1628\n",
      "Epoch 5, Batch 3090/5867, Loss: 0.2189\n",
      "Epoch 5, Batch 3100/5867, Loss: 0.1707\n",
      "Epoch 5, Batch 3110/5867, Loss: 0.2316\n",
      "Epoch 5, Batch 3120/5867, Loss: 0.1212\n",
      "Epoch 5, Batch 3130/5867, Loss: 0.2482\n",
      "Epoch 5, Batch 3140/5867, Loss: 0.2528\n",
      "Epoch 5, Batch 3150/5867, Loss: 0.1712\n",
      "Epoch 5, Batch 3160/5867, Loss: 0.3223\n",
      "Epoch 5, Batch 3170/5867, Loss: 0.2526\n",
      "Epoch 5, Batch 3180/5867, Loss: 0.1267\n",
      "Epoch 5, Batch 3190/5867, Loss: 0.2081\n",
      "Epoch 5, Batch 3200/5867, Loss: 0.1168\n",
      "Epoch 5, Batch 3210/5867, Loss: 0.1692\n",
      "Epoch 5, Batch 3220/5867, Loss: 0.2153\n",
      "Epoch 5, Batch 3230/5867, Loss: 0.2366\n",
      "Epoch 5, Batch 3240/5867, Loss: 0.1047\n",
      "Epoch 5, Batch 3250/5867, Loss: 0.2152\n",
      "Epoch 5, Batch 3260/5867, Loss: 0.1828\n",
      "Epoch 5, Batch 3270/5867, Loss: 0.0909\n",
      "Epoch 5, Batch 3280/5867, Loss: 0.0912\n",
      "Epoch 5, Batch 3290/5867, Loss: 0.1071\n",
      "Epoch 5, Batch 3300/5867, Loss: 0.1734\n",
      "Epoch 5, Batch 3310/5867, Loss: 0.2580\n",
      "Epoch 5, Batch 3320/5867, Loss: 0.2198\n",
      "Epoch 5, Batch 3330/5867, Loss: 0.2763\n",
      "Epoch 5, Batch 3340/5867, Loss: 0.1408\n",
      "Epoch 5, Batch 3350/5867, Loss: 0.1754\n",
      "Epoch 5, Batch 3360/5867, Loss: 0.6567\n",
      "Epoch 5, Batch 3370/5867, Loss: 0.1537\n",
      "Epoch 5, Batch 3380/5867, Loss: 0.1165\n",
      "Epoch 5, Batch 3390/5867, Loss: 0.2545\n",
      "Epoch 5, Batch 3400/5867, Loss: 0.0760\n",
      "Epoch 5, Batch 3410/5867, Loss: 0.3306\n",
      "Epoch 5, Batch 3420/5867, Loss: 0.1840\n",
      "Epoch 5, Batch 3430/5867, Loss: 0.1834\n",
      "Epoch 5, Batch 3440/5867, Loss: 0.2997\n",
      "Epoch 5, Batch 3450/5867, Loss: 0.1256\n",
      "Epoch 5, Batch 3460/5867, Loss: 0.1533\n",
      "Epoch 5, Batch 3470/5867, Loss: 0.3933\n",
      "Epoch 5, Batch 3480/5867, Loss: 0.0436\n",
      "Epoch 5, Batch 3490/5867, Loss: 0.3608\n",
      "Epoch 5, Batch 3500/5867, Loss: 0.1691\n",
      "Epoch 5, Batch 3510/5867, Loss: 0.2055\n",
      "Epoch 5, Batch 3520/5867, Loss: 0.1699\n",
      "Epoch 5, Batch 3530/5867, Loss: 0.2448\n",
      "Epoch 5, Batch 3540/5867, Loss: 0.2073\n",
      "Epoch 5, Batch 3550/5867, Loss: 0.1454\n",
      "Epoch 5, Batch 3560/5867, Loss: 0.1792\n",
      "Epoch 5, Batch 3570/5867, Loss: 0.1233\n",
      "Epoch 5, Batch 3580/5867, Loss: 0.1378\n",
      "Epoch 5, Batch 3590/5867, Loss: 0.3071\n",
      "Epoch 5, Batch 3600/5867, Loss: 0.4278\n",
      "Epoch 5, Batch 3610/5867, Loss: 0.1179\n",
      "Epoch 5, Batch 3620/5867, Loss: 0.0689\n",
      "Epoch 5, Batch 3630/5867, Loss: 0.1379\n",
      "Epoch 5, Batch 3640/5867, Loss: 0.1547\n",
      "Epoch 5, Batch 3650/5867, Loss: 0.2214\n",
      "Epoch 5, Batch 3660/5867, Loss: 0.3744\n",
      "Epoch 5, Batch 3670/5867, Loss: 0.2956\n",
      "Epoch 5, Batch 3680/5867, Loss: 0.1971\n",
      "Epoch 5, Batch 3690/5867, Loss: 0.1508\n",
      "Epoch 5, Batch 3700/5867, Loss: 0.2624\n",
      "Epoch 5, Batch 3710/5867, Loss: 0.2194\n",
      "Epoch 5, Batch 3720/5867, Loss: 0.1700\n",
      "Epoch 5, Batch 3730/5867, Loss: 0.0987\n",
      "Epoch 5, Batch 3740/5867, Loss: 0.2444\n",
      "Epoch 5, Batch 3750/5867, Loss: 0.2155\n",
      "Epoch 5, Batch 3760/5867, Loss: 0.2828\n",
      "Epoch 5, Batch 3770/5867, Loss: 0.1306\n",
      "Epoch 5, Batch 3780/5867, Loss: 0.1255\n",
      "Epoch 5, Batch 3790/5867, Loss: 0.1770\n",
      "Epoch 5, Batch 3800/5867, Loss: 0.0467\n",
      "Epoch 5, Batch 3810/5867, Loss: 0.1976\n",
      "Epoch 5, Batch 3820/5867, Loss: 0.0826\n",
      "Epoch 5, Batch 3830/5867, Loss: 0.2533\n",
      "Epoch 5, Batch 3840/5867, Loss: 0.1733\n",
      "Epoch 5, Batch 3850/5867, Loss: 0.1303\n",
      "Epoch 5, Batch 3860/5867, Loss: 0.1204\n",
      "Epoch 5, Batch 3870/5867, Loss: 0.1680\n",
      "Epoch 5, Batch 3880/5867, Loss: 0.0898\n",
      "Epoch 5, Batch 3890/5867, Loss: 0.5727\n",
      "Epoch 5, Batch 3900/5867, Loss: 0.1812\n",
      "Epoch 5, Batch 3910/5867, Loss: 0.2258\n",
      "Epoch 5, Batch 3920/5867, Loss: 0.2092\n",
      "Epoch 5, Batch 3930/5867, Loss: 0.2202\n",
      "Epoch 5, Batch 3940/5867, Loss: 0.1847\n",
      "Epoch 5, Batch 3950/5867, Loss: 0.1264\n",
      "Epoch 5, Batch 3960/5867, Loss: 0.1164\n",
      "Epoch 5, Batch 3970/5867, Loss: 0.0940\n",
      "Epoch 5, Batch 3980/5867, Loss: 0.2157\n",
      "Epoch 5, Batch 3990/5867, Loss: 0.3646\n",
      "Epoch 5, Batch 4000/5867, Loss: 0.1909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 4010/5867, Loss: 0.1726\n",
      "Epoch 5, Batch 4020/5867, Loss: 0.2650\n",
      "Epoch 5, Batch 4030/5867, Loss: 0.0921\n",
      "Epoch 5, Batch 4040/5867, Loss: 0.2386\n",
      "Epoch 5, Batch 4050/5867, Loss: 0.1146\n",
      "Epoch 5, Batch 4060/5867, Loss: 0.1818\n",
      "Epoch 5, Batch 4070/5867, Loss: 0.1100\n",
      "Epoch 5, Batch 4080/5867, Loss: 0.1648\n",
      "Epoch 5, Batch 4090/5867, Loss: 0.2962\n",
      "Epoch 5, Batch 4100/5867, Loss: 0.0852\n",
      "Epoch 5, Batch 4110/5867, Loss: 0.4300\n",
      "Epoch 5, Batch 4120/5867, Loss: 0.2659\n",
      "Epoch 5, Batch 4130/5867, Loss: 0.2963\n",
      "Epoch 5, Batch 4140/5867, Loss: 0.2158\n",
      "Epoch 5, Batch 4150/5867, Loss: 0.1603\n",
      "Epoch 5, Batch 4160/5867, Loss: 0.1582\n",
      "Epoch 5, Batch 4170/5867, Loss: 0.2018\n",
      "Epoch 5, Batch 4180/5867, Loss: 0.2331\n",
      "Epoch 5, Batch 4190/5867, Loss: 0.4417\n",
      "Epoch 5, Batch 4200/5867, Loss: 0.0764\n",
      "Epoch 5, Batch 4210/5867, Loss: 0.1487\n",
      "Epoch 5, Batch 4220/5867, Loss: 0.1585\n",
      "Epoch 5, Batch 4230/5867, Loss: 0.0871\n",
      "Epoch 5, Batch 4240/5867, Loss: 0.3292\n",
      "Epoch 5, Batch 4250/5867, Loss: 0.0841\n",
      "Epoch 5, Batch 4260/5867, Loss: 0.3756\n",
      "Epoch 5, Batch 4270/5867, Loss: 0.0935\n",
      "Epoch 5, Batch 4280/5867, Loss: 0.2932\n",
      "Epoch 5, Batch 4290/5867, Loss: 0.0709\n",
      "Epoch 5, Batch 4300/5867, Loss: 0.0873\n",
      "Epoch 5, Batch 4310/5867, Loss: 0.2237\n",
      "Epoch 5, Batch 4320/5867, Loss: 0.1697\n",
      "Epoch 5, Batch 4330/5867, Loss: 0.1976\n",
      "Epoch 5, Batch 4340/5867, Loss: 0.1090\n",
      "Epoch 5, Batch 4350/5867, Loss: 0.1670\n",
      "Epoch 5, Batch 4360/5867, Loss: 0.1354\n",
      "Epoch 5, Batch 4370/5867, Loss: 0.4624\n",
      "Epoch 5, Batch 4380/5867, Loss: 0.2975\n",
      "Epoch 5, Batch 4390/5867, Loss: 0.1677\n",
      "Epoch 5, Batch 4400/5867, Loss: 0.2405\n",
      "Epoch 5, Batch 4410/5867, Loss: 0.2460\n",
      "Epoch 5, Batch 4420/5867, Loss: 0.2324\n",
      "Epoch 5, Batch 4430/5867, Loss: 0.2371\n",
      "Epoch 5, Batch 4440/5867, Loss: 0.2625\n",
      "Epoch 5, Batch 4450/5867, Loss: 0.0915\n",
      "Epoch 5, Batch 4460/5867, Loss: 0.1810\n",
      "Epoch 5, Batch 4470/5867, Loss: 0.1684\n",
      "Epoch 5, Batch 4480/5867, Loss: 0.1055\n",
      "Epoch 5, Batch 4490/5867, Loss: 0.1130\n",
      "Epoch 5, Batch 4500/5867, Loss: 0.2922\n",
      "Epoch 5, Batch 4510/5867, Loss: 0.1072\n",
      "Epoch 5, Batch 4520/5867, Loss: 0.1508\n",
      "Epoch 5, Batch 4530/5867, Loss: 0.1211\n",
      "Epoch 5, Batch 4540/5867, Loss: 0.1830\n",
      "Epoch 5, Batch 4550/5867, Loss: 0.2398\n",
      "Epoch 5, Batch 4560/5867, Loss: 0.1061\n",
      "Epoch 5, Batch 4570/5867, Loss: 0.2760\n",
      "Epoch 5, Batch 4580/5867, Loss: 0.2444\n",
      "Epoch 5, Batch 4590/5867, Loss: 0.1862\n",
      "Epoch 5, Batch 4600/5867, Loss: 0.2145\n",
      "Epoch 5, Batch 4610/5867, Loss: 0.1386\n",
      "Epoch 5, Batch 4620/5867, Loss: 0.0855\n",
      "Epoch 5, Batch 4630/5867, Loss: 0.3133\n",
      "Epoch 5, Batch 4640/5867, Loss: 0.1339\n",
      "Epoch 5, Batch 4650/5867, Loss: 0.2028\n",
      "Epoch 5, Batch 4660/5867, Loss: 0.1023\n",
      "Epoch 5, Batch 4670/5867, Loss: 0.1738\n",
      "Epoch 5, Batch 4680/5867, Loss: 0.1048\n",
      "Epoch 5, Batch 4690/5867, Loss: 0.0361\n",
      "Epoch 5, Batch 4700/5867, Loss: 0.1336\n",
      "Epoch 5, Batch 4710/5867, Loss: 0.0706\n",
      "Epoch 5, Batch 4720/5867, Loss: 0.1845\n",
      "Epoch 5, Batch 4730/5867, Loss: 0.0737\n",
      "Epoch 5, Batch 4740/5867, Loss: 0.0930\n",
      "Epoch 5, Batch 4750/5867, Loss: 0.1257\n",
      "Epoch 5, Batch 4760/5867, Loss: 0.1705\n",
      "Epoch 5, Batch 4770/5867, Loss: 0.1295\n",
      "Epoch 5, Batch 4780/5867, Loss: 0.2073\n",
      "Epoch 5, Batch 4790/5867, Loss: 0.2311\n",
      "Epoch 5, Batch 4800/5867, Loss: 0.0618\n",
      "Epoch 5, Batch 4810/5867, Loss: 0.1521\n",
      "Epoch 5, Batch 4820/5867, Loss: 0.0629\n",
      "Epoch 5, Batch 4830/5867, Loss: 0.1958\n",
      "Epoch 5, Batch 4840/5867, Loss: 0.2030\n",
      "Epoch 5, Batch 4850/5867, Loss: 0.2875\n",
      "Epoch 5, Batch 4860/5867, Loss: 0.0740\n",
      "Epoch 5, Batch 4870/5867, Loss: 0.1478\n",
      "Epoch 5, Batch 4880/5867, Loss: 0.2417\n",
      "Epoch 5, Batch 4890/5867, Loss: 0.0964\n",
      "Epoch 5, Batch 4900/5867, Loss: 0.2842\n",
      "Epoch 5, Batch 4910/5867, Loss: 0.2594\n",
      "Epoch 5, Batch 4920/5867, Loss: 0.1244\n",
      "Epoch 5, Batch 4930/5867, Loss: 0.0750\n",
      "Epoch 5, Batch 4940/5867, Loss: 0.3104\n",
      "Epoch 5, Batch 4950/5867, Loss: 0.1342\n",
      "Epoch 5, Batch 4960/5867, Loss: 0.0647\n",
      "Epoch 5, Batch 4970/5867, Loss: 0.1115\n",
      "Epoch 5, Batch 4980/5867, Loss: 0.0859\n",
      "Epoch 5, Batch 4990/5867, Loss: 0.2692\n",
      "Epoch 5, Batch 5000/5867, Loss: 0.2747\n",
      "Epoch 5, Batch 5010/5867, Loss: 0.2080\n",
      "Epoch 5, Batch 5020/5867, Loss: 0.0459\n",
      "Epoch 5, Batch 5030/5867, Loss: 0.0731\n",
      "Epoch 5, Batch 5040/5867, Loss: 0.2083\n",
      "Epoch 5, Batch 5050/5867, Loss: 0.1656\n",
      "Epoch 5, Batch 5060/5867, Loss: 0.2621\n",
      "Epoch 5, Batch 5070/5867, Loss: 0.2649\n",
      "Epoch 5, Batch 5080/5867, Loss: 0.1381\n",
      "Epoch 5, Batch 5090/5867, Loss: 0.3459\n",
      "Epoch 5, Batch 5100/5867, Loss: 0.1387\n",
      "Epoch 5, Batch 5110/5867, Loss: 0.1659\n",
      "Epoch 5, Batch 5120/5867, Loss: 0.2048\n",
      "Epoch 5, Batch 5130/5867, Loss: 0.2785\n",
      "Epoch 5, Batch 5140/5867, Loss: 0.1833\n",
      "Epoch 5, Batch 5150/5867, Loss: 0.1061\n",
      "Epoch 5, Batch 5160/5867, Loss: 0.2036\n",
      "Epoch 5, Batch 5170/5867, Loss: 0.2043\n",
      "Epoch 5, Batch 5180/5867, Loss: 0.1690\n",
      "Epoch 5, Batch 5190/5867, Loss: 0.2892\n",
      "Epoch 5, Batch 5200/5867, Loss: 0.2522\n",
      "Epoch 5, Batch 5210/5867, Loss: 0.1792\n",
      "Epoch 5, Batch 5220/5867, Loss: 0.2906\n",
      "Epoch 5, Batch 5230/5867, Loss: 0.0721\n",
      "Epoch 5, Batch 5240/5867, Loss: 0.1285\n",
      "Epoch 5, Batch 5250/5867, Loss: 0.1132\n",
      "Epoch 5, Batch 5260/5867, Loss: 0.2709\n",
      "Epoch 5, Batch 5270/5867, Loss: 0.1257\n",
      "Epoch 5, Batch 5280/5867, Loss: 0.2229\n",
      "Epoch 5, Batch 5290/5867, Loss: 0.1641\n",
      "Epoch 5, Batch 5300/5867, Loss: 0.1846\n",
      "Epoch 5, Batch 5310/5867, Loss: 0.0996\n",
      "Epoch 5, Batch 5320/5867, Loss: 0.3400\n",
      "Epoch 5, Batch 5330/5867, Loss: 0.1640\n",
      "Epoch 5, Batch 5340/5867, Loss: 0.1161\n",
      "Epoch 5, Batch 5350/5867, Loss: 0.0602\n",
      "Epoch 5, Batch 5360/5867, Loss: 0.2199\n",
      "Epoch 5, Batch 5370/5867, Loss: 0.4675\n",
      "Epoch 5, Batch 5380/5867, Loss: 0.1132\n",
      "Epoch 5, Batch 5390/5867, Loss: 0.3024\n",
      "Epoch 5, Batch 5400/5867, Loss: 0.1715\n",
      "Epoch 5, Batch 5410/5867, Loss: 0.0881\n",
      "Epoch 5, Batch 5420/5867, Loss: 0.1087\n",
      "Epoch 5, Batch 5430/5867, Loss: 0.2661\n",
      "Epoch 5, Batch 5440/5867, Loss: 0.1003\n",
      "Epoch 5, Batch 5450/5867, Loss: 0.0548\n",
      "Epoch 5, Batch 5460/5867, Loss: 0.2765\n",
      "Epoch 5, Batch 5470/5867, Loss: 0.2368\n",
      "Epoch 5, Batch 5480/5867, Loss: 0.3071\n",
      "Epoch 5, Batch 5490/5867, Loss: 0.1796\n",
      "Epoch 5, Batch 5500/5867, Loss: 0.2155\n",
      "Epoch 5, Batch 5510/5867, Loss: 0.0950\n",
      "Epoch 5, Batch 5520/5867, Loss: 0.3956\n",
      "Epoch 5, Batch 5530/5867, Loss: 0.0865\n",
      "Epoch 5, Batch 5540/5867, Loss: 0.1568\n",
      "Epoch 5, Batch 5550/5867, Loss: 0.2424\n",
      "Epoch 5, Batch 5560/5867, Loss: 0.2590\n",
      "Epoch 5, Batch 5570/5867, Loss: 0.2582\n",
      "Epoch 5, Batch 5580/5867, Loss: 0.1987\n",
      "Epoch 5, Batch 5590/5867, Loss: 0.2857\n",
      "Epoch 5, Batch 5600/5867, Loss: 0.1246\n",
      "Epoch 5, Batch 5610/5867, Loss: 0.1661\n",
      "Epoch 5, Batch 5620/5867, Loss: 0.1570\n",
      "Epoch 5, Batch 5630/5867, Loss: 0.1161\n",
      "Epoch 5, Batch 5640/5867, Loss: 0.1591\n",
      "Epoch 5, Batch 5650/5867, Loss: 0.1307\n",
      "Epoch 5, Batch 5660/5867, Loss: 0.1903\n",
      "Epoch 5, Batch 5670/5867, Loss: 0.3503\n",
      "Epoch 5, Batch 5680/5867, Loss: 0.2458\n",
      "Epoch 5, Batch 5690/5867, Loss: 0.1758\n",
      "Epoch 5, Batch 5700/5867, Loss: 0.2818\n",
      "Epoch 5, Batch 5710/5867, Loss: 0.2590\n",
      "Epoch 5, Batch 5720/5867, Loss: 0.3542\n",
      "Epoch 5, Batch 5730/5867, Loss: 0.1725\n",
      "Epoch 5, Batch 5740/5867, Loss: 0.1696\n",
      "Epoch 5, Batch 5750/5867, Loss: 0.3119\n",
      "Epoch 5, Batch 5760/5867, Loss: 0.2045\n",
      "Epoch 5, Batch 5770/5867, Loss: 0.1010\n",
      "Epoch 5, Batch 5780/5867, Loss: 0.3102\n",
      "Epoch 5, Batch 5790/5867, Loss: 0.0756\n",
      "Epoch 5, Batch 5800/5867, Loss: 0.3381\n",
      "Epoch 5, Batch 5810/5867, Loss: 0.0617\n",
      "Epoch 5, Batch 5820/5867, Loss: 0.3500\n",
      "Epoch 5, Batch 5830/5867, Loss: 0.3191\n",
      "Epoch 5, Batch 5840/5867, Loss: 0.1284\n",
      "Epoch 5, Batch 5850/5867, Loss: 0.1820\n",
      "Epoch 5, Batch 5860/5867, Loss: 0.2042\n",
      "Epoch 5, Training Loss: 0.1955, Validation Loss: 0.1892\n",
      "Starting epoch 6...\n",
      "Epoch 6, Batch 10/5867, Loss: 0.1785\n",
      "Epoch 6, Batch 20/5867, Loss: 0.2728\n",
      "Epoch 6, Batch 30/5867, Loss: 0.1926\n",
      "Epoch 6, Batch 40/5867, Loss: 0.2768\n",
      "Epoch 6, Batch 50/5867, Loss: 0.3192\n",
      "Epoch 6, Batch 60/5867, Loss: 0.3019\n",
      "Epoch 6, Batch 70/5867, Loss: 0.2222\n",
      "Epoch 6, Batch 80/5867, Loss: 0.1579\n",
      "Epoch 6, Batch 90/5867, Loss: 0.2004\n",
      "Epoch 6, Batch 100/5867, Loss: 0.2210\n",
      "Epoch 6, Batch 110/5867, Loss: 0.0982\n",
      "Epoch 6, Batch 120/5867, Loss: 0.2833\n",
      "Epoch 6, Batch 130/5867, Loss: 0.1781\n",
      "Epoch 6, Batch 140/5867, Loss: 0.1787\n",
      "Epoch 6, Batch 150/5867, Loss: 0.2103\n",
      "Epoch 6, Batch 160/5867, Loss: 0.1433\n",
      "Epoch 6, Batch 170/5867, Loss: 0.3094\n",
      "Epoch 6, Batch 180/5867, Loss: 0.1491\n",
      "Epoch 6, Batch 190/5867, Loss: 0.2523\n",
      "Epoch 6, Batch 200/5867, Loss: 0.1483\n",
      "Epoch 6, Batch 210/5867, Loss: 0.1488\n",
      "Epoch 6, Batch 220/5867, Loss: 0.1523\n",
      "Epoch 6, Batch 230/5867, Loss: 0.2291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 240/5867, Loss: 0.1918\n",
      "Epoch 6, Batch 250/5867, Loss: 0.0596\n",
      "Epoch 6, Batch 260/5867, Loss: 0.2063\n",
      "Epoch 6, Batch 270/5867, Loss: 0.1565\n",
      "Epoch 6, Batch 280/5867, Loss: 0.2458\n",
      "Epoch 6, Batch 290/5867, Loss: 0.1430\n",
      "Epoch 6, Batch 300/5867, Loss: 0.1232\n",
      "Epoch 6, Batch 310/5867, Loss: 0.1002\n",
      "Epoch 6, Batch 320/5867, Loss: 0.0915\n",
      "Epoch 6, Batch 330/5867, Loss: 0.1402\n",
      "Epoch 6, Batch 340/5867, Loss: 0.1409\n",
      "Epoch 6, Batch 350/5867, Loss: 0.3272\n",
      "Epoch 6, Batch 360/5867, Loss: 0.2612\n",
      "Epoch 6, Batch 370/5867, Loss: 0.0875\n",
      "Epoch 6, Batch 380/5867, Loss: 0.2950\n",
      "Epoch 6, Batch 390/5867, Loss: 0.2983\n",
      "Epoch 6, Batch 400/5867, Loss: 0.4373\n",
      "Epoch 6, Batch 410/5867, Loss: 0.0885\n",
      "Epoch 6, Batch 420/5867, Loss: 0.0544\n",
      "Epoch 6, Batch 430/5867, Loss: 0.3994\n",
      "Epoch 6, Batch 440/5867, Loss: 0.2545\n",
      "Epoch 6, Batch 450/5867, Loss: 0.1552\n",
      "Epoch 6, Batch 460/5867, Loss: 0.1267\n",
      "Epoch 6, Batch 470/5867, Loss: 0.1695\n",
      "Epoch 6, Batch 480/5867, Loss: 0.2879\n",
      "Epoch 6, Batch 490/5867, Loss: 0.2196\n",
      "Epoch 6, Batch 500/5867, Loss: 0.1016\n",
      "Epoch 6, Batch 510/5867, Loss: 0.0469\n",
      "Epoch 6, Batch 520/5867, Loss: 0.1219\n",
      "Epoch 6, Batch 530/5867, Loss: 0.2872\n",
      "Epoch 6, Batch 540/5867, Loss: 0.0958\n",
      "Epoch 6, Batch 550/5867, Loss: 0.2327\n",
      "Epoch 6, Batch 560/5867, Loss: 0.2670\n",
      "Epoch 6, Batch 570/5867, Loss: 0.1812\n",
      "Epoch 6, Batch 580/5867, Loss: 0.1580\n",
      "Epoch 6, Batch 590/5867, Loss: 0.0787\n",
      "Epoch 6, Batch 600/5867, Loss: 0.1164\n",
      "Epoch 6, Batch 610/5867, Loss: 0.2456\n",
      "Epoch 6, Batch 620/5867, Loss: 0.2091\n",
      "Epoch 6, Batch 630/5867, Loss: 0.2040\n",
      "Epoch 6, Batch 640/5867, Loss: 0.0997\n",
      "Epoch 6, Batch 650/5867, Loss: 0.1470\n",
      "Epoch 6, Batch 660/5867, Loss: 0.0886\n",
      "Epoch 6, Batch 670/5867, Loss: 0.2595\n",
      "Epoch 6, Batch 680/5867, Loss: 0.1666\n",
      "Epoch 6, Batch 690/5867, Loss: 0.0918\n",
      "Epoch 6, Batch 700/5867, Loss: 0.2070\n",
      "Epoch 6, Batch 710/5867, Loss: 0.0640\n",
      "Epoch 6, Batch 720/5867, Loss: 0.1618\n",
      "Epoch 6, Batch 730/5867, Loss: 0.1569\n",
      "Epoch 6, Batch 740/5867, Loss: 0.1380\n",
      "Epoch 6, Batch 750/5867, Loss: 0.1331\n",
      "Epoch 6, Batch 760/5867, Loss: 0.1265\n",
      "Epoch 6, Batch 770/5867, Loss: 0.1583\n",
      "Epoch 6, Batch 780/5867, Loss: 0.0649\n",
      "Epoch 6, Batch 790/5867, Loss: 0.2366\n",
      "Epoch 6, Batch 800/5867, Loss: 0.1489\n",
      "Epoch 6, Batch 810/5867, Loss: 0.1428\n",
      "Epoch 6, Batch 820/5867, Loss: 0.0639\n",
      "Epoch 6, Batch 830/5867, Loss: 0.3545\n",
      "Epoch 6, Batch 840/5867, Loss: 0.3399\n",
      "Epoch 6, Batch 850/5867, Loss: 0.3284\n",
      "Epoch 6, Batch 860/5867, Loss: 0.3943\n",
      "Epoch 6, Batch 870/5867, Loss: 0.3896\n",
      "Epoch 6, Batch 880/5867, Loss: 0.1237\n",
      "Epoch 6, Batch 890/5867, Loss: 0.0626\n",
      "Epoch 6, Batch 900/5867, Loss: 0.1162\n",
      "Epoch 6, Batch 910/5867, Loss: 0.1682\n",
      "Epoch 6, Batch 920/5867, Loss: 0.4057\n",
      "Epoch 6, Batch 930/5867, Loss: 0.2443\n",
      "Epoch 6, Batch 940/5867, Loss: 0.3264\n",
      "Epoch 6, Batch 950/5867, Loss: 0.2081\n",
      "Epoch 6, Batch 960/5867, Loss: 0.2842\n",
      "Epoch 6, Batch 970/5867, Loss: 0.2129\n",
      "Epoch 6, Batch 980/5867, Loss: 0.1285\n",
      "Epoch 6, Batch 990/5867, Loss: 0.1524\n",
      "Epoch 6, Batch 1000/5867, Loss: 0.1225\n",
      "Epoch 6, Batch 1010/5867, Loss: 0.1621\n",
      "Epoch 6, Batch 1020/5867, Loss: 0.4358\n",
      "Epoch 6, Batch 1030/5867, Loss: 0.0873\n",
      "Epoch 6, Batch 1040/5867, Loss: 0.2764\n",
      "Epoch 6, Batch 1050/5867, Loss: 0.2617\n",
      "Epoch 6, Batch 1060/5867, Loss: 0.2010\n",
      "Epoch 6, Batch 1070/5867, Loss: 0.0767\n",
      "Epoch 6, Batch 1080/5867, Loss: 0.3410\n",
      "Epoch 6, Batch 1090/5867, Loss: 0.3181\n",
      "Epoch 6, Batch 1100/5867, Loss: 0.1277\n",
      "Epoch 6, Batch 1110/5867, Loss: 0.3259\n",
      "Epoch 6, Batch 1120/5867, Loss: 0.1735\n",
      "Epoch 6, Batch 1130/5867, Loss: 0.2537\n",
      "Epoch 6, Batch 1140/5867, Loss: 0.2070\n",
      "Epoch 6, Batch 1150/5867, Loss: 0.1803\n",
      "Epoch 6, Batch 1160/5867, Loss: 0.1407\n",
      "Epoch 6, Batch 1170/5867, Loss: 0.3433\n",
      "Epoch 6, Batch 1180/5867, Loss: 0.3404\n",
      "Epoch 6, Batch 1190/5867, Loss: 0.1690\n",
      "Epoch 6, Batch 1200/5867, Loss: 0.2225\n",
      "Epoch 6, Batch 1210/5867, Loss: 0.1120\n",
      "Epoch 6, Batch 1220/5867, Loss: 0.0766\n",
      "Epoch 6, Batch 1230/5867, Loss: 0.0657\n",
      "Epoch 6, Batch 1240/5867, Loss: 0.1408\n",
      "Epoch 6, Batch 1250/5867, Loss: 0.1115\n",
      "Epoch 6, Batch 1260/5867, Loss: 0.0807\n",
      "Epoch 6, Batch 1270/5867, Loss: 0.0997\n",
      "Epoch 6, Batch 1280/5867, Loss: 0.3448\n",
      "Epoch 6, Batch 1290/5867, Loss: 0.2637\n",
      "Epoch 6, Batch 1300/5867, Loss: 0.2415\n",
      "Epoch 6, Batch 1310/5867, Loss: 0.1090\n",
      "Epoch 6, Batch 1320/5867, Loss: 0.1148\n",
      "Epoch 6, Batch 1330/5867, Loss: 0.1808\n",
      "Epoch 6, Batch 1340/5867, Loss: 0.2195\n",
      "Epoch 6, Batch 1350/5867, Loss: 0.1390\n",
      "Epoch 6, Batch 1360/5867, Loss: 0.1649\n",
      "Epoch 6, Batch 1370/5867, Loss: 0.2277\n",
      "Epoch 6, Batch 1380/5867, Loss: 0.1354\n",
      "Epoch 6, Batch 1390/5867, Loss: 0.1381\n",
      "Epoch 6, Batch 1400/5867, Loss: 0.1698\n",
      "Epoch 6, Batch 1410/5867, Loss: 0.2281\n",
      "Epoch 6, Batch 1420/5867, Loss: 0.4971\n",
      "Epoch 6, Batch 1430/5867, Loss: 0.2649\n",
      "Epoch 6, Batch 1440/5867, Loss: 0.2185\n",
      "Epoch 6, Batch 1450/5867, Loss: 0.1751\n",
      "Epoch 6, Batch 1460/5867, Loss: 0.3003\n",
      "Epoch 6, Batch 1470/5867, Loss: 0.1570\n",
      "Epoch 6, Batch 1480/5867, Loss: 0.2758\n",
      "Epoch 6, Batch 1490/5867, Loss: 0.1212\n",
      "Epoch 6, Batch 1500/5867, Loss: 0.0568\n",
      "Epoch 6, Batch 1510/5867, Loss: 0.1056\n",
      "Epoch 6, Batch 1520/5867, Loss: 0.1400\n",
      "Epoch 6, Batch 1530/5867, Loss: 0.4063\n",
      "Epoch 6, Batch 1540/5867, Loss: 0.1508\n",
      "Epoch 6, Batch 1550/5867, Loss: 0.1557\n",
      "Epoch 6, Batch 1560/5867, Loss: 0.1469\n",
      "Epoch 6, Batch 1570/5867, Loss: 0.2997\n",
      "Epoch 6, Batch 1580/5867, Loss: 0.0788\n",
      "Epoch 6, Batch 1590/5867, Loss: 0.1105\n",
      "Epoch 6, Batch 1600/5867, Loss: 0.1409\n",
      "Epoch 6, Batch 1610/5867, Loss: 0.0860\n",
      "Epoch 6, Batch 1620/5867, Loss: 0.1531\n",
      "Epoch 6, Batch 1630/5867, Loss: 0.0556\n",
      "Epoch 6, Batch 1640/5867, Loss: 0.3913\n",
      "Epoch 6, Batch 1650/5867, Loss: 0.0868\n",
      "Epoch 6, Batch 1660/5867, Loss: 0.0994\n",
      "Epoch 6, Batch 1670/5867, Loss: 0.0939\n",
      "Epoch 6, Batch 1680/5867, Loss: 0.2495\n",
      "Epoch 6, Batch 1690/5867, Loss: 0.1508\n",
      "Epoch 6, Batch 1700/5867, Loss: 0.2841\n",
      "Epoch 6, Batch 1710/5867, Loss: 0.3050\n",
      "Epoch 6, Batch 1720/5867, Loss: 0.1456\n",
      "Epoch 6, Batch 1730/5867, Loss: 0.0667\n",
      "Epoch 6, Batch 1740/5867, Loss: 0.0700\n",
      "Epoch 6, Batch 1750/5867, Loss: 0.2116\n",
      "Epoch 6, Batch 1760/5867, Loss: 0.2609\n",
      "Epoch 6, Batch 1770/5867, Loss: 0.1103\n",
      "Epoch 6, Batch 1780/5867, Loss: 0.1402\n",
      "Epoch 6, Batch 1790/5867, Loss: 0.1234\n",
      "Epoch 6, Batch 1800/5867, Loss: 0.2614\n",
      "Epoch 6, Batch 1810/5867, Loss: 0.3891\n",
      "Epoch 6, Batch 1820/5867, Loss: 0.2459\n",
      "Epoch 6, Batch 1830/5867, Loss: 0.0969\n",
      "Epoch 6, Batch 1840/5867, Loss: 0.1170\n",
      "Epoch 6, Batch 1850/5867, Loss: 0.1745\n",
      "Epoch 6, Batch 1860/5867, Loss: 0.1475\n",
      "Epoch 6, Batch 1870/5867, Loss: 0.1976\n",
      "Epoch 6, Batch 1880/5867, Loss: 0.3516\n",
      "Epoch 6, Batch 1890/5867, Loss: 0.0963\n",
      "Epoch 6, Batch 1900/5867, Loss: 0.2012\n",
      "Epoch 6, Batch 1910/5867, Loss: 0.2062\n",
      "Epoch 6, Batch 1920/5867, Loss: 0.2685\n",
      "Epoch 6, Batch 1930/5867, Loss: 0.1026\n",
      "Epoch 6, Batch 1940/5867, Loss: 0.3092\n",
      "Epoch 6, Batch 1950/5867, Loss: 0.1160\n",
      "Epoch 6, Batch 1960/5867, Loss: 0.0989\n",
      "Epoch 6, Batch 1970/5867, Loss: 0.1375\n",
      "Epoch 6, Batch 1980/5867, Loss: 0.1060\n",
      "Epoch 6, Batch 1990/5867, Loss: 0.1268\n",
      "Epoch 6, Batch 2000/5867, Loss: 0.1813\n",
      "Epoch 6, Batch 2010/5867, Loss: 0.2215\n",
      "Epoch 6, Batch 2020/5867, Loss: 0.3058\n",
      "Epoch 6, Batch 2030/5867, Loss: 0.1351\n",
      "Epoch 6, Batch 2040/5867, Loss: 0.4181\n",
      "Epoch 6, Batch 2050/5867, Loss: 0.2230\n",
      "Epoch 6, Batch 2060/5867, Loss: 0.1306\n",
      "Epoch 6, Batch 2070/5867, Loss: 0.0975\n",
      "Epoch 6, Batch 2080/5867, Loss: 0.1670\n",
      "Epoch 6, Batch 2090/5867, Loss: 0.0427\n",
      "Epoch 6, Batch 2100/5867, Loss: 0.1405\n",
      "Epoch 6, Batch 2110/5867, Loss: 0.2530\n",
      "Epoch 6, Batch 2120/5867, Loss: 0.2533\n",
      "Epoch 6, Batch 2130/5867, Loss: 0.1577\n",
      "Epoch 6, Batch 2140/5867, Loss: 0.0870\n",
      "Epoch 6, Batch 2150/5867, Loss: 0.3874\n",
      "Epoch 6, Batch 2160/5867, Loss: 0.2590\n",
      "Epoch 6, Batch 2170/5867, Loss: 0.0852\n",
      "Epoch 6, Batch 2180/5867, Loss: 0.0678\n",
      "Epoch 6, Batch 2190/5867, Loss: 0.1707\n",
      "Epoch 6, Batch 2200/5867, Loss: 0.1683\n",
      "Epoch 6, Batch 2210/5867, Loss: 0.1293\n",
      "Epoch 6, Batch 2220/5867, Loss: 0.1475\n",
      "Epoch 6, Batch 2230/5867, Loss: 0.1318\n",
      "Epoch 6, Batch 2240/5867, Loss: 0.1129\n",
      "Epoch 6, Batch 2250/5867, Loss: 0.2686\n",
      "Epoch 6, Batch 2260/5867, Loss: 0.2710\n",
      "Epoch 6, Batch 2270/5867, Loss: 0.2001\n",
      "Epoch 6, Batch 2280/5867, Loss: 0.0995\n",
      "Epoch 6, Batch 2290/5867, Loss: 0.4332\n",
      "Epoch 6, Batch 2300/5867, Loss: 0.1972\n",
      "Epoch 6, Batch 2310/5867, Loss: 0.1505\n",
      "Epoch 6, Batch 2320/5867, Loss: 0.1073\n",
      "Epoch 6, Batch 2330/5867, Loss: 0.1658\n",
      "Epoch 6, Batch 2340/5867, Loss: 0.2612\n",
      "Epoch 6, Batch 2350/5867, Loss: 0.1468\n",
      "Epoch 6, Batch 2360/5867, Loss: 0.1781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 2370/5867, Loss: 0.2608\n",
      "Epoch 6, Batch 2380/5867, Loss: 0.1219\n",
      "Epoch 6, Batch 2390/5867, Loss: 0.1670\n",
      "Epoch 6, Batch 2400/5867, Loss: 0.1134\n",
      "Epoch 6, Batch 2410/5867, Loss: 0.1811\n",
      "Epoch 6, Batch 2420/5867, Loss: 0.3272\n",
      "Epoch 6, Batch 2430/5867, Loss: 0.1881\n",
      "Epoch 6, Batch 2440/5867, Loss: 0.2020\n",
      "Epoch 6, Batch 2450/5867, Loss: 0.1067\n",
      "Epoch 6, Batch 2460/5867, Loss: 0.0786\n",
      "Epoch 6, Batch 2470/5867, Loss: 0.1526\n",
      "Epoch 6, Batch 2480/5867, Loss: 0.0759\n",
      "Epoch 6, Batch 2490/5867, Loss: 0.1577\n",
      "Epoch 6, Batch 2500/5867, Loss: 0.1867\n",
      "Epoch 6, Batch 2510/5867, Loss: 0.2201\n",
      "Epoch 6, Batch 2520/5867, Loss: 0.0437\n",
      "Epoch 6, Batch 2530/5867, Loss: 0.1796\n",
      "Epoch 6, Batch 2540/5867, Loss: 0.1582\n",
      "Epoch 6, Batch 2550/5867, Loss: 0.2581\n",
      "Epoch 6, Batch 2560/5867, Loss: 0.2616\n",
      "Epoch 6, Batch 2570/5867, Loss: 0.4362\n",
      "Epoch 6, Batch 2580/5867, Loss: 0.2321\n",
      "Epoch 6, Batch 2590/5867, Loss: 0.1909\n",
      "Epoch 6, Batch 2600/5867, Loss: 0.1214\n",
      "Epoch 6, Batch 2610/5867, Loss: 0.4434\n",
      "Epoch 6, Batch 2620/5867, Loss: 0.3365\n",
      "Epoch 6, Batch 2630/5867, Loss: 0.1300\n",
      "Epoch 6, Batch 2640/5867, Loss: 0.1017\n",
      "Epoch 6, Batch 2650/5867, Loss: 0.0479\n",
      "Epoch 6, Batch 2660/5867, Loss: 0.0934\n",
      "Epoch 6, Batch 2670/5867, Loss: 0.1243\n",
      "Epoch 6, Batch 2680/5867, Loss: 0.2130\n",
      "Epoch 6, Batch 2690/5867, Loss: 0.2178\n",
      "Epoch 6, Batch 2700/5867, Loss: 0.1448\n",
      "Epoch 6, Batch 2710/5867, Loss: 0.0596\n",
      "Epoch 6, Batch 2720/5867, Loss: 0.1260\n",
      "Epoch 6, Batch 2730/5867, Loss: 0.3810\n",
      "Epoch 6, Batch 2740/5867, Loss: 0.0833\n",
      "Epoch 6, Batch 2750/5867, Loss: 0.2012\n",
      "Epoch 6, Batch 2760/5867, Loss: 0.1336\n",
      "Epoch 6, Batch 2770/5867, Loss: 0.3818\n",
      "Epoch 6, Batch 2780/5867, Loss: 0.2499\n",
      "Epoch 6, Batch 2790/5867, Loss: 0.0980\n",
      "Epoch 6, Batch 2800/5867, Loss: 0.2445\n",
      "Epoch 6, Batch 2810/5867, Loss: 0.1653\n",
      "Epoch 6, Batch 2820/5867, Loss: 0.2316\n",
      "Epoch 6, Batch 2830/5867, Loss: 0.1522\n",
      "Epoch 6, Batch 2840/5867, Loss: 0.1632\n",
      "Epoch 6, Batch 2850/5867, Loss: 0.2100\n",
      "Epoch 6, Batch 2860/5867, Loss: 0.1171\n",
      "Epoch 6, Batch 2870/5867, Loss: 0.1010\n",
      "Epoch 6, Batch 2880/5867, Loss: 0.2082\n",
      "Epoch 6, Batch 2890/5867, Loss: 0.2520\n",
      "Epoch 6, Batch 2900/5867, Loss: 0.0818\n",
      "Epoch 6, Batch 2910/5867, Loss: 0.3319\n",
      "Epoch 6, Batch 2920/5867, Loss: 0.2004\n",
      "Epoch 6, Batch 2930/5867, Loss: 0.0886\n",
      "Epoch 6, Batch 2940/5867, Loss: 0.1600\n",
      "Epoch 6, Batch 2950/5867, Loss: 0.2083\n",
      "Epoch 6, Batch 2960/5867, Loss: 0.1323\n",
      "Epoch 6, Batch 2970/5867, Loss: 0.1044\n",
      "Epoch 6, Batch 2980/5867, Loss: 0.2603\n",
      "Epoch 6, Batch 2990/5867, Loss: 0.1122\n",
      "Epoch 6, Batch 3000/5867, Loss: 0.1877\n",
      "Epoch 6, Batch 3010/5867, Loss: 0.1094\n",
      "Epoch 6, Batch 3020/5867, Loss: 0.2611\n",
      "Epoch 6, Batch 3030/5867, Loss: 0.1583\n",
      "Epoch 6, Batch 3040/5867, Loss: 0.0683\n",
      "Epoch 6, Batch 3050/5867, Loss: 0.2175\n",
      "Epoch 6, Batch 3060/5867, Loss: 0.2940\n",
      "Epoch 6, Batch 3070/5867, Loss: 0.2131\n",
      "Epoch 6, Batch 3080/5867, Loss: 0.1704\n",
      "Epoch 6, Batch 3090/5867, Loss: 0.3090\n",
      "Epoch 6, Batch 3100/5867, Loss: 0.1581\n",
      "Epoch 6, Batch 3110/5867, Loss: 0.2429\n",
      "Epoch 6, Batch 3120/5867, Loss: 0.1561\n",
      "Epoch 6, Batch 3130/5867, Loss: 0.1307\n",
      "Epoch 6, Batch 3140/5867, Loss: 0.2198\n",
      "Epoch 6, Batch 3150/5867, Loss: 0.2742\n",
      "Epoch 6, Batch 3160/5867, Loss: 0.1772\n",
      "Epoch 6, Batch 3170/5867, Loss: 0.0813\n",
      "Epoch 6, Batch 3180/5867, Loss: 0.1108\n",
      "Epoch 6, Batch 3190/5867, Loss: 0.2757\n",
      "Epoch 6, Batch 3200/5867, Loss: 0.2361\n",
      "Epoch 6, Batch 3210/5867, Loss: 0.1560\n",
      "Epoch 6, Batch 3220/5867, Loss: 0.2684\n",
      "Epoch 6, Batch 3230/5867, Loss: 0.3159\n",
      "Epoch 6, Batch 3240/5867, Loss: 0.1727\n",
      "Epoch 6, Batch 3250/5867, Loss: 0.1858\n",
      "Epoch 6, Batch 3260/5867, Loss: 0.1651\n",
      "Epoch 6, Batch 3270/5867, Loss: 0.1359\n",
      "Epoch 6, Batch 3280/5867, Loss: 0.1973\n",
      "Epoch 6, Batch 3290/5867, Loss: 0.1646\n",
      "Epoch 6, Batch 3300/5867, Loss: 0.0613\n",
      "Epoch 6, Batch 3310/5867, Loss: 0.2664\n",
      "Epoch 6, Batch 3320/5867, Loss: 0.2356\n",
      "Epoch 6, Batch 3330/5867, Loss: 0.1830\n",
      "Epoch 6, Batch 3340/5867, Loss: 0.1439\n",
      "Epoch 6, Batch 3350/5867, Loss: 0.1675\n",
      "Epoch 6, Batch 3360/5867, Loss: 0.1231\n",
      "Epoch 6, Batch 3370/5867, Loss: 0.1830\n",
      "Epoch 6, Batch 3380/5867, Loss: 0.1682\n",
      "Epoch 6, Batch 3390/5867, Loss: 0.2185\n",
      "Epoch 6, Batch 3400/5867, Loss: 0.1177\n",
      "Epoch 6, Batch 3410/5867, Loss: 0.0579\n",
      "Epoch 6, Batch 3420/5867, Loss: 0.0902\n",
      "Epoch 6, Batch 3430/5867, Loss: 0.1189\n",
      "Epoch 6, Batch 3440/5867, Loss: 0.1929\n",
      "Epoch 6, Batch 3450/5867, Loss: 0.1639\n",
      "Epoch 6, Batch 3460/5867, Loss: 0.0981\n",
      "Epoch 6, Batch 3470/5867, Loss: 0.0735\n",
      "Epoch 6, Batch 3480/5867, Loss: 0.2719\n",
      "Epoch 6, Batch 3490/5867, Loss: 0.1977\n",
      "Epoch 6, Batch 3500/5867, Loss: 0.2334\n",
      "Epoch 6, Batch 3510/5867, Loss: 0.3273\n",
      "Epoch 6, Batch 3520/5867, Loss: 0.3342\n",
      "Epoch 6, Batch 3530/5867, Loss: 0.2209\n",
      "Epoch 6, Batch 3540/5867, Loss: 0.1862\n",
      "Epoch 6, Batch 3550/5867, Loss: 0.1735\n",
      "Epoch 6, Batch 3560/5867, Loss: 0.1452\n",
      "Epoch 6, Batch 3570/5867, Loss: 0.1377\n",
      "Epoch 6, Batch 3580/5867, Loss: 0.1834\n",
      "Epoch 6, Batch 3590/5867, Loss: 0.1034\n",
      "Epoch 6, Batch 3600/5867, Loss: 0.1884\n",
      "Epoch 6, Batch 3610/5867, Loss: 0.2251\n",
      "Epoch 6, Batch 3620/5867, Loss: 0.1751\n",
      "Epoch 6, Batch 3630/5867, Loss: 0.4143\n",
      "Epoch 6, Batch 3640/5867, Loss: 0.1718\n",
      "Epoch 6, Batch 3650/5867, Loss: 0.2477\n",
      "Epoch 6, Batch 3660/5867, Loss: 0.2614\n",
      "Epoch 6, Batch 3670/5867, Loss: 0.0849\n",
      "Epoch 6, Batch 3680/5867, Loss: 0.0992\n",
      "Epoch 6, Batch 3690/5867, Loss: 0.0858\n",
      "Epoch 6, Batch 3700/5867, Loss: 0.1054\n",
      "Epoch 6, Batch 3710/5867, Loss: 0.2403\n",
      "Epoch 6, Batch 3720/5867, Loss: 0.1885\n",
      "Epoch 6, Batch 3730/5867, Loss: 0.1452\n",
      "Epoch 6, Batch 3740/5867, Loss: 0.1726\n",
      "Epoch 6, Batch 3750/5867, Loss: 0.1325\n",
      "Epoch 6, Batch 3760/5867, Loss: 0.1233\n",
      "Epoch 6, Batch 3770/5867, Loss: 0.2934\n",
      "Epoch 6, Batch 3780/5867, Loss: 0.2748\n",
      "Epoch 6, Batch 3790/5867, Loss: 0.1503\n",
      "Epoch 6, Batch 3800/5867, Loss: 0.2230\n",
      "Epoch 6, Batch 3810/5867, Loss: 0.1323\n",
      "Epoch 6, Batch 3820/5867, Loss: 0.1074\n",
      "Epoch 6, Batch 3830/5867, Loss: 0.3795\n",
      "Epoch 6, Batch 3840/5867, Loss: 0.2623\n",
      "Epoch 6, Batch 3850/5867, Loss: 0.1262\n",
      "Epoch 6, Batch 3860/5867, Loss: 0.1491\n",
      "Epoch 6, Batch 3870/5867, Loss: 0.0904\n",
      "Epoch 6, Batch 3880/5867, Loss: 0.1823\n",
      "Epoch 6, Batch 3890/5867, Loss: 0.2989\n",
      "Epoch 6, Batch 3900/5867, Loss: 0.4620\n",
      "Epoch 6, Batch 3910/5867, Loss: 0.2016\n",
      "Epoch 6, Batch 3920/5867, Loss: 0.1430\n",
      "Epoch 6, Batch 3930/5867, Loss: 0.2085\n",
      "Epoch 6, Batch 3940/5867, Loss: 0.2295\n",
      "Epoch 6, Batch 3950/5867, Loss: 0.3580\n",
      "Epoch 6, Batch 3960/5867, Loss: 0.2441\n",
      "Epoch 6, Batch 3970/5867, Loss: 0.1073\n",
      "Epoch 6, Batch 3980/5867, Loss: 0.1854\n",
      "Epoch 6, Batch 3990/5867, Loss: 0.1174\n",
      "Epoch 6, Batch 4000/5867, Loss: 0.1950\n",
      "Epoch 6, Batch 4010/5867, Loss: 0.2081\n",
      "Epoch 6, Batch 4020/5867, Loss: 0.1772\n",
      "Epoch 6, Batch 4030/5867, Loss: 0.0385\n",
      "Epoch 6, Batch 4040/5867, Loss: 0.0576\n",
      "Epoch 6, Batch 4050/5867, Loss: 0.2838\n",
      "Epoch 6, Batch 4060/5867, Loss: 0.3809\n",
      "Epoch 6, Batch 4070/5867, Loss: 0.0852\n",
      "Epoch 6, Batch 4080/5867, Loss: 0.1556\n",
      "Epoch 6, Batch 4090/5867, Loss: 0.2059\n",
      "Epoch 6, Batch 4100/5867, Loss: 0.1281\n",
      "Epoch 6, Batch 4110/5867, Loss: 0.1500\n",
      "Epoch 6, Batch 4120/5867, Loss: 0.1320\n",
      "Epoch 6, Batch 4130/5867, Loss: 0.2914\n",
      "Epoch 6, Batch 4140/5867, Loss: 0.1878\n",
      "Epoch 6, Batch 4150/5867, Loss: 0.3557\n",
      "Epoch 6, Batch 4160/5867, Loss: 0.2075\n",
      "Epoch 6, Batch 4170/5867, Loss: 0.1746\n",
      "Epoch 6, Batch 4180/5867, Loss: 0.2260\n",
      "Epoch 6, Batch 4190/5867, Loss: 0.2756\n",
      "Epoch 6, Batch 4200/5867, Loss: 0.2430\n",
      "Epoch 6, Batch 4210/5867, Loss: 0.3001\n",
      "Epoch 6, Batch 4220/5867, Loss: 0.0426\n",
      "Epoch 6, Batch 4230/5867, Loss: 0.1795\n",
      "Epoch 6, Batch 4240/5867, Loss: 0.1626\n",
      "Epoch 6, Batch 4250/5867, Loss: 0.1467\n",
      "Epoch 6, Batch 4260/5867, Loss: 0.1208\n",
      "Epoch 6, Batch 4270/5867, Loss: 0.1994\n",
      "Epoch 6, Batch 4280/5867, Loss: 0.1448\n",
      "Epoch 6, Batch 4290/5867, Loss: 0.1468\n",
      "Epoch 6, Batch 4300/5867, Loss: 0.0479\n",
      "Epoch 6, Batch 4310/5867, Loss: 0.0863\n",
      "Epoch 6, Batch 4320/5867, Loss: 0.1985\n",
      "Epoch 6, Batch 4330/5867, Loss: 0.1686\n",
      "Epoch 6, Batch 4340/5867, Loss: 0.2240\n",
      "Epoch 6, Batch 4350/5867, Loss: 0.0729\n",
      "Epoch 6, Batch 4360/5867, Loss: 0.1479\n",
      "Epoch 6, Batch 4370/5867, Loss: 0.1970\n",
      "Epoch 6, Batch 4380/5867, Loss: 0.3820\n",
      "Epoch 6, Batch 4390/5867, Loss: 0.1834\n",
      "Epoch 6, Batch 4400/5867, Loss: 0.2855\n",
      "Epoch 6, Batch 4410/5867, Loss: 0.3136\n",
      "Epoch 6, Batch 4420/5867, Loss: 0.1820\n",
      "Epoch 6, Batch 4430/5867, Loss: 0.1166\n",
      "Epoch 6, Batch 4440/5867, Loss: 0.2049\n",
      "Epoch 6, Batch 4450/5867, Loss: 0.1204\n",
      "Epoch 6, Batch 4460/5867, Loss: 0.2224\n",
      "Epoch 6, Batch 4470/5867, Loss: 0.1876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 4480/5867, Loss: 0.3727\n",
      "Epoch 6, Batch 4490/5867, Loss: 0.1112\n",
      "Epoch 6, Batch 4500/5867, Loss: 0.1840\n",
      "Epoch 6, Batch 4510/5867, Loss: 0.1238\n",
      "Epoch 6, Batch 4520/5867, Loss: 0.0771\n",
      "Epoch 6, Batch 4530/5867, Loss: 0.1979\n",
      "Epoch 6, Batch 4540/5867, Loss: 0.2114\n",
      "Epoch 6, Batch 4550/5867, Loss: 0.1025\n",
      "Epoch 6, Batch 4560/5867, Loss: 0.1822\n",
      "Epoch 6, Batch 4570/5867, Loss: 0.1197\n",
      "Epoch 6, Batch 4580/5867, Loss: 0.1443\n",
      "Epoch 6, Batch 4590/5867, Loss: 0.1861\n",
      "Epoch 6, Batch 4600/5867, Loss: 0.0186\n",
      "Epoch 6, Batch 4610/5867, Loss: 0.2562\n",
      "Epoch 6, Batch 4620/5867, Loss: 0.1672\n",
      "Epoch 6, Batch 4630/5867, Loss: 0.1779\n",
      "Epoch 6, Batch 4640/5867, Loss: 0.1666\n",
      "Epoch 6, Batch 4650/5867, Loss: 0.0483\n",
      "Epoch 6, Batch 4660/5867, Loss: 0.1690\n",
      "Epoch 6, Batch 4670/5867, Loss: 0.2081\n",
      "Epoch 6, Batch 4680/5867, Loss: 0.2694\n",
      "Epoch 6, Batch 4690/5867, Loss: 0.1341\n",
      "Epoch 6, Batch 4700/5867, Loss: 0.1119\n",
      "Epoch 6, Batch 4710/5867, Loss: 0.1598\n",
      "Epoch 6, Batch 4720/5867, Loss: 0.2392\n",
      "Epoch 6, Batch 4730/5867, Loss: 0.1074\n",
      "Epoch 6, Batch 4740/5867, Loss: 0.2076\n",
      "Epoch 6, Batch 4750/5867, Loss: 0.0970\n",
      "Epoch 6, Batch 4760/5867, Loss: 0.3455\n",
      "Epoch 6, Batch 4770/5867, Loss: 0.0827\n",
      "Epoch 6, Batch 4780/5867, Loss: 0.3498\n",
      "Epoch 6, Batch 4790/5867, Loss: 0.2833\n",
      "Epoch 6, Batch 4800/5867, Loss: 0.3164\n",
      "Epoch 6, Batch 4810/5867, Loss: 0.1828\n",
      "Epoch 6, Batch 4820/5867, Loss: 0.1579\n",
      "Epoch 6, Batch 4830/5867, Loss: 0.1724\n",
      "Epoch 6, Batch 4840/5867, Loss: 0.1805\n",
      "Epoch 6, Batch 4850/5867, Loss: 0.1738\n",
      "Epoch 6, Batch 4860/5867, Loss: 0.1637\n",
      "Epoch 6, Batch 4870/5867, Loss: 0.1584\n",
      "Epoch 6, Batch 4880/5867, Loss: 0.3165\n",
      "Epoch 6, Batch 4890/5867, Loss: 0.2372\n",
      "Epoch 6, Batch 4900/5867, Loss: 0.1647\n",
      "Epoch 6, Batch 4910/5867, Loss: 0.1675\n",
      "Epoch 6, Batch 4920/5867, Loss: 0.3357\n",
      "Epoch 6, Batch 4930/5867, Loss: 0.1062\n",
      "Epoch 6, Batch 4940/5867, Loss: 0.1389\n",
      "Epoch 6, Batch 4950/5867, Loss: 0.2356\n",
      "Epoch 6, Batch 4960/5867, Loss: 0.4868\n",
      "Epoch 6, Batch 4970/5867, Loss: 0.1445\n",
      "Epoch 6, Batch 4980/5867, Loss: 0.4439\n",
      "Epoch 6, Batch 4990/5867, Loss: 0.1008\n",
      "Epoch 6, Batch 5000/5867, Loss: 0.1723\n",
      "Epoch 6, Batch 5010/5867, Loss: 0.1917\n",
      "Epoch 6, Batch 5020/5867, Loss: 0.1007\n",
      "Epoch 6, Batch 5030/5867, Loss: 0.2035\n",
      "Epoch 6, Batch 5040/5867, Loss: 0.1283\n",
      "Epoch 6, Batch 5050/5867, Loss: 0.2230\n",
      "Epoch 6, Batch 5060/5867, Loss: 0.0755\n",
      "Epoch 6, Batch 5070/5867, Loss: 0.1717\n",
      "Epoch 6, Batch 5080/5867, Loss: 0.1969\n",
      "Epoch 6, Batch 5090/5867, Loss: 0.1505\n",
      "Epoch 6, Batch 5100/5867, Loss: 0.1390\n",
      "Epoch 6, Batch 5110/5867, Loss: 0.2743\n",
      "Epoch 6, Batch 5120/5867, Loss: 0.1247\n",
      "Epoch 6, Batch 5130/5867, Loss: 0.1090\n",
      "Epoch 6, Batch 5140/5867, Loss: 0.2929\n",
      "Epoch 6, Batch 5150/5867, Loss: 0.2460\n",
      "Epoch 6, Batch 5160/5867, Loss: 0.2176\n",
      "Epoch 6, Batch 5170/5867, Loss: 0.2203\n",
      "Epoch 6, Batch 5180/5867, Loss: 0.2918\n",
      "Epoch 6, Batch 5190/5867, Loss: 0.2343\n",
      "Epoch 6, Batch 5200/5867, Loss: 0.0723\n",
      "Epoch 6, Batch 5210/5867, Loss: 0.1818\n",
      "Epoch 6, Batch 5220/5867, Loss: 0.1953\n",
      "Epoch 6, Batch 5230/5867, Loss: 0.1452\n",
      "Epoch 6, Batch 5240/5867, Loss: 0.2231\n",
      "Epoch 6, Batch 5250/5867, Loss: 0.2435\n",
      "Epoch 6, Batch 5260/5867, Loss: 0.3070\n",
      "Epoch 6, Batch 5270/5867, Loss: 0.2247\n",
      "Epoch 6, Batch 5280/5867, Loss: 0.1109\n",
      "Epoch 6, Batch 5290/5867, Loss: 0.3698\n",
      "Epoch 6, Batch 5300/5867, Loss: 0.2593\n",
      "Epoch 6, Batch 5310/5867, Loss: 0.0472\n",
      "Epoch 6, Batch 5320/5867, Loss: 0.2230\n",
      "Epoch 6, Batch 5330/5867, Loss: 0.1288\n",
      "Epoch 6, Batch 5340/5867, Loss: 0.2466\n",
      "Epoch 6, Batch 5350/5867, Loss: 0.1762\n",
      "Epoch 6, Batch 5360/5867, Loss: 0.1003\n",
      "Epoch 6, Batch 5370/5867, Loss: 0.3337\n",
      "Epoch 6, Batch 5380/5867, Loss: 0.2153\n",
      "Epoch 6, Batch 5390/5867, Loss: 0.1428\n",
      "Epoch 6, Batch 5400/5867, Loss: 0.2448\n",
      "Epoch 6, Batch 5410/5867, Loss: 0.3333\n",
      "Epoch 6, Batch 5420/5867, Loss: 0.2732\n",
      "Epoch 6, Batch 5430/5867, Loss: 0.0760\n",
      "Epoch 6, Batch 5440/5867, Loss: 0.1541\n",
      "Epoch 6, Batch 5450/5867, Loss: 0.2640\n",
      "Epoch 6, Batch 5460/5867, Loss: 0.1320\n",
      "Epoch 6, Batch 5470/5867, Loss: 0.0853\n",
      "Epoch 6, Batch 5480/5867, Loss: 0.1507\n",
      "Epoch 6, Batch 5490/5867, Loss: 0.2909\n",
      "Epoch 6, Batch 5500/5867, Loss: 0.3187\n",
      "Epoch 6, Batch 5510/5867, Loss: 0.0634\n",
      "Epoch 6, Batch 5520/5867, Loss: 0.1886\n",
      "Epoch 6, Batch 5530/5867, Loss: 0.2266\n",
      "Epoch 6, Batch 5540/5867, Loss: 0.1204\n",
      "Epoch 6, Batch 5550/5867, Loss: 0.1772\n",
      "Epoch 6, Batch 5560/5867, Loss: 0.1717\n",
      "Epoch 6, Batch 5570/5867, Loss: 0.2894\n",
      "Epoch 6, Batch 5580/5867, Loss: 0.1463\n",
      "Epoch 6, Batch 5590/5867, Loss: 0.0539\n",
      "Epoch 6, Batch 5600/5867, Loss: 0.0483\n",
      "Epoch 6, Batch 5610/5867, Loss: 0.0668\n",
      "Epoch 6, Batch 5620/5867, Loss: 0.1596\n",
      "Epoch 6, Batch 5630/5867, Loss: 0.1638\n",
      "Epoch 6, Batch 5640/5867, Loss: 0.2963\n",
      "Epoch 6, Batch 5650/5867, Loss: 0.3372\n",
      "Epoch 6, Batch 5660/5867, Loss: 0.2873\n",
      "Epoch 6, Batch 5670/5867, Loss: 0.1794\n",
      "Epoch 6, Batch 5680/5867, Loss: 0.2456\n",
      "Epoch 6, Batch 5690/5867, Loss: 0.3039\n",
      "Epoch 6, Batch 5700/5867, Loss: 0.2238\n",
      "Epoch 6, Batch 5710/5867, Loss: 0.0775\n",
      "Epoch 6, Batch 5720/5867, Loss: 0.2155\n",
      "Epoch 6, Batch 5730/5867, Loss: 0.2836\n",
      "Epoch 6, Batch 5740/5867, Loss: 0.2499\n",
      "Epoch 6, Batch 5750/5867, Loss: 0.1682\n",
      "Epoch 6, Batch 5760/5867, Loss: 0.1372\n",
      "Epoch 6, Batch 5770/5867, Loss: 0.0521\n",
      "Epoch 6, Batch 5780/5867, Loss: 0.1328\n",
      "Epoch 6, Batch 5790/5867, Loss: 0.1814\n",
      "Epoch 6, Batch 5800/5867, Loss: 0.2221\n",
      "Epoch 6, Batch 5810/5867, Loss: 0.1371\n",
      "Epoch 6, Batch 5820/5867, Loss: 0.1758\n",
      "Epoch 6, Batch 5830/5867, Loss: 0.1467\n",
      "Epoch 6, Batch 5840/5867, Loss: 0.2169\n",
      "Epoch 6, Batch 5850/5867, Loss: 0.1117\n",
      "Epoch 6, Batch 5860/5867, Loss: 0.0942\n",
      "Epoch 6, Training Loss: 0.1919, Validation Loss: 0.1930\n",
      "Starting epoch 7...\n",
      "Epoch 7, Batch 10/5867, Loss: 0.1556\n",
      "Epoch 7, Batch 20/5867, Loss: 0.3874\n",
      "Epoch 7, Batch 30/5867, Loss: 0.1075\n",
      "Epoch 7, Batch 40/5867, Loss: 0.2331\n",
      "Epoch 7, Batch 50/5867, Loss: 0.2053\n",
      "Epoch 7, Batch 60/5867, Loss: 0.1672\n",
      "Epoch 7, Batch 70/5867, Loss: 0.2574\n",
      "Epoch 7, Batch 80/5867, Loss: 0.2648\n",
      "Epoch 7, Batch 90/5867, Loss: 0.1184\n",
      "Epoch 7, Batch 100/5867, Loss: 0.1167\n",
      "Epoch 7, Batch 110/5867, Loss: 0.2114\n",
      "Epoch 7, Batch 120/5867, Loss: 0.1476\n",
      "Epoch 7, Batch 130/5867, Loss: 0.2973\n",
      "Epoch 7, Batch 140/5867, Loss: 0.2305\n",
      "Epoch 7, Batch 150/5867, Loss: 0.2997\n",
      "Epoch 7, Batch 160/5867, Loss: 0.2273\n",
      "Epoch 7, Batch 170/5867, Loss: 0.1538\n",
      "Epoch 7, Batch 180/5867, Loss: 0.1501\n",
      "Epoch 7, Batch 190/5867, Loss: 0.0980\n",
      "Epoch 7, Batch 200/5867, Loss: 0.2129\n",
      "Epoch 7, Batch 210/5867, Loss: 0.3567\n",
      "Epoch 7, Batch 220/5867, Loss: 0.3739\n",
      "Epoch 7, Batch 230/5867, Loss: 0.1975\n",
      "Epoch 7, Batch 240/5867, Loss: 0.0508\n",
      "Epoch 7, Batch 250/5867, Loss: 0.2225\n",
      "Epoch 7, Batch 260/5867, Loss: 0.2613\n",
      "Epoch 7, Batch 270/5867, Loss: 0.1591\n",
      "Epoch 7, Batch 280/5867, Loss: 0.1420\n",
      "Epoch 7, Batch 290/5867, Loss: 0.1253\n",
      "Epoch 7, Batch 300/5867, Loss: 0.2818\n",
      "Epoch 7, Batch 310/5867, Loss: 0.1644\n",
      "Epoch 7, Batch 320/5867, Loss: 0.1100\n",
      "Epoch 7, Batch 330/5867, Loss: 0.0773\n",
      "Epoch 7, Batch 340/5867, Loss: 0.2532\n",
      "Epoch 7, Batch 350/5867, Loss: 0.1534\n",
      "Epoch 7, Batch 360/5867, Loss: 0.2102\n",
      "Epoch 7, Batch 370/5867, Loss: 0.1755\n",
      "Epoch 7, Batch 380/5867, Loss: 0.3101\n",
      "Epoch 7, Batch 390/5867, Loss: 0.1543\n",
      "Epoch 7, Batch 400/5867, Loss: 0.1061\n",
      "Epoch 7, Batch 410/5867, Loss: 0.3100\n",
      "Epoch 7, Batch 420/5867, Loss: 0.0756\n",
      "Epoch 7, Batch 430/5867, Loss: 0.1351\n",
      "Epoch 7, Batch 440/5867, Loss: 0.2633\n",
      "Epoch 7, Batch 450/5867, Loss: 0.3414\n",
      "Epoch 7, Batch 460/5867, Loss: 0.1925\n",
      "Epoch 7, Batch 470/5867, Loss: 0.1544\n",
      "Epoch 7, Batch 480/5867, Loss: 0.1230\n",
      "Epoch 7, Batch 490/5867, Loss: 0.0762\n",
      "Epoch 7, Batch 500/5867, Loss: 0.2271\n",
      "Epoch 7, Batch 510/5867, Loss: 0.0860\n",
      "Epoch 7, Batch 520/5867, Loss: 0.0491\n",
      "Epoch 7, Batch 530/5867, Loss: 0.1833\n",
      "Epoch 7, Batch 540/5867, Loss: 0.1280\n",
      "Epoch 7, Batch 550/5867, Loss: 0.1465\n",
      "Epoch 7, Batch 560/5867, Loss: 0.1815\n",
      "Epoch 7, Batch 570/5867, Loss: 0.1797\n",
      "Epoch 7, Batch 580/5867, Loss: 0.1384\n",
      "Epoch 7, Batch 590/5867, Loss: 0.0752\n",
      "Epoch 7, Batch 600/5867, Loss: 0.1194\n",
      "Epoch 7, Batch 610/5867, Loss: 0.1910\n",
      "Epoch 7, Batch 620/5867, Loss: 0.0520\n",
      "Epoch 7, Batch 630/5867, Loss: 0.0937\n",
      "Epoch 7, Batch 640/5867, Loss: 0.2481\n",
      "Epoch 7, Batch 650/5867, Loss: 0.1994\n",
      "Epoch 7, Batch 660/5867, Loss: 0.2579\n",
      "Epoch 7, Batch 670/5867, Loss: 0.0709\n",
      "Epoch 7, Batch 680/5867, Loss: 0.4212\n",
      "Epoch 7, Batch 690/5867, Loss: 0.2584\n",
      "Epoch 7, Batch 700/5867, Loss: 0.1566\n",
      "Epoch 7, Batch 710/5867, Loss: 0.2276\n",
      "Epoch 7, Batch 720/5867, Loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 730/5867, Loss: 0.1926\n",
      "Epoch 7, Batch 740/5867, Loss: 0.1374\n",
      "Epoch 7, Batch 750/5867, Loss: 0.3431\n",
      "Epoch 7, Batch 760/5867, Loss: 0.2086\n",
      "Epoch 7, Batch 770/5867, Loss: 0.1196\n",
      "Epoch 7, Batch 780/5867, Loss: 0.2300\n",
      "Epoch 7, Batch 790/5867, Loss: 0.3246\n",
      "Epoch 7, Batch 800/5867, Loss: 0.0939\n",
      "Epoch 7, Batch 810/5867, Loss: 0.2568\n",
      "Epoch 7, Batch 820/5867, Loss: 0.1534\n",
      "Epoch 7, Batch 830/5867, Loss: 0.2473\n",
      "Epoch 7, Batch 840/5867, Loss: 0.2561\n",
      "Epoch 7, Batch 850/5867, Loss: 0.3091\n",
      "Epoch 7, Batch 860/5867, Loss: 0.2759\n",
      "Epoch 7, Batch 870/5867, Loss: 0.2301\n",
      "Epoch 7, Batch 880/5867, Loss: 0.2135\n",
      "Epoch 7, Batch 890/5867, Loss: 0.2531\n",
      "Epoch 7, Batch 900/5867, Loss: 0.3434\n",
      "Epoch 7, Batch 910/5867, Loss: 0.1919\n",
      "Epoch 7, Batch 920/5867, Loss: 0.1592\n",
      "Epoch 7, Batch 930/5867, Loss: 0.3580\n",
      "Epoch 7, Batch 940/5867, Loss: 0.2535\n",
      "Epoch 7, Batch 950/5867, Loss: 0.0724\n",
      "Epoch 7, Batch 960/5867, Loss: 0.2277\n",
      "Epoch 7, Batch 970/5867, Loss: 0.3058\n",
      "Epoch 7, Batch 980/5867, Loss: 0.3720\n",
      "Epoch 7, Batch 990/5867, Loss: 0.2778\n",
      "Epoch 7, Batch 1000/5867, Loss: 0.1412\n",
      "Epoch 7, Batch 1010/5867, Loss: 0.0754\n",
      "Epoch 7, Batch 1020/5867, Loss: 0.2110\n",
      "Epoch 7, Batch 1030/5867, Loss: 0.2967\n",
      "Epoch 7, Batch 1040/5867, Loss: 0.1708\n",
      "Epoch 7, Batch 1050/5867, Loss: 0.0904\n",
      "Epoch 7, Batch 1060/5867, Loss: 0.0922\n",
      "Epoch 7, Batch 1070/5867, Loss: 0.1663\n",
      "Epoch 7, Batch 1080/5867, Loss: 0.1796\n",
      "Epoch 7, Batch 1090/5867, Loss: 0.1074\n",
      "Epoch 7, Batch 1100/5867, Loss: 0.1579\n",
      "Epoch 7, Batch 1110/5867, Loss: 0.1385\n",
      "Epoch 7, Batch 1120/5867, Loss: 0.0730\n",
      "Epoch 7, Batch 1130/5867, Loss: 0.1182\n",
      "Epoch 7, Batch 1140/5867, Loss: 0.0450\n",
      "Epoch 7, Batch 1150/5867, Loss: 0.1248\n",
      "Epoch 7, Batch 1160/5867, Loss: 0.2457\n",
      "Epoch 7, Batch 1170/5867, Loss: 0.1693\n",
      "Epoch 7, Batch 1180/5867, Loss: 0.1825\n",
      "Epoch 7, Batch 1190/5867, Loss: 0.2482\n",
      "Epoch 7, Batch 1200/5867, Loss: 0.2289\n",
      "Epoch 7, Batch 1210/5867, Loss: 0.2063\n",
      "Epoch 7, Batch 1220/5867, Loss: 0.1657\n",
      "Epoch 7, Batch 1230/5867, Loss: 0.1586\n",
      "Epoch 7, Batch 1240/5867, Loss: 0.1025\n",
      "Epoch 7, Batch 1250/5867, Loss: 0.2045\n",
      "Epoch 7, Batch 1260/5867, Loss: 0.0855\n",
      "Epoch 7, Batch 1270/5867, Loss: 0.3261\n",
      "Epoch 7, Batch 1280/5867, Loss: 0.2201\n",
      "Epoch 7, Batch 1290/5867, Loss: 0.2256\n",
      "Epoch 7, Batch 1300/5867, Loss: 0.0750\n",
      "Epoch 7, Batch 1310/5867, Loss: 0.0779\n",
      "Epoch 7, Batch 1320/5867, Loss: 0.1867\n",
      "Epoch 7, Batch 1330/5867, Loss: 0.1168\n",
      "Epoch 7, Batch 1340/5867, Loss: 0.1816\n",
      "Epoch 7, Batch 1350/5867, Loss: 0.1882\n",
      "Epoch 7, Batch 1360/5867, Loss: 0.2035\n",
      "Epoch 7, Batch 1370/5867, Loss: 0.0852\n",
      "Epoch 7, Batch 1380/5867, Loss: 0.2715\n",
      "Epoch 7, Batch 1390/5867, Loss: 0.1580\n",
      "Epoch 7, Batch 1400/5867, Loss: 0.0778\n",
      "Epoch 7, Batch 1410/5867, Loss: 0.2618\n",
      "Epoch 7, Batch 1420/5867, Loss: 0.2023\n",
      "Epoch 7, Batch 1430/5867, Loss: 0.1751\n",
      "Epoch 7, Batch 1440/5867, Loss: 0.2106\n",
      "Epoch 7, Batch 1450/5867, Loss: 0.0786\n",
      "Epoch 7, Batch 1460/5867, Loss: 0.0948\n",
      "Epoch 7, Batch 1470/5867, Loss: 0.1927\n",
      "Epoch 7, Batch 1480/5867, Loss: 0.0937\n",
      "Epoch 7, Batch 1490/5867, Loss: 0.0923\n",
      "Epoch 7, Batch 1500/5867, Loss: 0.0882\n",
      "Epoch 7, Batch 1510/5867, Loss: 0.2722\n",
      "Epoch 7, Batch 1520/5867, Loss: 0.1907\n",
      "Epoch 7, Batch 1530/5867, Loss: 0.1025\n",
      "Epoch 7, Batch 1540/5867, Loss: 0.1775\n",
      "Epoch 7, Batch 1550/5867, Loss: 0.2715\n",
      "Epoch 7, Batch 1560/5867, Loss: 0.1341\n",
      "Epoch 7, Batch 1570/5867, Loss: 0.1778\n",
      "Epoch 7, Batch 1580/5867, Loss: 0.4011\n",
      "Epoch 7, Batch 1590/5867, Loss: 0.1573\n",
      "Epoch 7, Batch 1600/5867, Loss: 0.2041\n",
      "Epoch 7, Batch 1610/5867, Loss: 0.3033\n",
      "Epoch 7, Batch 1620/5867, Loss: 0.3211\n",
      "Epoch 7, Batch 1630/5867, Loss: 0.1920\n",
      "Epoch 7, Batch 1640/5867, Loss: 0.1678\n",
      "Epoch 7, Batch 1650/5867, Loss: 0.0842\n",
      "Epoch 7, Batch 1660/5867, Loss: 0.0894\n",
      "Epoch 7, Batch 1670/5867, Loss: 0.1783\n",
      "Epoch 7, Batch 1680/5867, Loss: 0.3071\n",
      "Epoch 7, Batch 1690/5867, Loss: 0.1722\n",
      "Epoch 7, Batch 1700/5867, Loss: 0.1322\n",
      "Epoch 7, Batch 1710/5867, Loss: 0.2727\n",
      "Epoch 7, Batch 1720/5867, Loss: 0.2633\n",
      "Epoch 7, Batch 1730/5867, Loss: 0.1460\n",
      "Epoch 7, Batch 1740/5867, Loss: 0.1526\n",
      "Epoch 7, Batch 1750/5867, Loss: 0.3124\n",
      "Epoch 7, Batch 1760/5867, Loss: 0.0836\n",
      "Epoch 7, Batch 1770/5867, Loss: 0.1077\n",
      "Epoch 7, Batch 1780/5867, Loss: 0.2527\n",
      "Epoch 7, Batch 1790/5867, Loss: 0.1139\n",
      "Epoch 7, Batch 1800/5867, Loss: 0.1336\n",
      "Epoch 7, Batch 1810/5867, Loss: 0.2382\n",
      "Epoch 7, Batch 1820/5867, Loss: 0.3385\n",
      "Epoch 7, Batch 1830/5867, Loss: 0.1861\n",
      "Epoch 7, Batch 1840/5867, Loss: 0.2221\n",
      "Epoch 7, Batch 1850/5867, Loss: 0.1586\n",
      "Epoch 7, Batch 1860/5867, Loss: 0.0579\n",
      "Epoch 7, Batch 1870/5867, Loss: 0.4275\n",
      "Epoch 7, Batch 1880/5867, Loss: 0.2246\n",
      "Epoch 7, Batch 1890/5867, Loss: 0.1398\n",
      "Epoch 7, Batch 1900/5867, Loss: 0.1840\n",
      "Epoch 7, Batch 1910/5867, Loss: 0.0573\n",
      "Epoch 7, Batch 1920/5867, Loss: 0.1823\n",
      "Epoch 7, Batch 1930/5867, Loss: 0.1492\n",
      "Epoch 7, Batch 1940/5867, Loss: 0.1336\n",
      "Epoch 7, Batch 1950/5867, Loss: 0.1443\n",
      "Epoch 7, Batch 1960/5867, Loss: 0.2693\n",
      "Epoch 7, Batch 1970/5867, Loss: 0.1556\n",
      "Epoch 7, Batch 1980/5867, Loss: 0.1167\n",
      "Epoch 7, Batch 1990/5867, Loss: 0.1554\n",
      "Epoch 7, Batch 2000/5867, Loss: 0.1750\n",
      "Epoch 7, Batch 2010/5867, Loss: 0.2912\n",
      "Epoch 7, Batch 2020/5867, Loss: 0.1429\n",
      "Epoch 7, Batch 2030/5867, Loss: 0.2319\n",
      "Epoch 7, Batch 2040/5867, Loss: 0.1279\n",
      "Epoch 7, Batch 2050/5867, Loss: 0.1604\n",
      "Epoch 7, Batch 2060/5867, Loss: 0.0801\n",
      "Epoch 7, Batch 2070/5867, Loss: 0.1817\n",
      "Epoch 7, Batch 2080/5867, Loss: 0.1714\n",
      "Epoch 7, Batch 2090/5867, Loss: 0.1611\n",
      "Epoch 7, Batch 2100/5867, Loss: 0.1457\n",
      "Epoch 7, Batch 2110/5867, Loss: 0.3284\n",
      "Epoch 7, Batch 2120/5867, Loss: 0.1982\n",
      "Epoch 7, Batch 2130/5867, Loss: 0.1971\n",
      "Epoch 7, Batch 2140/5867, Loss: 0.1523\n",
      "Epoch 7, Batch 2150/5867, Loss: 0.1877\n",
      "Epoch 7, Batch 2160/5867, Loss: 0.1121\n",
      "Epoch 7, Batch 2170/5867, Loss: 0.2652\n",
      "Epoch 7, Batch 2180/5867, Loss: 0.3027\n",
      "Epoch 7, Batch 2190/5867, Loss: 0.1645\n",
      "Epoch 7, Batch 2200/5867, Loss: 0.1396\n",
      "Epoch 7, Batch 2210/5867, Loss: 0.1612\n",
      "Epoch 7, Batch 2220/5867, Loss: 0.3103\n",
      "Epoch 7, Batch 2230/5867, Loss: 0.2472\n",
      "Epoch 7, Batch 2240/5867, Loss: 0.1818\n",
      "Epoch 7, Batch 2250/5867, Loss: 0.2389\n",
      "Epoch 7, Batch 2260/5867, Loss: 0.0715\n",
      "Epoch 7, Batch 2270/5867, Loss: 0.2326\n",
      "Epoch 7, Batch 2280/5867, Loss: 0.1912\n",
      "Epoch 7, Batch 2290/5867, Loss: 0.2415\n",
      "Epoch 7, Batch 2300/5867, Loss: 0.2605\n",
      "Epoch 7, Batch 2310/5867, Loss: 0.1982\n",
      "Epoch 7, Batch 2320/5867, Loss: 0.1266\n",
      "Epoch 7, Batch 2330/5867, Loss: 0.1977\n",
      "Epoch 7, Batch 2340/5867, Loss: 0.2539\n",
      "Epoch 7, Batch 2350/5867, Loss: 0.0991\n",
      "Epoch 7, Batch 2360/5867, Loss: 0.3087\n",
      "Epoch 7, Batch 2370/5867, Loss: 0.2380\n",
      "Epoch 7, Batch 2380/5867, Loss: 0.3068\n",
      "Epoch 7, Batch 2390/5867, Loss: 0.0849\n",
      "Epoch 7, Batch 2400/5867, Loss: 0.1584\n",
      "Epoch 7, Batch 2410/5867, Loss: 0.3602\n",
      "Epoch 7, Batch 2420/5867, Loss: 0.2321\n",
      "Epoch 7, Batch 2430/5867, Loss: 0.1077\n",
      "Epoch 7, Batch 2440/5867, Loss: 0.1318\n",
      "Epoch 7, Batch 2450/5867, Loss: 0.0918\n",
      "Epoch 7, Batch 2460/5867, Loss: 0.1921\n",
      "Epoch 7, Batch 2470/5867, Loss: 0.2278\n",
      "Epoch 7, Batch 2480/5867, Loss: 0.1717\n",
      "Epoch 7, Batch 2490/5867, Loss: 0.3394\n",
      "Epoch 7, Batch 2500/5867, Loss: 0.2038\n",
      "Epoch 7, Batch 2510/5867, Loss: 0.2219\n",
      "Epoch 7, Batch 2520/5867, Loss: 0.3990\n",
      "Epoch 7, Batch 2530/5867, Loss: 0.1834\n",
      "Epoch 7, Batch 2540/5867, Loss: 0.0725\n",
      "Epoch 7, Batch 2550/5867, Loss: 0.1612\n",
      "Epoch 7, Batch 2560/5867, Loss: 0.2783\n",
      "Epoch 7, Batch 2570/5867, Loss: 0.0946\n",
      "Epoch 7, Batch 2580/5867, Loss: 0.1288\n",
      "Epoch 7, Batch 2590/5867, Loss: 0.1873\n",
      "Epoch 7, Batch 2600/5867, Loss: 0.2152\n",
      "Epoch 7, Batch 2610/5867, Loss: 0.1030\n",
      "Epoch 7, Batch 2620/5867, Loss: 0.2143\n",
      "Epoch 7, Batch 2630/5867, Loss: 0.1362\n",
      "Epoch 7, Batch 2640/5867, Loss: 0.1249\n",
      "Epoch 7, Batch 2650/5867, Loss: 0.1030\n",
      "Epoch 7, Batch 2660/5867, Loss: 0.3627\n",
      "Epoch 7, Batch 2670/5867, Loss: 0.0166\n",
      "Epoch 7, Batch 2680/5867, Loss: 0.0758\n",
      "Epoch 7, Batch 2690/5867, Loss: 0.1228\n",
      "Epoch 7, Batch 2700/5867, Loss: 0.2031\n",
      "Epoch 7, Batch 2710/5867, Loss: 0.1889\n",
      "Epoch 7, Batch 2720/5867, Loss: 0.2464\n",
      "Epoch 7, Batch 2730/5867, Loss: 0.1402\n",
      "Epoch 7, Batch 2740/5867, Loss: 0.1780\n",
      "Epoch 7, Batch 2750/5867, Loss: 0.3702\n",
      "Epoch 7, Batch 2760/5867, Loss: 0.2380\n",
      "Epoch 7, Batch 2770/5867, Loss: 0.1297\n",
      "Epoch 7, Batch 2780/5867, Loss: 0.3111\n",
      "Epoch 7, Batch 2790/5867, Loss: 0.1325\n",
      "Epoch 7, Batch 2800/5867, Loss: 0.1805\n",
      "Epoch 7, Batch 2810/5867, Loss: 0.1840\n",
      "Epoch 7, Batch 2820/5867, Loss: 0.1228\n",
      "Epoch 7, Batch 2830/5867, Loss: 0.3327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 2840/5867, Loss: 0.3143\n",
      "Epoch 7, Batch 2850/5867, Loss: 0.2577\n",
      "Epoch 7, Batch 2860/5867, Loss: 0.3307\n",
      "Epoch 7, Batch 2870/5867, Loss: 0.1039\n",
      "Epoch 7, Batch 2880/5867, Loss: 0.2977\n",
      "Epoch 7, Batch 2890/5867, Loss: 0.2681\n",
      "Epoch 7, Batch 2900/5867, Loss: 0.1717\n",
      "Epoch 7, Batch 2910/5867, Loss: 0.0723\n",
      "Epoch 7, Batch 2920/5867, Loss: 0.3079\n",
      "Epoch 7, Batch 2930/5867, Loss: 0.1642\n",
      "Epoch 7, Batch 2940/5867, Loss: 0.1685\n",
      "Epoch 7, Batch 2950/5867, Loss: 0.1667\n",
      "Epoch 7, Batch 2960/5867, Loss: 0.2398\n",
      "Epoch 7, Batch 2970/5867, Loss: 0.1429\n",
      "Epoch 7, Batch 2980/5867, Loss: 0.4338\n",
      "Epoch 7, Batch 2990/5867, Loss: 0.1771\n",
      "Epoch 7, Batch 3000/5867, Loss: 0.1795\n",
      "Epoch 7, Batch 3010/5867, Loss: 0.1007\n",
      "Epoch 7, Batch 3020/5867, Loss: 0.3822\n",
      "Epoch 7, Batch 3030/5867, Loss: 0.0771\n",
      "Epoch 7, Batch 3040/5867, Loss: 0.2696\n",
      "Epoch 7, Batch 3050/5867, Loss: 0.2285\n",
      "Epoch 7, Batch 3060/5867, Loss: 0.1074\n",
      "Epoch 7, Batch 3070/5867, Loss: 0.1407\n",
      "Epoch 7, Batch 3080/5867, Loss: 0.1697\n",
      "Epoch 7, Batch 3090/5867, Loss: 0.1255\n",
      "Epoch 7, Batch 3100/5867, Loss: 0.0659\n",
      "Epoch 7, Batch 3110/5867, Loss: 0.1252\n",
      "Epoch 7, Batch 3120/5867, Loss: 0.1238\n",
      "Epoch 7, Batch 3130/5867, Loss: 0.2121\n",
      "Epoch 7, Batch 3140/5867, Loss: 0.1773\n",
      "Epoch 7, Batch 3150/5867, Loss: 0.0903\n",
      "Epoch 7, Batch 3160/5867, Loss: 0.2999\n",
      "Epoch 7, Batch 3170/5867, Loss: 0.2334\n",
      "Epoch 7, Batch 3180/5867, Loss: 0.0700\n",
      "Epoch 7, Batch 3190/5867, Loss: 0.1121\n",
      "Epoch 7, Batch 3200/5867, Loss: 0.2036\n",
      "Epoch 7, Batch 3210/5867, Loss: 0.1960\n",
      "Epoch 7, Batch 3220/5867, Loss: 0.1074\n",
      "Epoch 7, Batch 3230/5867, Loss: 0.1852\n",
      "Epoch 7, Batch 3240/5867, Loss: 0.1432\n",
      "Epoch 7, Batch 3250/5867, Loss: 0.1343\n",
      "Epoch 7, Batch 3260/5867, Loss: 0.0728\n",
      "Epoch 7, Batch 3270/5867, Loss: 0.1969\n",
      "Epoch 7, Batch 3280/5867, Loss: 0.2044\n",
      "Epoch 7, Batch 3290/5867, Loss: 0.0922\n",
      "Epoch 7, Batch 3300/5867, Loss: 0.1157\n",
      "Epoch 7, Batch 3310/5867, Loss: 0.1650\n",
      "Epoch 7, Batch 3320/5867, Loss: 0.1179\n",
      "Epoch 7, Batch 3330/5867, Loss: 0.1884\n",
      "Epoch 7, Batch 3340/5867, Loss: 0.1085\n",
      "Epoch 7, Batch 3350/5867, Loss: 0.2408\n",
      "Epoch 7, Batch 3360/5867, Loss: 0.1633\n",
      "Epoch 7, Batch 3370/5867, Loss: 0.2864\n",
      "Epoch 7, Batch 3380/5867, Loss: 0.3419\n",
      "Epoch 7, Batch 3390/5867, Loss: 0.2747\n",
      "Epoch 7, Batch 3400/5867, Loss: 0.2367\n",
      "Epoch 7, Batch 3410/5867, Loss: 0.1529\n",
      "Epoch 7, Batch 3420/5867, Loss: 0.1592\n",
      "Epoch 7, Batch 3430/5867, Loss: 0.1389\n",
      "Epoch 7, Batch 3440/5867, Loss: 0.1306\n",
      "Epoch 7, Batch 3450/5867, Loss: 0.1398\n",
      "Epoch 7, Batch 3460/5867, Loss: 0.1264\n",
      "Epoch 7, Batch 3470/5867, Loss: 0.1669\n",
      "Epoch 7, Batch 3480/5867, Loss: 0.1465\n",
      "Epoch 7, Batch 3490/5867, Loss: 0.2188\n",
      "Epoch 7, Batch 3500/5867, Loss: 0.2786\n",
      "Epoch 7, Batch 3510/5867, Loss: 0.2125\n",
      "Epoch 7, Batch 3520/5867, Loss: 0.2528\n",
      "Epoch 7, Batch 3530/5867, Loss: 0.1063\n",
      "Epoch 7, Batch 3540/5867, Loss: 0.3421\n",
      "Epoch 7, Batch 3550/5867, Loss: 0.1685\n",
      "Epoch 7, Batch 3560/5867, Loss: 0.3075\n",
      "Epoch 7, Batch 3570/5867, Loss: 0.1797\n",
      "Epoch 7, Batch 3580/5867, Loss: 0.1806\n",
      "Epoch 7, Batch 3590/5867, Loss: 0.0835\n",
      "Epoch 7, Batch 3600/5867, Loss: 0.1744\n",
      "Epoch 7, Batch 3610/5867, Loss: 0.0828\n",
      "Epoch 7, Batch 3620/5867, Loss: 0.2464\n",
      "Epoch 7, Batch 3630/5867, Loss: 0.1168\n",
      "Epoch 7, Batch 3640/5867, Loss: 0.3183\n",
      "Epoch 7, Batch 3650/5867, Loss: 0.2137\n",
      "Epoch 7, Batch 3660/5867, Loss: 0.1941\n",
      "Epoch 7, Batch 3670/5867, Loss: 0.2612\n",
      "Epoch 7, Batch 3680/5867, Loss: 0.1159\n",
      "Epoch 7, Batch 3690/5867, Loss: 0.1232\n",
      "Epoch 7, Batch 3700/5867, Loss: 0.1879\n",
      "Epoch 7, Batch 3710/5867, Loss: 0.2491\n",
      "Epoch 7, Batch 3720/5867, Loss: 0.0994\n",
      "Epoch 7, Batch 3730/5867, Loss: 0.2470\n",
      "Epoch 7, Batch 3740/5867, Loss: 0.1566\n",
      "Epoch 7, Batch 3750/5867, Loss: 0.1347\n",
      "Epoch 7, Batch 3760/5867, Loss: 0.0942\n",
      "Epoch 7, Batch 3770/5867, Loss: 0.2540\n",
      "Epoch 7, Batch 3780/5867, Loss: 0.2550\n",
      "Epoch 7, Batch 3790/5867, Loss: 0.1534\n",
      "Epoch 7, Batch 3800/5867, Loss: 0.3694\n",
      "Epoch 7, Batch 3810/5867, Loss: 0.2898\n",
      "Epoch 7, Batch 3820/5867, Loss: 0.3480\n",
      "Epoch 7, Batch 3830/5867, Loss: 0.2186\n",
      "Epoch 7, Batch 3840/5867, Loss: 0.2100\n",
      "Epoch 7, Batch 3850/5867, Loss: 0.1949\n",
      "Epoch 7, Batch 3860/5867, Loss: 0.1817\n",
      "Epoch 7, Batch 3870/5867, Loss: 0.0995\n",
      "Epoch 7, Batch 3880/5867, Loss: 0.3526\n",
      "Epoch 7, Batch 3890/5867, Loss: 0.1184\n",
      "Epoch 7, Batch 3900/5867, Loss: 0.1104\n",
      "Epoch 7, Batch 3910/5867, Loss: 0.2019\n",
      "Epoch 7, Batch 3920/5867, Loss: 0.2273\n",
      "Epoch 7, Batch 3930/5867, Loss: 0.3497\n",
      "Epoch 7, Batch 3940/5867, Loss: 0.1704\n",
      "Epoch 7, Batch 3950/5867, Loss: 0.2743\n",
      "Epoch 7, Batch 3960/5867, Loss: 0.2042\n",
      "Epoch 7, Batch 3970/5867, Loss: 0.2205\n",
      "Epoch 7, Batch 3980/5867, Loss: 0.1145\n",
      "Epoch 7, Batch 3990/5867, Loss: 0.2561\n",
      "Epoch 7, Batch 4000/5867, Loss: 0.1331\n",
      "Epoch 7, Batch 4010/5867, Loss: 0.1177\n",
      "Epoch 7, Batch 4020/5867, Loss: 0.0830\n",
      "Epoch 7, Batch 4030/5867, Loss: 0.1332\n",
      "Epoch 7, Batch 4040/5867, Loss: 0.2972\n",
      "Epoch 7, Batch 4050/5867, Loss: 0.2023\n",
      "Epoch 7, Batch 4060/5867, Loss: 0.1546\n",
      "Epoch 7, Batch 4070/5867, Loss: 0.2003\n",
      "Epoch 7, Batch 4080/5867, Loss: 0.3325\n",
      "Epoch 7, Batch 4090/5867, Loss: 0.3666\n",
      "Epoch 7, Batch 4100/5867, Loss: 0.1944\n",
      "Epoch 7, Batch 4110/5867, Loss: 0.1767\n",
      "Epoch 7, Batch 4120/5867, Loss: 0.1369\n",
      "Epoch 7, Batch 4130/5867, Loss: 0.3592\n",
      "Epoch 7, Batch 4140/5867, Loss: 0.1023\n",
      "Epoch 7, Batch 4150/5867, Loss: 0.2334\n",
      "Epoch 7, Batch 4160/5867, Loss: 0.1594\n",
      "Epoch 7, Batch 4170/5867, Loss: 0.1328\n",
      "Epoch 7, Batch 4180/5867, Loss: 0.1818\n",
      "Epoch 7, Batch 4190/5867, Loss: 0.1874\n",
      "Epoch 7, Batch 4200/5867, Loss: 0.2700\n",
      "Epoch 7, Batch 4210/5867, Loss: 0.1150\n",
      "Epoch 7, Batch 4220/5867, Loss: 0.1065\n",
      "Epoch 7, Batch 4230/5867, Loss: 0.0306\n",
      "Epoch 7, Batch 4240/5867, Loss: 0.0445\n",
      "Epoch 7, Batch 4250/5867, Loss: 0.2212\n",
      "Epoch 7, Batch 4260/5867, Loss: 0.0957\n",
      "Epoch 7, Batch 4270/5867, Loss: 0.2320\n",
      "Epoch 7, Batch 4280/5867, Loss: 0.2261\n",
      "Epoch 7, Batch 4290/5867, Loss: 0.2462\n",
      "Epoch 7, Batch 4300/5867, Loss: 0.1250\n",
      "Epoch 7, Batch 4310/5867, Loss: 0.1116\n",
      "Epoch 7, Batch 4320/5867, Loss: 0.1548\n",
      "Epoch 7, Batch 4330/5867, Loss: 0.1331\n",
      "Epoch 7, Batch 4340/5867, Loss: 0.1894\n",
      "Epoch 7, Batch 4350/5867, Loss: 0.0968\n",
      "Epoch 7, Batch 4360/5867, Loss: 0.2145\n",
      "Epoch 7, Batch 4370/5867, Loss: 0.1475\n",
      "Epoch 7, Batch 4380/5867, Loss: 0.1905\n",
      "Epoch 7, Batch 4390/5867, Loss: 0.1066\n",
      "Epoch 7, Batch 4400/5867, Loss: 0.1639\n",
      "Epoch 7, Batch 4410/5867, Loss: 0.1342\n",
      "Epoch 7, Batch 4420/5867, Loss: 0.2103\n",
      "Epoch 7, Batch 4430/5867, Loss: 0.1107\n",
      "Epoch 7, Batch 4440/5867, Loss: 0.0751\n",
      "Epoch 7, Batch 4450/5867, Loss: 0.1911\n",
      "Epoch 7, Batch 4460/5867, Loss: 0.1462\n",
      "Epoch 7, Batch 4470/5867, Loss: 0.1880\n",
      "Epoch 7, Batch 4480/5867, Loss: 0.1297\n",
      "Epoch 7, Batch 4490/5867, Loss: 0.0823\n",
      "Epoch 7, Batch 4500/5867, Loss: 0.1699\n",
      "Epoch 7, Batch 4510/5867, Loss: 0.1896\n",
      "Epoch 7, Batch 4520/5867, Loss: 0.1800\n",
      "Epoch 7, Batch 4530/5867, Loss: 0.0792\n",
      "Epoch 7, Batch 4540/5867, Loss: 0.1379\n",
      "Epoch 7, Batch 4550/5867, Loss: 0.1841\n",
      "Epoch 7, Batch 4560/5867, Loss: 0.1465\n",
      "Epoch 7, Batch 4570/5867, Loss: 0.1421\n",
      "Epoch 7, Batch 4580/5867, Loss: 0.1986\n",
      "Epoch 7, Batch 4590/5867, Loss: 0.1481\n",
      "Epoch 7, Batch 4600/5867, Loss: 0.1831\n",
      "Epoch 7, Batch 4610/5867, Loss: 0.1861\n",
      "Epoch 7, Batch 4620/5867, Loss: 0.0961\n",
      "Epoch 7, Batch 4630/5867, Loss: 0.1125\n",
      "Epoch 7, Batch 4640/5867, Loss: 0.0782\n",
      "Epoch 7, Batch 4650/5867, Loss: 0.1605\n",
      "Epoch 7, Batch 4660/5867, Loss: 0.1749\n",
      "Epoch 7, Batch 4670/5867, Loss: 0.1830\n",
      "Epoch 7, Batch 4680/5867, Loss: 0.0572\n",
      "Epoch 7, Batch 4690/5867, Loss: 0.1458\n",
      "Epoch 7, Batch 4700/5867, Loss: 0.1341\n",
      "Epoch 7, Batch 4710/5867, Loss: 0.1836\n",
      "Epoch 7, Batch 4720/5867, Loss: 0.1419\n",
      "Epoch 7, Batch 4730/5867, Loss: 0.2800\n",
      "Epoch 7, Batch 4740/5867, Loss: 0.2675\n",
      "Epoch 7, Batch 4750/5867, Loss: 0.2051\n",
      "Epoch 7, Batch 4760/5867, Loss: 0.1035\n",
      "Epoch 7, Batch 4770/5867, Loss: 0.1346\n",
      "Epoch 7, Batch 4780/5867, Loss: 0.0791\n",
      "Epoch 7, Batch 4790/5867, Loss: 0.0393\n",
      "Epoch 7, Batch 4800/5867, Loss: 0.2684\n",
      "Epoch 7, Batch 4810/5867, Loss: 0.2266\n",
      "Epoch 7, Batch 4820/5867, Loss: 0.1269\n",
      "Epoch 7, Batch 4830/5867, Loss: 0.2587\n",
      "Epoch 7, Batch 4840/5867, Loss: 0.2908\n",
      "Epoch 7, Batch 4850/5867, Loss: 0.1925\n",
      "Epoch 7, Batch 4860/5867, Loss: 0.2709\n",
      "Epoch 7, Batch 4870/5867, Loss: 0.1173\n",
      "Epoch 7, Batch 4880/5867, Loss: 0.1991\n",
      "Epoch 7, Batch 4890/5867, Loss: 0.1449\n",
      "Epoch 7, Batch 4900/5867, Loss: 0.1792\n",
      "Epoch 7, Batch 4910/5867, Loss: 0.4031\n",
      "Epoch 7, Batch 4920/5867, Loss: 0.1264\n",
      "Epoch 7, Batch 4930/5867, Loss: 0.1514\n",
      "Epoch 7, Batch 4940/5867, Loss: 0.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 4950/5867, Loss: 0.3074\n",
      "Epoch 7, Batch 4960/5867, Loss: 0.0589\n",
      "Epoch 7, Batch 4970/5867, Loss: 0.1126\n",
      "Epoch 7, Batch 4980/5867, Loss: 0.3580\n",
      "Epoch 7, Batch 4990/5867, Loss: 0.1791\n",
      "Epoch 7, Batch 5000/5867, Loss: 0.0614\n",
      "Epoch 7, Batch 5010/5867, Loss: 0.1865\n",
      "Epoch 7, Batch 5020/5867, Loss: 0.1802\n",
      "Epoch 7, Batch 5030/5867, Loss: 0.1187\n",
      "Epoch 7, Batch 5040/5867, Loss: 0.2306\n",
      "Epoch 7, Batch 5050/5867, Loss: 0.2398\n",
      "Epoch 7, Batch 5060/5867, Loss: 0.2859\n",
      "Epoch 7, Batch 5070/5867, Loss: 0.2331\n",
      "Epoch 7, Batch 5080/5867, Loss: 0.2040\n",
      "Epoch 7, Batch 5090/5867, Loss: 0.1939\n",
      "Epoch 7, Batch 5100/5867, Loss: 0.1477\n",
      "Epoch 7, Batch 5110/5867, Loss: 0.4121\n",
      "Epoch 7, Batch 5120/5867, Loss: 0.1883\n",
      "Epoch 7, Batch 5130/5867, Loss: 0.1238\n",
      "Epoch 7, Batch 5140/5867, Loss: 0.1485\n",
      "Epoch 7, Batch 5150/5867, Loss: 0.1357\n",
      "Epoch 7, Batch 5160/5867, Loss: 0.1736\n",
      "Epoch 7, Batch 5170/5867, Loss: 0.1805\n",
      "Epoch 7, Batch 5180/5867, Loss: 0.0716\n",
      "Epoch 7, Batch 5190/5867, Loss: 0.2061\n",
      "Epoch 7, Batch 5200/5867, Loss: 0.5238\n",
      "Epoch 7, Batch 5210/5867, Loss: 0.2898\n",
      "Epoch 7, Batch 5220/5867, Loss: 0.2503\n",
      "Epoch 7, Batch 5230/5867, Loss: 0.3357\n",
      "Epoch 7, Batch 5240/5867, Loss: 0.3178\n",
      "Epoch 7, Batch 5250/5867, Loss: 0.1086\n",
      "Epoch 7, Batch 5260/5867, Loss: 0.2124\n",
      "Epoch 7, Batch 5270/5867, Loss: 0.2356\n",
      "Epoch 7, Batch 5280/5867, Loss: 0.2789\n",
      "Epoch 7, Batch 5290/5867, Loss: 0.0638\n",
      "Epoch 7, Batch 5300/5867, Loss: 0.2849\n",
      "Epoch 7, Batch 5310/5867, Loss: 0.2186\n",
      "Epoch 7, Batch 5320/5867, Loss: 0.1490\n",
      "Epoch 7, Batch 5330/5867, Loss: 0.1617\n",
      "Epoch 7, Batch 5340/5867, Loss: 0.3194\n",
      "Epoch 7, Batch 5350/5867, Loss: 0.2193\n",
      "Epoch 7, Batch 5360/5867, Loss: 0.2166\n",
      "Epoch 7, Batch 5370/5867, Loss: 0.2083\n",
      "Epoch 7, Batch 5380/5867, Loss: 0.0883\n",
      "Epoch 7, Batch 5390/5867, Loss: 0.2561\n",
      "Epoch 7, Batch 5400/5867, Loss: 0.1180\n",
      "Epoch 7, Batch 5410/5867, Loss: 0.2020\n",
      "Epoch 7, Batch 5420/5867, Loss: 0.0802\n",
      "Epoch 7, Batch 5430/5867, Loss: 0.2236\n",
      "Epoch 7, Batch 5440/5867, Loss: 0.0715\n",
      "Epoch 7, Batch 5450/5867, Loss: 0.2230\n",
      "Epoch 7, Batch 5460/5867, Loss: 0.2440\n",
      "Epoch 7, Batch 5470/5867, Loss: 0.2687\n",
      "Epoch 7, Batch 5480/5867, Loss: 0.0780\n",
      "Epoch 7, Batch 5490/5867, Loss: 0.2559\n",
      "Epoch 7, Batch 5500/5867, Loss: 0.0954\n",
      "Epoch 7, Batch 5510/5867, Loss: 0.1038\n",
      "Epoch 7, Batch 5520/5867, Loss: 0.1163\n",
      "Epoch 7, Batch 5530/5867, Loss: 0.1835\n",
      "Epoch 7, Batch 5540/5867, Loss: 0.3608\n",
      "Epoch 7, Batch 5550/5867, Loss: 0.3205\n",
      "Epoch 7, Batch 5560/5867, Loss: 0.1513\n",
      "Epoch 7, Batch 5570/5867, Loss: 0.0983\n",
      "Epoch 7, Batch 5580/5867, Loss: 0.2633\n",
      "Epoch 7, Batch 5590/5867, Loss: 0.0964\n",
      "Epoch 7, Batch 5600/5867, Loss: 0.1774\n",
      "Epoch 7, Batch 5610/5867, Loss: 0.0946\n",
      "Epoch 7, Batch 5620/5867, Loss: 0.3910\n",
      "Epoch 7, Batch 5630/5867, Loss: 0.1871\n",
      "Epoch 7, Batch 5640/5867, Loss: 0.1956\n",
      "Epoch 7, Batch 5650/5867, Loss: 0.1261\n",
      "Epoch 7, Batch 5660/5867, Loss: 0.1288\n",
      "Epoch 7, Batch 5670/5867, Loss: 0.2208\n",
      "Epoch 7, Batch 5680/5867, Loss: 0.0738\n",
      "Epoch 7, Batch 5690/5867, Loss: 0.1585\n",
      "Epoch 7, Batch 5700/5867, Loss: 0.1577\n",
      "Epoch 7, Batch 5710/5867, Loss: 0.0811\n",
      "Epoch 7, Batch 5720/5867, Loss: 0.1644\n",
      "Epoch 7, Batch 5730/5867, Loss: 0.1385\n",
      "Epoch 7, Batch 5740/5867, Loss: 0.0742\n",
      "Epoch 7, Batch 5750/5867, Loss: 0.1114\n",
      "Epoch 7, Batch 5760/5867, Loss: 0.1957\n",
      "Epoch 7, Batch 5770/5867, Loss: 0.2374\n",
      "Epoch 7, Batch 5780/5867, Loss: 0.2627\n",
      "Epoch 7, Batch 5790/5867, Loss: 0.1097\n",
      "Epoch 7, Batch 5800/5867, Loss: 0.0620\n",
      "Epoch 7, Batch 5810/5867, Loss: 0.1319\n",
      "Epoch 7, Batch 5820/5867, Loss: 0.2874\n",
      "Epoch 7, Batch 5830/5867, Loss: 0.2148\n",
      "Epoch 7, Batch 5840/5867, Loss: 0.1561\n",
      "Epoch 7, Batch 5850/5867, Loss: 0.0939\n",
      "Epoch 7, Batch 5860/5867, Loss: 0.2185\n",
      "Epoch 7, Training Loss: 0.1879, Validation Loss: 0.1862\n",
      "Starting epoch 8...\n",
      "Epoch 8, Batch 10/5867, Loss: 0.1232\n",
      "Epoch 8, Batch 20/5867, Loss: 0.2050\n",
      "Epoch 8, Batch 30/5867, Loss: 0.1157\n",
      "Epoch 8, Batch 40/5867, Loss: 0.1978\n",
      "Epoch 8, Batch 50/5867, Loss: 0.1789\n",
      "Epoch 8, Batch 60/5867, Loss: 0.1478\n",
      "Epoch 8, Batch 70/5867, Loss: 0.1395\n",
      "Epoch 8, Batch 80/5867, Loss: 0.1293\n",
      "Epoch 8, Batch 90/5867, Loss: 0.2106\n",
      "Epoch 8, Batch 100/5867, Loss: 0.1402\n",
      "Epoch 8, Batch 110/5867, Loss: 0.1904\n",
      "Epoch 8, Batch 120/5867, Loss: 0.1375\n",
      "Epoch 8, Batch 130/5867, Loss: 0.2612\n",
      "Epoch 8, Batch 140/5867, Loss: 0.0248\n",
      "Epoch 8, Batch 150/5867, Loss: 0.2378\n",
      "Epoch 8, Batch 160/5867, Loss: 0.1395\n",
      "Epoch 8, Batch 170/5867, Loss: 0.1425\n",
      "Epoch 8, Batch 180/5867, Loss: 0.1051\n",
      "Epoch 8, Batch 190/5867, Loss: 0.1821\n",
      "Epoch 8, Batch 200/5867, Loss: 0.1090\n",
      "Epoch 8, Batch 210/5867, Loss: 0.0753\n",
      "Epoch 8, Batch 220/5867, Loss: 0.1850\n",
      "Epoch 8, Batch 230/5867, Loss: 0.2061\n",
      "Epoch 8, Batch 240/5867, Loss: 0.2202\n",
      "Epoch 8, Batch 250/5867, Loss: 0.1175\n",
      "Epoch 8, Batch 260/5867, Loss: 0.0778\n",
      "Epoch 8, Batch 270/5867, Loss: 0.1856\n",
      "Epoch 8, Batch 280/5867, Loss: 0.2704\n",
      "Epoch 8, Batch 290/5867, Loss: 0.0774\n",
      "Epoch 8, Batch 300/5867, Loss: 0.1178\n",
      "Epoch 8, Batch 310/5867, Loss: 0.1316\n",
      "Epoch 8, Batch 320/5867, Loss: 0.1822\n",
      "Epoch 8, Batch 330/5867, Loss: 0.1245\n",
      "Epoch 8, Batch 340/5867, Loss: 0.3070\n",
      "Epoch 8, Batch 350/5867, Loss: 0.0756\n",
      "Epoch 8, Batch 360/5867, Loss: 0.2689\n",
      "Epoch 8, Batch 370/5867, Loss: 0.2667\n",
      "Epoch 8, Batch 380/5867, Loss: 0.3649\n",
      "Epoch 8, Batch 390/5867, Loss: 0.1735\n",
      "Epoch 8, Batch 400/5867, Loss: 0.1655\n",
      "Epoch 8, Batch 410/5867, Loss: 0.1215\n",
      "Epoch 8, Batch 420/5867, Loss: 0.0792\n",
      "Epoch 8, Batch 430/5867, Loss: 0.0596\n",
      "Epoch 8, Batch 440/5867, Loss: 0.1081\n",
      "Epoch 8, Batch 450/5867, Loss: 0.2410\n",
      "Epoch 8, Batch 460/5867, Loss: 0.0878\n",
      "Epoch 8, Batch 470/5867, Loss: 0.2122\n",
      "Epoch 8, Batch 480/5867, Loss: 0.1434\n",
      "Epoch 8, Batch 490/5867, Loss: 0.1391\n",
      "Epoch 8, Batch 500/5867, Loss: 0.1902\n",
      "Epoch 8, Batch 510/5867, Loss: 0.2370\n",
      "Epoch 8, Batch 520/5867, Loss: 0.1764\n",
      "Epoch 8, Batch 530/5867, Loss: 0.2236\n",
      "Epoch 8, Batch 540/5867, Loss: 0.2037\n",
      "Epoch 8, Batch 550/5867, Loss: 0.1999\n",
      "Epoch 8, Batch 560/5867, Loss: 0.1795\n",
      "Epoch 8, Batch 570/5867, Loss: 0.1360\n",
      "Epoch 8, Batch 580/5867, Loss: 0.1813\n",
      "Epoch 8, Batch 590/5867, Loss: 0.4819\n",
      "Epoch 8, Batch 600/5867, Loss: 0.2331\n",
      "Epoch 8, Batch 610/5867, Loss: 0.2760\n",
      "Epoch 8, Batch 620/5867, Loss: 0.2284\n",
      "Epoch 8, Batch 630/5867, Loss: 0.0292\n",
      "Epoch 8, Batch 640/5867, Loss: 0.1174\n",
      "Epoch 8, Batch 650/5867, Loss: 0.1844\n",
      "Epoch 8, Batch 660/5867, Loss: 0.2817\n",
      "Epoch 8, Batch 670/5867, Loss: 0.4403\n",
      "Epoch 8, Batch 680/5867, Loss: 0.2826\n",
      "Epoch 8, Batch 690/5867, Loss: 0.1438\n",
      "Epoch 8, Batch 700/5867, Loss: 0.1279\n",
      "Epoch 8, Batch 710/5867, Loss: 0.1182\n",
      "Epoch 8, Batch 720/5867, Loss: 0.3186\n",
      "Epoch 8, Batch 730/5867, Loss: 0.1464\n",
      "Epoch 8, Batch 740/5867, Loss: 0.3378\n",
      "Epoch 8, Batch 750/5867, Loss: 0.0993\n",
      "Epoch 8, Batch 760/5867, Loss: 0.2517\n",
      "Epoch 8, Batch 770/5867, Loss: 0.0758\n",
      "Epoch 8, Batch 780/5867, Loss: 0.0972\n",
      "Epoch 8, Batch 790/5867, Loss: 0.2732\n",
      "Epoch 8, Batch 800/5867, Loss: 0.0900\n",
      "Epoch 8, Batch 810/5867, Loss: 0.1063\n",
      "Epoch 8, Batch 820/5867, Loss: 0.2485\n",
      "Epoch 8, Batch 830/5867, Loss: 0.0764\n",
      "Epoch 8, Batch 840/5867, Loss: 0.1904\n",
      "Epoch 8, Batch 850/5867, Loss: 0.3797\n",
      "Epoch 8, Batch 860/5867, Loss: 0.1134\n",
      "Epoch 8, Batch 870/5867, Loss: 0.1417\n",
      "Epoch 8, Batch 880/5867, Loss: 0.2050\n",
      "Epoch 8, Batch 890/5867, Loss: 0.1052\n",
      "Epoch 8, Batch 900/5867, Loss: 0.3480\n",
      "Epoch 8, Batch 910/5867, Loss: 0.1809\n",
      "Epoch 8, Batch 920/5867, Loss: 0.2234\n",
      "Epoch 8, Batch 930/5867, Loss: 0.3862\n",
      "Epoch 8, Batch 940/5867, Loss: 0.1680\n",
      "Epoch 8, Batch 950/5867, Loss: 0.1528\n",
      "Epoch 8, Batch 960/5867, Loss: 0.2443\n",
      "Epoch 8, Batch 970/5867, Loss: 0.3098\n",
      "Epoch 8, Batch 980/5867, Loss: 0.1544\n",
      "Epoch 8, Batch 990/5867, Loss: 0.1555\n",
      "Epoch 8, Batch 1000/5867, Loss: 0.2525\n",
      "Epoch 8, Batch 1010/5867, Loss: 0.1403\n",
      "Epoch 8, Batch 1020/5867, Loss: 0.0941\n",
      "Epoch 8, Batch 1030/5867, Loss: 0.2181\n",
      "Epoch 8, Batch 1040/5867, Loss: 0.0753\n",
      "Epoch 8, Batch 1050/5867, Loss: 0.2813\n",
      "Epoch 8, Batch 1060/5867, Loss: 0.2007\n",
      "Epoch 8, Batch 1070/5867, Loss: 0.0953\n",
      "Epoch 8, Batch 1080/5867, Loss: 0.2008\n",
      "Epoch 8, Batch 1090/5867, Loss: 0.0722\n",
      "Epoch 8, Batch 1100/5867, Loss: 0.2318\n",
      "Epoch 8, Batch 1110/5867, Loss: 0.1949\n",
      "Epoch 8, Batch 1120/5867, Loss: 0.0919\n",
      "Epoch 8, Batch 1130/5867, Loss: 0.0874\n",
      "Epoch 8, Batch 1140/5867, Loss: 0.0917\n",
      "Epoch 8, Batch 1150/5867, Loss: 0.0991\n",
      "Epoch 8, Batch 1160/5867, Loss: 0.2830\n",
      "Epoch 8, Batch 1170/5867, Loss: 0.1236\n",
      "Epoch 8, Batch 1180/5867, Loss: 0.0950\n",
      "Epoch 8, Batch 1190/5867, Loss: 0.1887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 1200/5867, Loss: 0.1529\n",
      "Epoch 8, Batch 1210/5867, Loss: 0.3183\n",
      "Epoch 8, Batch 1220/5867, Loss: 0.1236\n",
      "Epoch 8, Batch 1230/5867, Loss: 0.2164\n",
      "Epoch 8, Batch 1240/5867, Loss: 0.1009\n",
      "Epoch 8, Batch 1250/5867, Loss: 0.1833\n",
      "Epoch 8, Batch 1260/5867, Loss: 0.1344\n",
      "Epoch 8, Batch 1270/5867, Loss: 0.1799\n",
      "Epoch 8, Batch 1280/5867, Loss: 0.1979\n",
      "Epoch 8, Batch 1290/5867, Loss: 0.1359\n",
      "Epoch 8, Batch 1300/5867, Loss: 0.1050\n",
      "Epoch 8, Batch 1310/5867, Loss: 0.1168\n",
      "Epoch 8, Batch 1320/5867, Loss: 0.1795\n",
      "Epoch 8, Batch 1330/5867, Loss: 0.2430\n",
      "Epoch 8, Batch 1340/5867, Loss: 0.1841\n",
      "Epoch 8, Batch 1350/5867, Loss: 0.4726\n",
      "Epoch 8, Batch 1360/5867, Loss: 0.1583\n",
      "Epoch 8, Batch 1370/5867, Loss: 0.2895\n",
      "Epoch 8, Batch 1380/5867, Loss: 0.1255\n",
      "Epoch 8, Batch 1390/5867, Loss: 0.0510\n",
      "Epoch 8, Batch 1400/5867, Loss: 0.3941\n",
      "Epoch 8, Batch 1410/5867, Loss: 0.2491\n",
      "Epoch 8, Batch 1420/5867, Loss: 0.1419\n",
      "Epoch 8, Batch 1430/5867, Loss: 0.1744\n",
      "Epoch 8, Batch 1440/5867, Loss: 0.0847\n",
      "Epoch 8, Batch 1450/5867, Loss: 0.0778\n",
      "Epoch 8, Batch 1460/5867, Loss: 0.2400\n",
      "Epoch 8, Batch 1470/5867, Loss: 0.1150\n",
      "Epoch 8, Batch 1480/5867, Loss: 0.1121\n",
      "Epoch 8, Batch 1490/5867, Loss: 0.1445\n",
      "Epoch 8, Batch 1500/5867, Loss: 0.1429\n",
      "Epoch 8, Batch 1510/5867, Loss: 0.2178\n",
      "Epoch 8, Batch 1520/5867, Loss: 0.2444\n",
      "Epoch 8, Batch 1530/5867, Loss: 0.1962\n",
      "Epoch 8, Batch 1540/5867, Loss: 0.0646\n",
      "Epoch 8, Batch 1550/5867, Loss: 0.0929\n",
      "Epoch 8, Batch 1560/5867, Loss: 0.1273\n",
      "Epoch 8, Batch 1570/5867, Loss: 0.2373\n",
      "Epoch 8, Batch 1580/5867, Loss: 0.1577\n",
      "Epoch 8, Batch 1590/5867, Loss: 0.1193\n",
      "Epoch 8, Batch 1600/5867, Loss: 0.2051\n",
      "Epoch 8, Batch 1610/5867, Loss: 0.1080\n",
      "Epoch 8, Batch 1620/5867, Loss: 0.1834\n",
      "Epoch 8, Batch 1630/5867, Loss: 0.1313\n",
      "Epoch 8, Batch 1640/5867, Loss: 0.2219\n",
      "Epoch 8, Batch 1650/5867, Loss: 0.0546\n",
      "Epoch 8, Batch 1660/5867, Loss: 0.1423\n",
      "Epoch 8, Batch 1670/5867, Loss: 0.1980\n",
      "Epoch 8, Batch 1680/5867, Loss: 0.2280\n",
      "Epoch 8, Batch 1690/5867, Loss: 0.1851\n",
      "Epoch 8, Batch 1700/5867, Loss: 0.2669\n",
      "Epoch 8, Batch 1710/5867, Loss: 0.1634\n",
      "Epoch 8, Batch 1720/5867, Loss: 0.2588\n",
      "Epoch 8, Batch 1730/5867, Loss: 0.0881\n",
      "Epoch 8, Batch 1740/5867, Loss: 0.1996\n",
      "Epoch 8, Batch 1750/5867, Loss: 0.2791\n",
      "Epoch 8, Batch 1760/5867, Loss: 0.1811\n",
      "Epoch 8, Batch 1770/5867, Loss: 0.4365\n",
      "Epoch 8, Batch 1780/5867, Loss: 0.1012\n",
      "Epoch 8, Batch 1790/5867, Loss: 0.3502\n",
      "Epoch 8, Batch 1800/5867, Loss: 0.2086\n",
      "Epoch 8, Batch 1810/5867, Loss: 0.1051\n",
      "Epoch 8, Batch 1820/5867, Loss: 0.2631\n",
      "Epoch 8, Batch 1830/5867, Loss: 0.1342\n",
      "Epoch 8, Batch 1840/5867, Loss: 0.2583\n",
      "Epoch 8, Batch 1850/5867, Loss: 0.4370\n",
      "Epoch 8, Batch 1860/5867, Loss: 0.1194\n",
      "Epoch 8, Batch 1870/5867, Loss: 0.2144\n",
      "Epoch 8, Batch 1880/5867, Loss: 0.1258\n",
      "Epoch 8, Batch 1890/5867, Loss: 0.2982\n",
      "Epoch 8, Batch 1900/5867, Loss: 0.0571\n",
      "Epoch 8, Batch 1910/5867, Loss: 0.1501\n",
      "Epoch 8, Batch 1920/5867, Loss: 0.3026\n",
      "Epoch 8, Batch 1930/5867, Loss: 0.1782\n",
      "Epoch 8, Batch 1940/5867, Loss: 0.1736\n",
      "Epoch 8, Batch 1950/5867, Loss: 0.0973\n",
      "Epoch 8, Batch 1960/5867, Loss: 0.0959\n",
      "Epoch 8, Batch 1970/5867, Loss: 0.1667\n",
      "Epoch 8, Batch 1980/5867, Loss: 0.2391\n",
      "Epoch 8, Batch 1990/5867, Loss: 0.3335\n",
      "Epoch 8, Batch 2000/5867, Loss: 0.3281\n",
      "Epoch 8, Batch 2010/5867, Loss: 0.2311\n",
      "Epoch 8, Batch 2020/5867, Loss: 0.4257\n",
      "Epoch 8, Batch 2030/5867, Loss: 0.1360\n",
      "Epoch 8, Batch 2040/5867, Loss: 0.0813\n",
      "Epoch 8, Batch 2050/5867, Loss: 0.2673\n",
      "Epoch 8, Batch 2060/5867, Loss: 0.2309\n",
      "Epoch 8, Batch 2070/5867, Loss: 0.2277\n",
      "Epoch 8, Batch 2080/5867, Loss: 0.2098\n",
      "Epoch 8, Batch 2090/5867, Loss: 0.2122\n",
      "Epoch 8, Batch 2100/5867, Loss: 0.3032\n",
      "Epoch 8, Batch 2110/5867, Loss: 0.1316\n",
      "Epoch 8, Batch 2120/5867, Loss: 0.2165\n",
      "Epoch 8, Batch 2130/5867, Loss: 0.1935\n",
      "Epoch 8, Batch 2140/5867, Loss: 0.1213\n",
      "Epoch 8, Batch 2150/5867, Loss: 0.1722\n",
      "Epoch 8, Batch 2160/5867, Loss: 0.1322\n",
      "Epoch 8, Batch 2170/5867, Loss: 0.3620\n",
      "Epoch 8, Batch 2180/5867, Loss: 0.0826\n",
      "Epoch 8, Batch 2190/5867, Loss: 0.2856\n",
      "Epoch 8, Batch 2200/5867, Loss: 0.2482\n",
      "Epoch 8, Batch 2210/5867, Loss: 0.2417\n",
      "Epoch 8, Batch 2220/5867, Loss: 0.0758\n",
      "Epoch 8, Batch 2230/5867, Loss: 0.1863\n",
      "Epoch 8, Batch 2240/5867, Loss: 0.0736\n",
      "Epoch 8, Batch 2250/5867, Loss: 0.1169\n",
      "Epoch 8, Batch 2260/5867, Loss: 0.2228\n",
      "Epoch 8, Batch 2270/5867, Loss: 0.0679\n",
      "Epoch 8, Batch 2280/5867, Loss: 0.2648\n",
      "Epoch 8, Batch 2290/5867, Loss: 0.2389\n",
      "Epoch 8, Batch 2300/5867, Loss: 0.1524\n",
      "Epoch 8, Batch 2310/5867, Loss: 0.1957\n",
      "Epoch 8, Batch 2320/5867, Loss: 0.2323\n",
      "Epoch 8, Batch 2330/5867, Loss: 0.1039\n",
      "Epoch 8, Batch 2340/5867, Loss: 0.2322\n",
      "Epoch 8, Batch 2350/5867, Loss: 0.1188\n",
      "Epoch 8, Batch 2360/5867, Loss: 0.2783\n",
      "Epoch 8, Batch 2370/5867, Loss: 0.2017\n",
      "Epoch 8, Batch 2380/5867, Loss: 0.3896\n",
      "Epoch 8, Batch 2390/5867, Loss: 0.2704\n",
      "Epoch 8, Batch 2400/5867, Loss: 0.3592\n",
      "Epoch 8, Batch 2410/5867, Loss: 0.2134\n",
      "Epoch 8, Batch 2420/5867, Loss: 0.0475\n",
      "Epoch 8, Batch 2430/5867, Loss: 0.2419\n",
      "Epoch 8, Batch 2440/5867, Loss: 0.2479\n",
      "Epoch 8, Batch 2450/5867, Loss: 0.0719\n",
      "Epoch 8, Batch 2460/5867, Loss: 0.1391\n",
      "Epoch 8, Batch 2470/5867, Loss: 0.2198\n",
      "Epoch 8, Batch 2480/5867, Loss: 0.0938\n",
      "Epoch 8, Batch 2490/5867, Loss: 0.1346\n",
      "Epoch 8, Batch 2500/5867, Loss: 0.1257\n",
      "Epoch 8, Batch 2510/5867, Loss: 0.1598\n",
      "Epoch 8, Batch 2520/5867, Loss: 0.0625\n",
      "Epoch 8, Batch 2530/5867, Loss: 0.1848\n",
      "Epoch 8, Batch 2540/5867, Loss: 0.2339\n",
      "Epoch 8, Batch 2550/5867, Loss: 0.3770\n",
      "Epoch 8, Batch 2560/5867, Loss: 0.3020\n",
      "Epoch 8, Batch 2570/5867, Loss: 0.1263\n",
      "Epoch 8, Batch 2580/5867, Loss: 0.2799\n",
      "Epoch 8, Batch 2590/5867, Loss: 0.0919\n",
      "Epoch 8, Batch 2600/5867, Loss: 0.2270\n",
      "Epoch 8, Batch 2610/5867, Loss: 0.1566\n",
      "Epoch 8, Batch 2620/5867, Loss: 0.1995\n",
      "Epoch 8, Batch 2630/5867, Loss: 0.0922\n",
      "Epoch 8, Batch 2640/5867, Loss: 0.1553\n",
      "Epoch 8, Batch 2650/5867, Loss: 0.1644\n",
      "Epoch 8, Batch 2660/5867, Loss: 0.1989\n",
      "Epoch 8, Batch 2670/5867, Loss: 0.3784\n",
      "Epoch 8, Batch 2680/5867, Loss: 0.2201\n",
      "Epoch 8, Batch 2690/5867, Loss: 0.2337\n",
      "Epoch 8, Batch 2700/5867, Loss: 0.1621\n",
      "Epoch 8, Batch 2710/5867, Loss: 0.1340\n",
      "Epoch 8, Batch 2720/5867, Loss: 0.1139\n",
      "Epoch 8, Batch 2730/5867, Loss: 0.2807\n",
      "Epoch 8, Batch 2740/5867, Loss: 0.1538\n",
      "Epoch 8, Batch 2750/5867, Loss: 0.1372\n",
      "Epoch 8, Batch 2760/5867, Loss: 0.1948\n",
      "Epoch 8, Batch 2770/5867, Loss: 0.2759\n",
      "Epoch 8, Batch 2780/5867, Loss: 0.1763\n",
      "Epoch 8, Batch 2790/5867, Loss: 0.1655\n",
      "Epoch 8, Batch 2800/5867, Loss: 0.2054\n",
      "Epoch 8, Batch 2810/5867, Loss: 0.2358\n",
      "Epoch 8, Batch 2820/5867, Loss: 0.1167\n",
      "Epoch 8, Batch 2830/5867, Loss: 0.2399\n",
      "Epoch 8, Batch 2840/5867, Loss: 0.1396\n",
      "Epoch 8, Batch 2850/5867, Loss: 0.1878\n",
      "Epoch 8, Batch 2860/5867, Loss: 0.4028\n",
      "Epoch 8, Batch 2870/5867, Loss: 0.1054\n",
      "Epoch 8, Batch 2880/5867, Loss: 0.1181\n",
      "Epoch 8, Batch 2890/5867, Loss: 0.4388\n",
      "Epoch 8, Batch 2900/5867, Loss: 0.3582\n",
      "Epoch 8, Batch 2910/5867, Loss: 0.2618\n",
      "Epoch 8, Batch 2920/5867, Loss: 0.1731\n",
      "Epoch 8, Batch 2930/5867, Loss: 0.2894\n",
      "Epoch 8, Batch 2940/5867, Loss: 0.2841\n",
      "Epoch 8, Batch 2950/5867, Loss: 0.3406\n",
      "Epoch 8, Batch 2960/5867, Loss: 0.1595\n",
      "Epoch 8, Batch 2970/5867, Loss: 0.1581\n",
      "Epoch 8, Batch 2980/5867, Loss: 0.1636\n",
      "Epoch 8, Batch 2990/5867, Loss: 0.0997\n",
      "Epoch 8, Batch 3000/5867, Loss: 0.2577\n",
      "Epoch 8, Batch 3010/5867, Loss: 0.1207\n",
      "Epoch 8, Batch 3020/5867, Loss: 0.1120\n",
      "Epoch 8, Batch 3030/5867, Loss: 0.1068\n",
      "Epoch 8, Batch 3040/5867, Loss: 0.1276\n",
      "Epoch 8, Batch 3050/5867, Loss: 0.2936\n",
      "Epoch 8, Batch 3060/5867, Loss: 0.3079\n",
      "Epoch 8, Batch 3070/5867, Loss: 0.2662\n",
      "Epoch 8, Batch 3080/5867, Loss: 0.0979\n",
      "Epoch 8, Batch 3090/5867, Loss: 0.0946\n",
      "Epoch 8, Batch 3100/5867, Loss: 0.0960\n",
      "Epoch 8, Batch 3110/5867, Loss: 0.1703\n",
      "Epoch 8, Batch 3120/5867, Loss: 0.1624\n",
      "Epoch 8, Batch 3130/5867, Loss: 0.0696\n",
      "Epoch 8, Batch 3140/5867, Loss: 0.1878\n",
      "Epoch 8, Batch 3150/5867, Loss: 0.0680\n",
      "Epoch 8, Batch 3160/5867, Loss: 0.1288\n",
      "Epoch 8, Batch 3170/5867, Loss: 0.1737\n",
      "Epoch 8, Batch 3180/5867, Loss: 0.1547\n",
      "Epoch 8, Batch 3190/5867, Loss: 0.1207\n",
      "Epoch 8, Batch 3200/5867, Loss: 0.2009\n",
      "Epoch 8, Batch 3210/5867, Loss: 0.2232\n",
      "Epoch 8, Batch 3220/5867, Loss: 0.1449\n",
      "Epoch 8, Batch 3230/5867, Loss: 0.0723\n",
      "Epoch 8, Batch 3240/5867, Loss: 0.1429\n",
      "Epoch 8, Batch 3250/5867, Loss: 0.1398\n",
      "Epoch 8, Batch 3260/5867, Loss: 0.1142\n",
      "Epoch 8, Batch 3270/5867, Loss: 0.1291\n",
      "Epoch 8, Batch 3280/5867, Loss: 0.3065\n",
      "Epoch 8, Batch 3290/5867, Loss: 0.2008\n",
      "Epoch 8, Batch 3300/5867, Loss: 0.1550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 3310/5867, Loss: 0.4339\n",
      "Epoch 8, Batch 3320/5867, Loss: 0.1282\n",
      "Epoch 8, Batch 3330/5867, Loss: 0.1474\n",
      "Epoch 8, Batch 3340/5867, Loss: 0.1450\n",
      "Epoch 8, Batch 3350/5867, Loss: 0.1319\n",
      "Epoch 8, Batch 3360/5867, Loss: 0.1166\n",
      "Epoch 8, Batch 3370/5867, Loss: 0.0943\n",
      "Epoch 8, Batch 3380/5867, Loss: 0.1045\n",
      "Epoch 8, Batch 3390/5867, Loss: 0.3377\n",
      "Epoch 8, Batch 3400/5867, Loss: 0.1916\n",
      "Epoch 8, Batch 3410/5867, Loss: 0.2346\n",
      "Epoch 8, Batch 3420/5867, Loss: 0.2424\n",
      "Epoch 8, Batch 3430/5867, Loss: 0.1204\n",
      "Epoch 8, Batch 3440/5867, Loss: 0.0858\n",
      "Epoch 8, Batch 3450/5867, Loss: 0.1049\n",
      "Epoch 8, Batch 3460/5867, Loss: 0.2969\n",
      "Epoch 8, Batch 3470/5867, Loss: 0.3763\n",
      "Epoch 8, Batch 3480/5867, Loss: 0.2143\n",
      "Epoch 8, Batch 3490/5867, Loss: 0.1202\n",
      "Epoch 8, Batch 3500/5867, Loss: 0.4150\n",
      "Epoch 8, Batch 3510/5867, Loss: 0.1589\n",
      "Epoch 8, Batch 3520/5867, Loss: 0.5645\n",
      "Epoch 8, Batch 3530/5867, Loss: 0.2283\n",
      "Epoch 8, Batch 3540/5867, Loss: 0.2202\n",
      "Epoch 8, Batch 3550/5867, Loss: 0.1281\n",
      "Epoch 8, Batch 3560/5867, Loss: 0.5348\n",
      "Epoch 8, Batch 3570/5867, Loss: 0.1045\n",
      "Epoch 8, Batch 3580/5867, Loss: 0.2133\n",
      "Epoch 8, Batch 3590/5867, Loss: 0.2697\n",
      "Epoch 8, Batch 3600/5867, Loss: 0.1958\n",
      "Epoch 8, Batch 3610/5867, Loss: 0.2788\n",
      "Epoch 8, Batch 3620/5867, Loss: 0.1946\n",
      "Epoch 8, Batch 3630/5867, Loss: 0.1409\n",
      "Epoch 8, Batch 3640/5867, Loss: 0.2037\n",
      "Epoch 8, Batch 3650/5867, Loss: 0.0528\n",
      "Epoch 8, Batch 3660/5867, Loss: 0.1689\n",
      "Epoch 8, Batch 3670/5867, Loss: 0.1916\n",
      "Epoch 8, Batch 3680/5867, Loss: 0.1524\n",
      "Epoch 8, Batch 3690/5867, Loss: 0.2414\n",
      "Epoch 8, Batch 3700/5867, Loss: 0.1361\n",
      "Epoch 8, Batch 3710/5867, Loss: 0.1324\n",
      "Epoch 8, Batch 3720/5867, Loss: 0.0958\n",
      "Epoch 8, Batch 3730/5867, Loss: 0.1923\n",
      "Epoch 8, Batch 3740/5867, Loss: 0.1749\n",
      "Epoch 8, Batch 3750/5867, Loss: 0.1372\n",
      "Epoch 8, Batch 3760/5867, Loss: 0.0897\n",
      "Epoch 8, Batch 3770/5867, Loss: 0.0961\n",
      "Epoch 8, Batch 3780/5867, Loss: 0.1644\n",
      "Epoch 8, Batch 3790/5867, Loss: 0.1007\n",
      "Epoch 8, Batch 3800/5867, Loss: 0.0876\n",
      "Epoch 8, Batch 3810/5867, Loss: 0.1912\n",
      "Epoch 8, Batch 3820/5867, Loss: 0.1918\n",
      "Epoch 8, Batch 3830/5867, Loss: 0.1896\n",
      "Epoch 8, Batch 3840/5867, Loss: 0.1529\n",
      "Epoch 8, Batch 3850/5867, Loss: 0.2595\n",
      "Epoch 8, Batch 3860/5867, Loss: 0.0725\n",
      "Epoch 8, Batch 3870/5867, Loss: 0.2714\n",
      "Epoch 8, Batch 3880/5867, Loss: 0.2858\n",
      "Epoch 8, Batch 3890/5867, Loss: 0.0929\n",
      "Epoch 8, Batch 3900/5867, Loss: 0.2364\n",
      "Epoch 8, Batch 3910/5867, Loss: 0.1626\n",
      "Epoch 8, Batch 3920/5867, Loss: 0.3289\n",
      "Epoch 8, Batch 3930/5867, Loss: 0.2633\n",
      "Epoch 8, Batch 3940/5867, Loss: 0.1554\n",
      "Epoch 8, Batch 3950/5867, Loss: 0.1584\n",
      "Epoch 8, Batch 3960/5867, Loss: 0.0887\n",
      "Epoch 8, Batch 3970/5867, Loss: 0.1733\n",
      "Epoch 8, Batch 3980/5867, Loss: 0.0990\n",
      "Epoch 8, Batch 3990/5867, Loss: 0.1651\n",
      "Epoch 8, Batch 4000/5867, Loss: 0.2022\n",
      "Epoch 8, Batch 4010/5867, Loss: 0.0369\n",
      "Epoch 8, Batch 4020/5867, Loss: 0.1393\n",
      "Epoch 8, Batch 4030/5867, Loss: 0.2204\n",
      "Epoch 8, Batch 4040/5867, Loss: 0.2241\n",
      "Epoch 8, Batch 4050/5867, Loss: 0.0988\n",
      "Epoch 8, Batch 4060/5867, Loss: 0.1566\n",
      "Epoch 8, Batch 4070/5867, Loss: 0.2273\n",
      "Epoch 8, Batch 4080/5867, Loss: 0.3486\n",
      "Epoch 8, Batch 4090/5867, Loss: 0.3298\n",
      "Epoch 8, Batch 4100/5867, Loss: 0.2251\n",
      "Epoch 8, Batch 4110/5867, Loss: 0.0959\n",
      "Epoch 8, Batch 4120/5867, Loss: 0.2735\n",
      "Epoch 8, Batch 4130/5867, Loss: 0.3333\n",
      "Epoch 8, Batch 4140/5867, Loss: 0.3086\n",
      "Epoch 8, Batch 4150/5867, Loss: 0.2013\n",
      "Epoch 8, Batch 4160/5867, Loss: 0.1888\n",
      "Epoch 8, Batch 4170/5867, Loss: 0.1883\n",
      "Epoch 8, Batch 4180/5867, Loss: 0.1837\n",
      "Epoch 8, Batch 4190/5867, Loss: 0.3001\n",
      "Epoch 8, Batch 4200/5867, Loss: 0.0759\n",
      "Epoch 8, Batch 4210/5867, Loss: 0.1917\n",
      "Epoch 8, Batch 4220/5867, Loss: 0.3341\n",
      "Epoch 8, Batch 4230/5867, Loss: 0.3129\n",
      "Epoch 8, Batch 4240/5867, Loss: 0.1899\n",
      "Epoch 8, Batch 4250/5867, Loss: 0.1131\n",
      "Epoch 8, Batch 4260/5867, Loss: 0.1468\n",
      "Epoch 8, Batch 4270/5867, Loss: 0.1827\n",
      "Epoch 8, Batch 4280/5867, Loss: 0.2725\n",
      "Epoch 8, Batch 4290/5867, Loss: 0.0903\n",
      "Epoch 8, Batch 4300/5867, Loss: 0.2319\n",
      "Epoch 8, Batch 4310/5867, Loss: 0.2661\n",
      "Epoch 8, Batch 4320/5867, Loss: 0.1547\n",
      "Epoch 8, Batch 4330/5867, Loss: 0.2795\n",
      "Epoch 8, Batch 4340/5867, Loss: 0.4017\n",
      "Epoch 8, Batch 4350/5867, Loss: 0.1197\n",
      "Epoch 8, Batch 4360/5867, Loss: 0.1863\n",
      "Epoch 8, Batch 4370/5867, Loss: 0.1793\n",
      "Epoch 8, Batch 4380/5867, Loss: 0.1771\n",
      "Epoch 8, Batch 4390/5867, Loss: 0.3131\n",
      "Epoch 8, Batch 4400/5867, Loss: 0.1302\n",
      "Epoch 8, Batch 4410/5867, Loss: 0.0719\n",
      "Epoch 8, Batch 4420/5867, Loss: 0.2998\n",
      "Epoch 8, Batch 4430/5867, Loss: 0.2079\n",
      "Epoch 8, Batch 4440/5867, Loss: 0.1120\n",
      "Epoch 8, Batch 4450/5867, Loss: 0.0792\n",
      "Epoch 8, Batch 4460/5867, Loss: 0.0642\n",
      "Epoch 8, Batch 4470/5867, Loss: 0.1726\n",
      "Epoch 8, Batch 4480/5867, Loss: 0.1759\n",
      "Epoch 8, Batch 4490/5867, Loss: 0.2267\n",
      "Epoch 8, Batch 4500/5867, Loss: 0.3208\n",
      "Epoch 8, Batch 4510/5867, Loss: 0.1423\n",
      "Epoch 8, Batch 4520/5867, Loss: 0.1791\n",
      "Epoch 8, Batch 4530/5867, Loss: 0.1149\n",
      "Epoch 8, Batch 4540/5867, Loss: 0.2354\n",
      "Epoch 8, Batch 4550/5867, Loss: 0.1939\n",
      "Epoch 8, Batch 4560/5867, Loss: 0.1050\n",
      "Epoch 8, Batch 4570/5867, Loss: 0.2137\n",
      "Epoch 8, Batch 4580/5867, Loss: 0.2543\n",
      "Epoch 8, Batch 4590/5867, Loss: 0.1607\n",
      "Epoch 8, Batch 4600/5867, Loss: 0.1523\n",
      "Epoch 8, Batch 4610/5867, Loss: 0.6171\n",
      "Epoch 8, Batch 4620/5867, Loss: 0.1829\n",
      "Epoch 8, Batch 4630/5867, Loss: 0.3004\n",
      "Epoch 8, Batch 4640/5867, Loss: 0.1781\n",
      "Epoch 8, Batch 4650/5867, Loss: 0.2279\n",
      "Epoch 8, Batch 4660/5867, Loss: 0.2297\n",
      "Epoch 8, Batch 4670/5867, Loss: 0.1677\n",
      "Epoch 8, Batch 4680/5867, Loss: 0.2193\n",
      "Epoch 8, Batch 4690/5867, Loss: 0.1601\n",
      "Epoch 8, Batch 4700/5867, Loss: 0.1039\n",
      "Epoch 8, Batch 4710/5867, Loss: 0.1493\n",
      "Epoch 8, Batch 4720/5867, Loss: 0.4187\n",
      "Epoch 8, Batch 4730/5867, Loss: 0.1653\n",
      "Epoch 8, Batch 4740/5867, Loss: 0.1100\n",
      "Epoch 8, Batch 4750/5867, Loss: 0.2074\n",
      "Epoch 8, Batch 4760/5867, Loss: 0.1537\n",
      "Epoch 8, Batch 4770/5867, Loss: 0.1227\n",
      "Epoch 8, Batch 4780/5867, Loss: 0.2768\n",
      "Epoch 8, Batch 4790/5867, Loss: 0.3303\n",
      "Epoch 8, Batch 4800/5867, Loss: 0.2140\n",
      "Epoch 8, Batch 4810/5867, Loss: 0.2374\n",
      "Epoch 8, Batch 4820/5867, Loss: 0.2850\n",
      "Epoch 8, Batch 4830/5867, Loss: 0.1004\n",
      "Epoch 8, Batch 4840/5867, Loss: 0.2418\n",
      "Epoch 8, Batch 4850/5867, Loss: 0.3643\n",
      "Epoch 8, Batch 4860/5867, Loss: 0.1380\n",
      "Epoch 8, Batch 4870/5867, Loss: 0.1461\n",
      "Epoch 8, Batch 4880/5867, Loss: 0.1043\n",
      "Epoch 8, Batch 4890/5867, Loss: 0.0722\n",
      "Epoch 8, Batch 4900/5867, Loss: 0.2390\n",
      "Epoch 8, Batch 4910/5867, Loss: 0.0988\n",
      "Epoch 8, Batch 4920/5867, Loss: 0.1124\n",
      "Epoch 8, Batch 4930/5867, Loss: 0.0843\n",
      "Epoch 8, Batch 4940/5867, Loss: 0.2419\n",
      "Epoch 8, Batch 4950/5867, Loss: 0.1369\n",
      "Epoch 8, Batch 4960/5867, Loss: 0.1657\n",
      "Epoch 8, Batch 4970/5867, Loss: 0.0554\n",
      "Epoch 8, Batch 4980/5867, Loss: 0.1152\n",
      "Epoch 8, Batch 4990/5867, Loss: 0.1012\n",
      "Epoch 8, Batch 5000/5867, Loss: 0.1671\n",
      "Epoch 8, Batch 5010/5867, Loss: 0.1278\n",
      "Epoch 8, Batch 5020/5867, Loss: 0.1267\n",
      "Epoch 8, Batch 5030/5867, Loss: 0.2626\n",
      "Epoch 8, Batch 5040/5867, Loss: 0.1935\n",
      "Epoch 8, Batch 5050/5867, Loss: 0.2618\n",
      "Epoch 8, Batch 5060/5867, Loss: 0.1190\n",
      "Epoch 8, Batch 5070/5867, Loss: 0.3489\n",
      "Epoch 8, Batch 5080/5867, Loss: 0.1477\n",
      "Epoch 8, Batch 5090/5867, Loss: 0.0812\n",
      "Epoch 8, Batch 5100/5867, Loss: 0.1191\n",
      "Epoch 8, Batch 5110/5867, Loss: 0.1544\n",
      "Epoch 8, Batch 5120/5867, Loss: 0.1273\n",
      "Epoch 8, Batch 5130/5867, Loss: 0.2031\n",
      "Epoch 8, Batch 5140/5867, Loss: 0.1364\n",
      "Epoch 8, Batch 5150/5867, Loss: 0.1667\n",
      "Epoch 8, Batch 5160/5867, Loss: 0.1459\n",
      "Epoch 8, Batch 5170/5867, Loss: 0.1997\n",
      "Epoch 8, Batch 5180/5867, Loss: 0.1588\n",
      "Epoch 8, Batch 5190/5867, Loss: 0.3096\n",
      "Epoch 8, Batch 5200/5867, Loss: 0.1049\n",
      "Epoch 8, Batch 5210/5867, Loss: 0.3425\n",
      "Epoch 8, Batch 5220/5867, Loss: 0.0567\n",
      "Epoch 8, Batch 5230/5867, Loss: 0.0592\n",
      "Epoch 8, Batch 5240/5867, Loss: 0.1164\n",
      "Epoch 8, Batch 5250/5867, Loss: 0.1884\n",
      "Epoch 8, Batch 5260/5867, Loss: 0.1502\n",
      "Epoch 8, Batch 5270/5867, Loss: 0.1131\n",
      "Epoch 8, Batch 5280/5867, Loss: 0.2896\n",
      "Epoch 8, Batch 5290/5867, Loss: 0.2625\n",
      "Epoch 8, Batch 5300/5867, Loss: 0.2513\n",
      "Epoch 8, Batch 5310/5867, Loss: 0.0827\n",
      "Epoch 8, Batch 5320/5867, Loss: 0.2642\n",
      "Epoch 8, Batch 5330/5867, Loss: 0.1551\n",
      "Epoch 8, Batch 5340/5867, Loss: 0.1617\n",
      "Epoch 8, Batch 5350/5867, Loss: 0.3749\n",
      "Epoch 8, Batch 5360/5867, Loss: 0.2087\n",
      "Epoch 8, Batch 5370/5867, Loss: 0.0524\n",
      "Epoch 8, Batch 5380/5867, Loss: 0.1727\n",
      "Epoch 8, Batch 5390/5867, Loss: 0.1808\n",
      "Epoch 8, Batch 5400/5867, Loss: 0.2283\n",
      "Epoch 8, Batch 5410/5867, Loss: 0.1570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 5420/5867, Loss: 0.1428\n",
      "Epoch 8, Batch 5430/5867, Loss: 0.1524\n",
      "Epoch 8, Batch 5440/5867, Loss: 0.1301\n",
      "Epoch 8, Batch 5450/5867, Loss: 0.1089\n",
      "Epoch 8, Batch 5460/5867, Loss: 0.1628\n",
      "Epoch 8, Batch 5470/5867, Loss: 0.3058\n",
      "Epoch 8, Batch 5480/5867, Loss: 0.2042\n",
      "Epoch 8, Batch 5490/5867, Loss: 0.0801\n",
      "Epoch 8, Batch 5500/5867, Loss: 0.0814\n",
      "Epoch 8, Batch 5510/5867, Loss: 0.1180\n",
      "Epoch 8, Batch 5520/5867, Loss: 0.3325\n",
      "Epoch 8, Batch 5530/5867, Loss: 0.1683\n",
      "Epoch 8, Batch 5540/5867, Loss: 0.1550\n",
      "Epoch 8, Batch 5550/5867, Loss: 0.2000\n",
      "Epoch 8, Batch 5560/5867, Loss: 0.3118\n",
      "Epoch 8, Batch 5570/5867, Loss: 0.0792\n",
      "Epoch 8, Batch 5580/5867, Loss: 0.3482\n",
      "Epoch 8, Batch 5590/5867, Loss: 0.3296\n",
      "Epoch 8, Batch 5600/5867, Loss: 0.1367\n",
      "Epoch 8, Batch 5610/5867, Loss: 0.1563\n",
      "Epoch 8, Batch 5620/5867, Loss: 0.2994\n",
      "Epoch 8, Batch 5630/5867, Loss: 0.2936\n",
      "Epoch 8, Batch 5640/5867, Loss: 0.3055\n",
      "Epoch 8, Batch 5650/5867, Loss: 0.2121\n",
      "Epoch 8, Batch 5660/5867, Loss: 0.0753\n",
      "Epoch 8, Batch 5670/5867, Loss: 0.1031\n",
      "Epoch 8, Batch 5680/5867, Loss: 0.3180\n",
      "Epoch 8, Batch 5690/5867, Loss: 0.1007\n",
      "Epoch 8, Batch 5700/5867, Loss: 0.2299\n",
      "Epoch 8, Batch 5710/5867, Loss: 0.0813\n",
      "Epoch 8, Batch 5720/5867, Loss: 0.0787\n",
      "Epoch 8, Batch 5730/5867, Loss: 0.1075\n",
      "Epoch 8, Batch 5740/5867, Loss: 0.2216\n",
      "Epoch 8, Batch 5750/5867, Loss: 0.2044\n",
      "Epoch 8, Batch 5760/5867, Loss: 0.3581\n",
      "Epoch 8, Batch 5770/5867, Loss: 0.2748\n",
      "Epoch 8, Batch 5780/5867, Loss: 0.2132\n",
      "Epoch 8, Batch 5790/5867, Loss: 0.2155\n",
      "Epoch 8, Batch 5800/5867, Loss: 0.2611\n",
      "Epoch 8, Batch 5810/5867, Loss: 0.2361\n",
      "Epoch 8, Batch 5820/5867, Loss: 0.1583\n",
      "Epoch 8, Batch 5830/5867, Loss: 0.1519\n",
      "Epoch 8, Batch 5840/5867, Loss: 0.1039\n",
      "Epoch 8, Batch 5850/5867, Loss: 0.1662\n",
      "Epoch 8, Batch 5860/5867, Loss: 0.0398\n",
      "Epoch 8, Training Loss: 0.1858, Validation Loss: 0.1890\n",
      "Starting epoch 9...\n",
      "Epoch 9, Batch 10/5867, Loss: 0.2120\n",
      "Epoch 9, Batch 20/5867, Loss: 0.1194\n",
      "Epoch 9, Batch 30/5867, Loss: 0.3134\n",
      "Epoch 9, Batch 40/5867, Loss: 0.3135\n",
      "Epoch 9, Batch 50/5867, Loss: 0.2873\n",
      "Epoch 9, Batch 60/5867, Loss: 0.2065\n",
      "Epoch 9, Batch 70/5867, Loss: 0.1496\n",
      "Epoch 9, Batch 80/5867, Loss: 0.0387\n",
      "Epoch 9, Batch 90/5867, Loss: 0.1901\n",
      "Epoch 9, Batch 100/5867, Loss: 0.1759\n",
      "Epoch 9, Batch 110/5867, Loss: 0.1637\n",
      "Epoch 9, Batch 120/5867, Loss: 0.1552\n",
      "Epoch 9, Batch 130/5867, Loss: 0.3102\n",
      "Epoch 9, Batch 140/5867, Loss: 0.1365\n",
      "Epoch 9, Batch 150/5867, Loss: 0.1173\n",
      "Epoch 9, Batch 160/5867, Loss: 0.3451\n",
      "Epoch 9, Batch 170/5867, Loss: 0.2403\n",
      "Epoch 9, Batch 180/5867, Loss: 0.1724\n",
      "Epoch 9, Batch 190/5867, Loss: 0.1568\n",
      "Epoch 9, Batch 200/5867, Loss: 0.1944\n",
      "Epoch 9, Batch 210/5867, Loss: 0.1099\n",
      "Epoch 9, Batch 220/5867, Loss: 0.1677\n",
      "Epoch 9, Batch 230/5867, Loss: 0.1555\n",
      "Epoch 9, Batch 240/5867, Loss: 0.1880\n",
      "Epoch 9, Batch 250/5867, Loss: 0.1186\n",
      "Epoch 9, Batch 260/5867, Loss: 0.1239\n",
      "Epoch 9, Batch 270/5867, Loss: 0.1510\n",
      "Epoch 9, Batch 280/5867, Loss: 0.1074\n",
      "Epoch 9, Batch 290/5867, Loss: 0.2518\n",
      "Epoch 9, Batch 300/5867, Loss: 0.2135\n",
      "Epoch 9, Batch 310/5867, Loss: 0.1288\n",
      "Epoch 9, Batch 320/5867, Loss: 0.2732\n",
      "Epoch 9, Batch 330/5867, Loss: 0.2666\n",
      "Epoch 9, Batch 340/5867, Loss: 0.1394\n",
      "Epoch 9, Batch 350/5867, Loss: 0.3126\n",
      "Epoch 9, Batch 360/5867, Loss: 0.0930\n",
      "Epoch 9, Batch 370/5867, Loss: 0.1860\n",
      "Epoch 9, Batch 380/5867, Loss: 0.1141\n",
      "Epoch 9, Batch 390/5867, Loss: 0.3020\n",
      "Epoch 9, Batch 400/5867, Loss: 0.1405\n",
      "Epoch 9, Batch 410/5867, Loss: 0.1505\n",
      "Epoch 9, Batch 420/5867, Loss: 0.1230\n",
      "Epoch 9, Batch 430/5867, Loss: 0.1850\n",
      "Epoch 9, Batch 440/5867, Loss: 0.0856\n",
      "Epoch 9, Batch 450/5867, Loss: 0.1528\n",
      "Epoch 9, Batch 460/5867, Loss: 0.1837\n",
      "Epoch 9, Batch 470/5867, Loss: 0.0483\n",
      "Epoch 9, Batch 480/5867, Loss: 0.2354\n",
      "Epoch 9, Batch 490/5867, Loss: 0.1294\n",
      "Epoch 9, Batch 500/5867, Loss: 0.2596\n",
      "Epoch 9, Batch 510/5867, Loss: 0.1937\n",
      "Epoch 9, Batch 520/5867, Loss: 0.2153\n",
      "Epoch 9, Batch 530/5867, Loss: 0.2375\n",
      "Epoch 9, Batch 540/5867, Loss: 0.1513\n",
      "Epoch 9, Batch 550/5867, Loss: 0.1016\n",
      "Epoch 9, Batch 560/5867, Loss: 0.3185\n",
      "Epoch 9, Batch 570/5867, Loss: 0.1517\n",
      "Epoch 9, Batch 580/5867, Loss: 0.2386\n",
      "Epoch 9, Batch 590/5867, Loss: 0.2867\n",
      "Epoch 9, Batch 600/5867, Loss: 0.3023\n",
      "Epoch 9, Batch 610/5867, Loss: 0.1858\n",
      "Epoch 9, Batch 620/5867, Loss: 0.2085\n",
      "Epoch 9, Batch 630/5867, Loss: 0.1867\n",
      "Epoch 9, Batch 640/5867, Loss: 0.0810\n",
      "Epoch 9, Batch 650/5867, Loss: 0.1800\n",
      "Epoch 9, Batch 660/5867, Loss: 0.3592\n",
      "Epoch 9, Batch 670/5867, Loss: 0.2037\n",
      "Epoch 9, Batch 680/5867, Loss: 0.1487\n",
      "Epoch 9, Batch 690/5867, Loss: 0.1437\n",
      "Epoch 9, Batch 700/5867, Loss: 0.0381\n",
      "Epoch 9, Batch 710/5867, Loss: 0.2915\n",
      "Epoch 9, Batch 720/5867, Loss: 0.1050\n",
      "Epoch 9, Batch 730/5867, Loss: 0.2294\n",
      "Epoch 9, Batch 740/5867, Loss: 0.2802\n",
      "Epoch 9, Batch 750/5867, Loss: 0.2048\n",
      "Epoch 9, Batch 760/5867, Loss: 0.0864\n",
      "Epoch 9, Batch 770/5867, Loss: 0.3188\n",
      "Epoch 9, Batch 780/5867, Loss: 0.2653\n",
      "Epoch 9, Batch 790/5867, Loss: 0.2626\n",
      "Epoch 9, Batch 800/5867, Loss: 0.2706\n",
      "Epoch 9, Batch 810/5867, Loss: 0.1991\n",
      "Epoch 9, Batch 820/5867, Loss: 0.3496\n",
      "Epoch 9, Batch 830/5867, Loss: 0.0765\n",
      "Epoch 9, Batch 840/5867, Loss: 0.2189\n",
      "Epoch 9, Batch 850/5867, Loss: 0.2576\n",
      "Epoch 9, Batch 860/5867, Loss: 0.1853\n",
      "Epoch 9, Batch 870/5867, Loss: 0.2852\n",
      "Epoch 9, Batch 880/5867, Loss: 0.0883\n",
      "Epoch 9, Batch 890/5867, Loss: 0.0595\n",
      "Epoch 9, Batch 900/5867, Loss: 0.2192\n",
      "Epoch 9, Batch 910/5867, Loss: 0.1317\n",
      "Epoch 9, Batch 920/5867, Loss: 0.1595\n",
      "Epoch 9, Batch 930/5867, Loss: 0.0988\n",
      "Epoch 9, Batch 940/5867, Loss: 0.3314\n",
      "Epoch 9, Batch 950/5867, Loss: 0.0877\n",
      "Epoch 9, Batch 960/5867, Loss: 0.1253\n",
      "Epoch 9, Batch 970/5867, Loss: 0.0723\n",
      "Epoch 9, Batch 980/5867, Loss: 0.0755\n",
      "Epoch 9, Batch 990/5867, Loss: 0.3093\n",
      "Epoch 9, Batch 1000/5867, Loss: 0.1523\n",
      "Epoch 9, Batch 1010/5867, Loss: 0.1560\n",
      "Epoch 9, Batch 1020/5867, Loss: 0.2545\n",
      "Epoch 9, Batch 1030/5867, Loss: 0.3033\n",
      "Epoch 9, Batch 1040/5867, Loss: 0.0804\n",
      "Epoch 9, Batch 1050/5867, Loss: 0.0844\n",
      "Epoch 9, Batch 1060/5867, Loss: 0.1562\n",
      "Epoch 9, Batch 1070/5867, Loss: 0.2005\n",
      "Epoch 9, Batch 1080/5867, Loss: 0.1645\n",
      "Epoch 9, Batch 1090/5867, Loss: 0.4250\n",
      "Epoch 9, Batch 1100/5867, Loss: 0.1070\n",
      "Epoch 9, Batch 1110/5867, Loss: 0.0787\n",
      "Epoch 9, Batch 1120/5867, Loss: 0.1494\n",
      "Epoch 9, Batch 1130/5867, Loss: 0.1273\n",
      "Epoch 9, Batch 1140/5867, Loss: 0.1335\n",
      "Epoch 9, Batch 1150/5867, Loss: 0.0756\n",
      "Epoch 9, Batch 1160/5867, Loss: 0.2058\n",
      "Epoch 9, Batch 1170/5867, Loss: 0.1420\n",
      "Epoch 9, Batch 1180/5867, Loss: 0.2202\n",
      "Epoch 9, Batch 1190/5867, Loss: 0.1440\n",
      "Epoch 9, Batch 1200/5867, Loss: 0.1503\n",
      "Epoch 9, Batch 1210/5867, Loss: 0.1443\n",
      "Epoch 9, Batch 1220/5867, Loss: 0.2472\n",
      "Epoch 9, Batch 1230/5867, Loss: 0.0999\n",
      "Epoch 9, Batch 1240/5867, Loss: 0.1290\n",
      "Epoch 9, Batch 1250/5867, Loss: 0.3720\n",
      "Epoch 9, Batch 1260/5867, Loss: 0.0672\n",
      "Epoch 9, Batch 1270/5867, Loss: 0.1517\n",
      "Epoch 9, Batch 1280/5867, Loss: 0.1434\n",
      "Epoch 9, Batch 1290/5867, Loss: 0.1814\n",
      "Epoch 9, Batch 1300/5867, Loss: 0.1125\n",
      "Epoch 9, Batch 1310/5867, Loss: 0.1745\n",
      "Epoch 9, Batch 1320/5867, Loss: 0.2380\n",
      "Epoch 9, Batch 1330/5867, Loss: 0.2181\n",
      "Epoch 9, Batch 1340/5867, Loss: 0.0673\n",
      "Epoch 9, Batch 1350/5867, Loss: 0.1298\n",
      "Epoch 9, Batch 1360/5867, Loss: 0.1171\n",
      "Epoch 9, Batch 1370/5867, Loss: 0.2204\n",
      "Epoch 9, Batch 1380/5867, Loss: 0.3240\n",
      "Epoch 9, Batch 1390/5867, Loss: 0.1568\n",
      "Epoch 9, Batch 1400/5867, Loss: 0.1433\n",
      "Epoch 9, Batch 1410/5867, Loss: 0.1735\n",
      "Epoch 9, Batch 1420/5867, Loss: 0.1168\n",
      "Epoch 9, Batch 1430/5867, Loss: 0.2462\n",
      "Epoch 9, Batch 1440/5867, Loss: 0.0880\n",
      "Epoch 9, Batch 1450/5867, Loss: 0.1220\n",
      "Epoch 9, Batch 1460/5867, Loss: 0.0871\n",
      "Epoch 9, Batch 1470/5867, Loss: 0.1564\n",
      "Epoch 9, Batch 1480/5867, Loss: 0.1788\n",
      "Epoch 9, Batch 1490/5867, Loss: 0.1027\n",
      "Epoch 9, Batch 1500/5867, Loss: 0.0438\n",
      "Epoch 9, Batch 1510/5867, Loss: 0.0781\n",
      "Epoch 9, Batch 1520/5867, Loss: 0.0981\n",
      "Epoch 9, Batch 1530/5867, Loss: 0.2435\n",
      "Epoch 9, Batch 1540/5867, Loss: 0.1664\n",
      "Epoch 9, Batch 1550/5867, Loss: 0.1620\n",
      "Epoch 9, Batch 1560/5867, Loss: 0.1073\n",
      "Epoch 9, Batch 1570/5867, Loss: 0.2508\n",
      "Epoch 9, Batch 1580/5867, Loss: 0.1086\n",
      "Epoch 9, Batch 1590/5867, Loss: 0.1525\n",
      "Epoch 9, Batch 1600/5867, Loss: 0.3469\n",
      "Epoch 9, Batch 1610/5867, Loss: 0.1705\n",
      "Epoch 9, Batch 1620/5867, Loss: 0.1429\n",
      "Epoch 9, Batch 1630/5867, Loss: 0.1534\n",
      "Epoch 9, Batch 1640/5867, Loss: 0.1269\n",
      "Epoch 9, Batch 1650/5867, Loss: 0.2568\n",
      "Epoch 9, Batch 1660/5867, Loss: 0.1219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 1670/5867, Loss: 0.2091\n",
      "Epoch 9, Batch 1680/5867, Loss: 0.1518\n",
      "Epoch 9, Batch 1690/5867, Loss: 0.2157\n",
      "Epoch 9, Batch 1700/5867, Loss: 0.0753\n",
      "Epoch 9, Batch 1710/5867, Loss: 0.2170\n",
      "Epoch 9, Batch 1720/5867, Loss: 0.1051\n",
      "Epoch 9, Batch 1730/5867, Loss: 0.0890\n",
      "Epoch 9, Batch 1740/5867, Loss: 0.4699\n",
      "Epoch 9, Batch 1750/5867, Loss: 0.3872\n",
      "Epoch 9, Batch 1760/5867, Loss: 0.1800\n",
      "Epoch 9, Batch 1770/5867, Loss: 0.1824\n",
      "Epoch 9, Batch 1780/5867, Loss: 0.1660\n",
      "Epoch 9, Batch 1790/5867, Loss: 0.1960\n",
      "Epoch 9, Batch 1800/5867, Loss: 0.0919\n",
      "Epoch 9, Batch 1810/5867, Loss: 0.1019\n",
      "Epoch 9, Batch 1820/5867, Loss: 0.1406\n",
      "Epoch 9, Batch 1830/5867, Loss: 0.1333\n",
      "Epoch 9, Batch 1840/5867, Loss: 0.1534\n",
      "Epoch 9, Batch 1850/5867, Loss: 0.2364\n",
      "Epoch 9, Batch 1860/5867, Loss: 0.2711\n",
      "Epoch 9, Batch 1870/5867, Loss: 0.1709\n",
      "Epoch 9, Batch 1880/5867, Loss: 0.0481\n",
      "Epoch 9, Batch 1890/5867, Loss: 0.0852\n",
      "Epoch 9, Batch 1900/5867, Loss: 0.1802\n",
      "Epoch 9, Batch 1910/5867, Loss: 0.1690\n",
      "Epoch 9, Batch 1920/5867, Loss: 0.2727\n",
      "Epoch 9, Batch 1930/5867, Loss: 0.4191\n",
      "Epoch 9, Batch 1940/5867, Loss: 0.4153\n",
      "Epoch 9, Batch 1950/5867, Loss: 0.1455\n",
      "Epoch 9, Batch 1960/5867, Loss: 0.2476\n",
      "Epoch 9, Batch 1970/5867, Loss: 0.2754\n",
      "Epoch 9, Batch 1980/5867, Loss: 0.1802\n",
      "Epoch 9, Batch 1990/5867, Loss: 0.1347\n",
      "Epoch 9, Batch 2000/5867, Loss: 0.0770\n",
      "Epoch 9, Batch 2010/5867, Loss: 0.3856\n",
      "Epoch 9, Batch 2020/5867, Loss: 0.1735\n",
      "Epoch 9, Batch 2030/5867, Loss: 0.1642\n",
      "Epoch 9, Batch 2040/5867, Loss: 0.1560\n",
      "Epoch 9, Batch 2050/5867, Loss: 0.2296\n",
      "Epoch 9, Batch 2060/5867, Loss: 0.3119\n",
      "Epoch 9, Batch 2070/5867, Loss: 0.3418\n",
      "Epoch 9, Batch 2080/5867, Loss: 0.1628\n",
      "Epoch 9, Batch 2090/5867, Loss: 0.2358\n",
      "Epoch 9, Batch 2100/5867, Loss: 0.2214\n",
      "Epoch 9, Batch 2110/5867, Loss: 0.1079\n",
      "Epoch 9, Batch 2120/5867, Loss: 0.1776\n",
      "Epoch 9, Batch 2130/5867, Loss: 0.2336\n",
      "Epoch 9, Batch 2140/5867, Loss: 0.0372\n",
      "Epoch 9, Batch 2150/5867, Loss: 0.1236\n",
      "Epoch 9, Batch 2160/5867, Loss: 0.3618\n",
      "Epoch 9, Batch 2170/5867, Loss: 0.2025\n",
      "Epoch 9, Batch 2180/5867, Loss: 0.2458\n",
      "Epoch 9, Batch 2190/5867, Loss: 0.1500\n",
      "Epoch 9, Batch 2200/5867, Loss: 0.2649\n",
      "Epoch 9, Batch 2210/5867, Loss: 0.1872\n",
      "Epoch 9, Batch 2220/5867, Loss: 0.1452\n",
      "Epoch 9, Batch 2230/5867, Loss: 0.3565\n",
      "Epoch 9, Batch 2240/5867, Loss: 0.1881\n",
      "Epoch 9, Batch 2250/5867, Loss: 0.3491\n",
      "Epoch 9, Batch 2260/5867, Loss: 0.0651\n",
      "Epoch 9, Batch 2270/5867, Loss: 0.3130\n",
      "Epoch 9, Batch 2280/5867, Loss: 0.1324\n",
      "Epoch 9, Batch 2290/5867, Loss: 0.1855\n",
      "Epoch 9, Batch 2300/5867, Loss: 0.2053\n",
      "Epoch 9, Batch 2310/5867, Loss: 0.1036\n",
      "Epoch 9, Batch 2320/5867, Loss: 0.0759\n",
      "Epoch 9, Batch 2330/5867, Loss: 0.1267\n",
      "Epoch 9, Batch 2340/5867, Loss: 0.3305\n",
      "Epoch 9, Batch 2350/5867, Loss: 0.1629\n",
      "Epoch 9, Batch 2360/5867, Loss: 0.1504\n",
      "Epoch 9, Batch 2370/5867, Loss: 0.0741\n",
      "Epoch 9, Batch 2380/5867, Loss: 0.1944\n",
      "Epoch 9, Batch 2390/5867, Loss: 0.1680\n",
      "Epoch 9, Batch 2400/5867, Loss: 0.1550\n",
      "Epoch 9, Batch 2410/5867, Loss: 0.2235\n",
      "Epoch 9, Batch 2420/5867, Loss: 0.2177\n",
      "Epoch 9, Batch 2430/5867, Loss: 0.2102\n",
      "Epoch 9, Batch 2440/5867, Loss: 0.0761\n",
      "Epoch 9, Batch 2450/5867, Loss: 0.2231\n",
      "Epoch 9, Batch 2460/5867, Loss: 0.2085\n",
      "Epoch 9, Batch 2470/5867, Loss: 0.1096\n",
      "Epoch 9, Batch 2480/5867, Loss: 0.1134\n",
      "Epoch 9, Batch 2490/5867, Loss: 0.1008\n",
      "Epoch 9, Batch 2500/5867, Loss: 0.2473\n",
      "Epoch 9, Batch 2510/5867, Loss: 0.1355\n",
      "Epoch 9, Batch 2520/5867, Loss: 0.3275\n",
      "Epoch 9, Batch 2530/5867, Loss: 0.1482\n",
      "Epoch 9, Batch 2540/5867, Loss: 0.1096\n",
      "Epoch 9, Batch 2550/5867, Loss: 0.1960\n",
      "Epoch 9, Batch 2560/5867, Loss: 0.3723\n",
      "Epoch 9, Batch 2570/5867, Loss: 0.3887\n",
      "Epoch 9, Batch 2580/5867, Loss: 0.0865\n",
      "Epoch 9, Batch 2590/5867, Loss: 0.3124\n",
      "Epoch 9, Batch 2600/5867, Loss: 0.1892\n",
      "Epoch 9, Batch 2610/5867, Loss: 0.2108\n",
      "Epoch 9, Batch 2620/5867, Loss: 0.3067\n",
      "Epoch 9, Batch 2630/5867, Loss: 0.1138\n",
      "Epoch 9, Batch 2640/5867, Loss: 0.1722\n",
      "Epoch 9, Batch 2650/5867, Loss: 0.1262\n",
      "Epoch 9, Batch 2660/5867, Loss: 0.0825\n",
      "Epoch 9, Batch 2670/5867, Loss: 0.3159\n",
      "Epoch 9, Batch 2680/5867, Loss: 0.3633\n",
      "Epoch 9, Batch 2690/5867, Loss: 0.1891\n",
      "Epoch 9, Batch 2700/5867, Loss: 0.2338\n",
      "Epoch 9, Batch 2710/5867, Loss: 0.1907\n",
      "Epoch 9, Batch 2720/5867, Loss: 0.2674\n",
      "Epoch 9, Batch 2730/5867, Loss: 0.2362\n",
      "Epoch 9, Batch 2740/5867, Loss: 0.1063\n",
      "Epoch 9, Batch 2750/5867, Loss: 0.0966\n",
      "Epoch 9, Batch 2760/5867, Loss: 0.0826\n",
      "Epoch 9, Batch 2770/5867, Loss: 0.1510\n",
      "Epoch 9, Batch 2780/5867, Loss: 0.2235\n",
      "Epoch 9, Batch 2790/5867, Loss: 0.1451\n",
      "Epoch 9, Batch 2800/5867, Loss: 0.2713\n",
      "Epoch 9, Batch 2810/5867, Loss: 0.2624\n",
      "Epoch 9, Batch 2820/5867, Loss: 0.2365\n",
      "Epoch 9, Batch 2830/5867, Loss: 0.2599\n",
      "Epoch 9, Batch 2840/5867, Loss: 0.3308\n",
      "Epoch 9, Batch 2850/5867, Loss: 0.3462\n",
      "Epoch 9, Batch 2860/5867, Loss: 0.1633\n",
      "Epoch 9, Batch 2870/5867, Loss: 0.2018\n",
      "Epoch 9, Batch 2880/5867, Loss: 0.1637\n",
      "Epoch 9, Batch 2890/5867, Loss: 0.1338\n",
      "Epoch 9, Batch 2900/5867, Loss: 0.1618\n",
      "Epoch 9, Batch 2910/5867, Loss: 0.2154\n",
      "Epoch 9, Batch 2920/5867, Loss: 0.1494\n",
      "Epoch 9, Batch 2930/5867, Loss: 0.3143\n",
      "Epoch 9, Batch 2940/5867, Loss: 0.1696\n",
      "Epoch 9, Batch 2950/5867, Loss: 0.1341\n",
      "Epoch 9, Batch 2960/5867, Loss: 0.2931\n",
      "Epoch 9, Batch 2970/5867, Loss: 0.0685\n",
      "Epoch 9, Batch 2980/5867, Loss: 0.2088\n",
      "Epoch 9, Batch 2990/5867, Loss: 0.2936\n",
      "Epoch 9, Batch 3000/5867, Loss: 0.3047\n",
      "Epoch 9, Batch 3010/5867, Loss: 0.1340\n",
      "Epoch 9, Batch 3020/5867, Loss: 0.3231\n",
      "Epoch 9, Batch 3030/5867, Loss: 0.0978\n",
      "Epoch 9, Batch 3040/5867, Loss: 0.4083\n",
      "Epoch 9, Batch 3050/5867, Loss: 0.0773\n",
      "Epoch 9, Batch 3060/5867, Loss: 0.1000\n",
      "Epoch 9, Batch 3070/5867, Loss: 0.1933\n",
      "Epoch 9, Batch 3080/5867, Loss: 0.1842\n",
      "Epoch 9, Batch 3090/5867, Loss: 0.1127\n",
      "Epoch 9, Batch 3100/5867, Loss: 0.1746\n",
      "Epoch 9, Batch 3110/5867, Loss: 0.1127\n",
      "Epoch 9, Batch 3120/5867, Loss: 0.1396\n",
      "Epoch 9, Batch 3130/5867, Loss: 0.0836\n",
      "Epoch 9, Batch 3140/5867, Loss: 0.1415\n",
      "Epoch 9, Batch 3150/5867, Loss: 0.1560\n",
      "Epoch 9, Batch 3160/5867, Loss: 0.1941\n",
      "Epoch 9, Batch 3170/5867, Loss: 0.1098\n",
      "Epoch 9, Batch 3180/5867, Loss: 0.3123\n",
      "Epoch 9, Batch 3190/5867, Loss: 0.2933\n",
      "Epoch 9, Batch 3200/5867, Loss: 0.2416\n",
      "Epoch 9, Batch 3210/5867, Loss: 0.1691\n",
      "Epoch 9, Batch 3220/5867, Loss: 0.2910\n",
      "Epoch 9, Batch 3230/5867, Loss: 0.2120\n",
      "Epoch 9, Batch 3240/5867, Loss: 0.0608\n",
      "Epoch 9, Batch 3250/5867, Loss: 0.3081\n",
      "Epoch 9, Batch 3260/5867, Loss: 0.1558\n",
      "Epoch 9, Batch 3270/5867, Loss: 0.1934\n",
      "Epoch 9, Batch 3280/5867, Loss: 0.0258\n",
      "Epoch 9, Batch 3290/5867, Loss: 0.0400\n",
      "Epoch 9, Batch 3300/5867, Loss: 0.1552\n",
      "Epoch 9, Batch 3310/5867, Loss: 0.2141\n",
      "Epoch 9, Batch 3320/5867, Loss: 0.3258\n",
      "Epoch 9, Batch 3330/5867, Loss: 0.3480\n",
      "Epoch 9, Batch 3340/5867, Loss: 0.2714\n",
      "Epoch 9, Batch 3350/5867, Loss: 0.1948\n",
      "Epoch 9, Batch 3360/5867, Loss: 0.1218\n",
      "Epoch 9, Batch 3370/5867, Loss: 0.0948\n",
      "Epoch 9, Batch 3380/5867, Loss: 0.0776\n",
      "Epoch 9, Batch 3390/5867, Loss: 0.2169\n",
      "Epoch 9, Batch 3400/5867, Loss: 0.1108\n",
      "Epoch 9, Batch 3410/5867, Loss: 0.0829\n",
      "Epoch 9, Batch 3420/5867, Loss: 0.0713\n",
      "Epoch 9, Batch 3430/5867, Loss: 0.1980\n",
      "Epoch 9, Batch 3440/5867, Loss: 0.1300\n",
      "Epoch 9, Batch 3450/5867, Loss: 0.3552\n",
      "Epoch 9, Batch 3460/5867, Loss: 0.1552\n",
      "Epoch 9, Batch 3470/5867, Loss: 0.1183\n",
      "Epoch 9, Batch 3480/5867, Loss: 0.1528\n",
      "Epoch 9, Batch 3490/5867, Loss: 0.2747\n",
      "Epoch 9, Batch 3500/5867, Loss: 0.2631\n",
      "Epoch 9, Batch 3510/5867, Loss: 0.3027\n",
      "Epoch 9, Batch 3520/5867, Loss: 0.1964\n",
      "Epoch 9, Batch 3530/5867, Loss: 0.1634\n",
      "Epoch 9, Batch 3540/5867, Loss: 0.3425\n",
      "Epoch 9, Batch 3550/5867, Loss: 0.0651\n",
      "Epoch 9, Batch 3560/5867, Loss: 0.1976\n",
      "Epoch 9, Batch 3570/5867, Loss: 0.2866\n",
      "Epoch 9, Batch 3580/5867, Loss: 0.1962\n",
      "Epoch 9, Batch 3590/5867, Loss: 0.1602\n",
      "Epoch 9, Batch 3600/5867, Loss: 0.2673\n",
      "Epoch 9, Batch 3610/5867, Loss: 0.1944\n",
      "Epoch 9, Batch 3620/5867, Loss: 0.2012\n",
      "Epoch 9, Batch 3630/5867, Loss: 0.0778\n",
      "Epoch 9, Batch 3640/5867, Loss: 0.1412\n",
      "Epoch 9, Batch 3650/5867, Loss: 0.1165\n",
      "Epoch 9, Batch 3660/5867, Loss: 0.2576\n",
      "Epoch 9, Batch 3670/5867, Loss: 0.1368\n",
      "Epoch 9, Batch 3680/5867, Loss: 0.2590\n",
      "Epoch 9, Batch 3690/5867, Loss: 0.2729\n",
      "Epoch 9, Batch 3700/5867, Loss: 0.2812\n",
      "Epoch 9, Batch 3710/5867, Loss: 0.0783\n",
      "Epoch 9, Batch 3720/5867, Loss: 0.2006\n",
      "Epoch 9, Batch 3730/5867, Loss: 0.3042\n",
      "Epoch 9, Batch 3740/5867, Loss: 0.2800\n",
      "Epoch 9, Batch 3750/5867, Loss: 0.1586\n",
      "Epoch 9, Batch 3760/5867, Loss: 0.3897\n",
      "Epoch 9, Batch 3770/5867, Loss: 0.1786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 3780/5867, Loss: 0.1359\n",
      "Epoch 9, Batch 3790/5867, Loss: 0.2044\n",
      "Epoch 9, Batch 3800/5867, Loss: 0.2312\n",
      "Epoch 9, Batch 3810/5867, Loss: 0.0858\n",
      "Epoch 9, Batch 3820/5867, Loss: 0.1572\n",
      "Epoch 9, Batch 3830/5867, Loss: 0.1162\n",
      "Epoch 9, Batch 3840/5867, Loss: 0.1416\n",
      "Epoch 9, Batch 3850/5867, Loss: 0.1048\n",
      "Epoch 9, Batch 3860/5867, Loss: 0.0844\n",
      "Epoch 9, Batch 3870/5867, Loss: 0.1148\n",
      "Epoch 9, Batch 3880/5867, Loss: 0.1608\n",
      "Epoch 9, Batch 3890/5867, Loss: 0.1921\n",
      "Epoch 9, Batch 3900/5867, Loss: 0.3134\n",
      "Epoch 9, Batch 3910/5867, Loss: 0.1582\n",
      "Epoch 9, Batch 3920/5867, Loss: 0.0747\n",
      "Epoch 9, Batch 3930/5867, Loss: 0.0999\n",
      "Epoch 9, Batch 3940/5867, Loss: 0.2703\n",
      "Epoch 9, Batch 3950/5867, Loss: 0.1088\n",
      "Epoch 9, Batch 3960/5867, Loss: 0.2667\n",
      "Epoch 9, Batch 3970/5867, Loss: 0.1165\n",
      "Epoch 9, Batch 3980/5867, Loss: 0.1706\n",
      "Epoch 9, Batch 3990/5867, Loss: 0.1697\n",
      "Epoch 9, Batch 4000/5867, Loss: 0.2196\n",
      "Epoch 9, Batch 4010/5867, Loss: 0.0751\n",
      "Epoch 9, Batch 4020/5867, Loss: 0.2254\n",
      "Epoch 9, Batch 4030/5867, Loss: 0.2064\n",
      "Epoch 9, Batch 4040/5867, Loss: 0.2231\n",
      "Epoch 9, Batch 4050/5867, Loss: 0.1479\n",
      "Epoch 9, Batch 4060/5867, Loss: 0.1622\n",
      "Epoch 9, Batch 4070/5867, Loss: 0.1089\n",
      "Epoch 9, Batch 4080/5867, Loss: 0.3021\n",
      "Epoch 9, Batch 4090/5867, Loss: 0.0879\n",
      "Epoch 9, Batch 4100/5867, Loss: 0.1320\n",
      "Epoch 9, Batch 4110/5867, Loss: 0.1995\n",
      "Epoch 9, Batch 4120/5867, Loss: 0.2592\n",
      "Epoch 9, Batch 4130/5867, Loss: 0.1767\n",
      "Epoch 9, Batch 4140/5867, Loss: 0.1534\n",
      "Epoch 9, Batch 4150/5867, Loss: 0.2310\n",
      "Epoch 9, Batch 4160/5867, Loss: 0.1429\n",
      "Epoch 9, Batch 4170/5867, Loss: 0.2824\n",
      "Epoch 9, Batch 4180/5867, Loss: 0.1473\n",
      "Epoch 9, Batch 4190/5867, Loss: 0.1496\n",
      "Epoch 9, Batch 4200/5867, Loss: 0.4005\n",
      "Epoch 9, Batch 4210/5867, Loss: 0.1740\n",
      "Epoch 9, Batch 4220/5867, Loss: 0.1311\n",
      "Epoch 9, Batch 4230/5867, Loss: 0.1532\n",
      "Epoch 9, Batch 4240/5867, Loss: 0.2649\n",
      "Epoch 9, Batch 4250/5867, Loss: 0.2106\n",
      "Epoch 9, Batch 4260/5867, Loss: 0.2004\n",
      "Epoch 9, Batch 4270/5867, Loss: 0.0737\n",
      "Epoch 9, Batch 4280/5867, Loss: 0.0918\n",
      "Epoch 9, Batch 4290/5867, Loss: 0.2214\n",
      "Epoch 9, Batch 4300/5867, Loss: 0.1225\n",
      "Epoch 9, Batch 4310/5867, Loss: 0.0812\n",
      "Epoch 9, Batch 4320/5867, Loss: 0.0965\n",
      "Epoch 9, Batch 4330/5867, Loss: 0.1463\n",
      "Epoch 9, Batch 4340/5867, Loss: 0.0567\n",
      "Epoch 9, Batch 4350/5867, Loss: 0.3483\n",
      "Epoch 9, Batch 4360/5867, Loss: 0.1554\n",
      "Epoch 9, Batch 4370/5867, Loss: 0.2376\n",
      "Epoch 9, Batch 4380/5867, Loss: 0.1610\n",
      "Epoch 9, Batch 4390/5867, Loss: 0.1587\n",
      "Epoch 9, Batch 4400/5867, Loss: 0.1611\n",
      "Epoch 9, Batch 4410/5867, Loss: 0.0935\n",
      "Epoch 9, Batch 4420/5867, Loss: 0.1659\n",
      "Epoch 9, Batch 4430/5867, Loss: 0.0908\n",
      "Epoch 9, Batch 4440/5867, Loss: 0.0874\n",
      "Epoch 9, Batch 4450/5867, Loss: 0.1463\n",
      "Epoch 9, Batch 4460/5867, Loss: 0.1284\n",
      "Epoch 9, Batch 4470/5867, Loss: 0.2238\n",
      "Epoch 9, Batch 4480/5867, Loss: 0.0929\n",
      "Epoch 9, Batch 4490/5867, Loss: 0.1874\n",
      "Epoch 9, Batch 4500/5867, Loss: 0.2511\n",
      "Epoch 9, Batch 4510/5867, Loss: 0.2368\n",
      "Epoch 9, Batch 4520/5867, Loss: 0.2347\n",
      "Epoch 9, Batch 4530/5867, Loss: 0.0757\n",
      "Epoch 9, Batch 4540/5867, Loss: 0.2187\n",
      "Epoch 9, Batch 4550/5867, Loss: 0.1293\n",
      "Epoch 9, Batch 4560/5867, Loss: 0.0806\n",
      "Epoch 9, Batch 4570/5867, Loss: 0.1312\n",
      "Epoch 9, Batch 4580/5867, Loss: 0.2175\n",
      "Epoch 9, Batch 4590/5867, Loss: 0.1836\n",
      "Epoch 9, Batch 4600/5867, Loss: 0.2648\n",
      "Epoch 9, Batch 4610/5867, Loss: 0.2114\n",
      "Epoch 9, Batch 4620/5867, Loss: 0.0760\n",
      "Epoch 9, Batch 4630/5867, Loss: 0.2881\n",
      "Epoch 9, Batch 4640/5867, Loss: 0.1113\n",
      "Epoch 9, Batch 4650/5867, Loss: 0.3023\n",
      "Epoch 9, Batch 4660/5867, Loss: 0.0784\n",
      "Epoch 9, Batch 4670/5867, Loss: 0.0432\n",
      "Epoch 9, Batch 4680/5867, Loss: 0.0950\n",
      "Epoch 9, Batch 4690/5867, Loss: 0.2527\n",
      "Epoch 9, Batch 4700/5867, Loss: 0.1976\n",
      "Epoch 9, Batch 4710/5867, Loss: 0.4289\n",
      "Epoch 9, Batch 4720/5867, Loss: 0.1650\n",
      "Epoch 9, Batch 4730/5867, Loss: 0.2599\n",
      "Epoch 9, Batch 4740/5867, Loss: 0.2947\n",
      "Epoch 9, Batch 4750/5867, Loss: 0.2486\n",
      "Epoch 9, Batch 4760/5867, Loss: 0.1436\n",
      "Epoch 9, Batch 4770/5867, Loss: 0.1618\n",
      "Epoch 9, Batch 4780/5867, Loss: 0.1508\n",
      "Epoch 9, Batch 4790/5867, Loss: 0.3619\n",
      "Epoch 9, Batch 4800/5867, Loss: 0.4045\n",
      "Epoch 9, Batch 4810/5867, Loss: 0.3843\n",
      "Epoch 9, Batch 4820/5867, Loss: 0.2087\n",
      "Epoch 9, Batch 4830/5867, Loss: 0.1173\n",
      "Epoch 9, Batch 4840/5867, Loss: 0.1406\n",
      "Epoch 9, Batch 4850/5867, Loss: 0.1352\n",
      "Epoch 9, Batch 4860/5867, Loss: 0.1366\n",
      "Epoch 9, Batch 4870/5867, Loss: 0.3073\n",
      "Epoch 9, Batch 4880/5867, Loss: 0.1536\n",
      "Epoch 9, Batch 4890/5867, Loss: 0.2634\n",
      "Epoch 9, Batch 4900/5867, Loss: 0.1694\n",
      "Epoch 9, Batch 4910/5867, Loss: 0.1892\n",
      "Epoch 9, Batch 4920/5867, Loss: 0.1330\n",
      "Epoch 9, Batch 4930/5867, Loss: 0.1918\n",
      "Epoch 9, Batch 4940/5867, Loss: 0.1746\n",
      "Epoch 9, Batch 4950/5867, Loss: 0.2576\n",
      "Epoch 9, Batch 4960/5867, Loss: 0.0780\n",
      "Epoch 9, Batch 4970/5867, Loss: 0.2484\n",
      "Epoch 9, Batch 4980/5867, Loss: 0.1900\n",
      "Epoch 9, Batch 4990/5867, Loss: 0.1859\n",
      "Epoch 9, Batch 5000/5867, Loss: 0.3994\n",
      "Epoch 9, Batch 5010/5867, Loss: 0.2032\n",
      "Epoch 9, Batch 5020/5867, Loss: 0.4068\n",
      "Epoch 9, Batch 5030/5867, Loss: 0.2573\n",
      "Epoch 9, Batch 5040/5867, Loss: 0.2624\n",
      "Epoch 9, Batch 5050/5867, Loss: 0.0800\n",
      "Epoch 9, Batch 5060/5867, Loss: 0.2335\n",
      "Epoch 9, Batch 5070/5867, Loss: 0.1886\n",
      "Epoch 9, Batch 5080/5867, Loss: 0.3558\n",
      "Epoch 9, Batch 5090/5867, Loss: 0.2174\n",
      "Epoch 9, Batch 5100/5867, Loss: 0.3734\n",
      "Epoch 9, Batch 5110/5867, Loss: 0.2522\n",
      "Epoch 9, Batch 5120/5867, Loss: 0.1406\n",
      "Epoch 9, Batch 5130/5867, Loss: 0.2433\n",
      "Epoch 9, Batch 5140/5867, Loss: 0.1028\n",
      "Epoch 9, Batch 5150/5867, Loss: 0.0632\n",
      "Epoch 9, Batch 5160/5867, Loss: 0.1364\n",
      "Epoch 9, Batch 5170/5867, Loss: 0.2341\n",
      "Epoch 9, Batch 5180/5867, Loss: 0.1626\n",
      "Epoch 9, Batch 5190/5867, Loss: 0.2889\n",
      "Epoch 9, Batch 5200/5867, Loss: 0.1134\n",
      "Epoch 9, Batch 5210/5867, Loss: 0.0530\n",
      "Epoch 9, Batch 5220/5867, Loss: 0.2051\n",
      "Epoch 9, Batch 5230/5867, Loss: 0.2623\n",
      "Epoch 9, Batch 5240/5867, Loss: 0.0703\n",
      "Epoch 9, Batch 5250/5867, Loss: 0.1398\n",
      "Epoch 9, Batch 5260/5867, Loss: 0.1818\n",
      "Epoch 9, Batch 5270/5867, Loss: 0.0896\n",
      "Epoch 9, Batch 5280/5867, Loss: 0.2093\n",
      "Epoch 9, Batch 5290/5867, Loss: 0.3969\n",
      "Epoch 9, Batch 5300/5867, Loss: 0.1193\n",
      "Epoch 9, Batch 5310/5867, Loss: 0.3419\n",
      "Epoch 9, Batch 5320/5867, Loss: 0.1766\n",
      "Epoch 9, Batch 5330/5867, Loss: 0.1722\n",
      "Epoch 9, Batch 5340/5867, Loss: 0.0767\n",
      "Epoch 9, Batch 5350/5867, Loss: 0.1941\n",
      "Epoch 9, Batch 5360/5867, Loss: 0.2183\n",
      "Epoch 9, Batch 5370/5867, Loss: 0.1647\n",
      "Epoch 9, Batch 5380/5867, Loss: 0.2031\n",
      "Epoch 9, Batch 5390/5867, Loss: 0.2775\n",
      "Epoch 9, Batch 5400/5867, Loss: 0.0488\n",
      "Epoch 9, Batch 5410/5867, Loss: 0.2968\n",
      "Epoch 9, Batch 5420/5867, Loss: 0.1127\n",
      "Epoch 9, Batch 5430/5867, Loss: 0.1402\n",
      "Epoch 9, Batch 5440/5867, Loss: 0.2354\n",
      "Epoch 9, Batch 5450/5867, Loss: 0.0810\n",
      "Epoch 9, Batch 5460/5867, Loss: 0.2935\n",
      "Epoch 9, Batch 5470/5867, Loss: 0.1001\n",
      "Epoch 9, Batch 5480/5867, Loss: 0.1646\n",
      "Epoch 9, Batch 5490/5867, Loss: 0.2087\n",
      "Epoch 9, Batch 5500/5867, Loss: 0.1704\n",
      "Epoch 9, Batch 5510/5867, Loss: 0.1597\n",
      "Epoch 9, Batch 5520/5867, Loss: 0.2965\n",
      "Epoch 9, Batch 5530/5867, Loss: 0.2320\n",
      "Epoch 9, Batch 5540/5867, Loss: 0.3270\n",
      "Epoch 9, Batch 5550/5867, Loss: 0.1232\n",
      "Epoch 9, Batch 5560/5867, Loss: 0.2711\n",
      "Epoch 9, Batch 5570/5867, Loss: 0.5026\n",
      "Epoch 9, Batch 5580/5867, Loss: 0.1695\n",
      "Epoch 9, Batch 5590/5867, Loss: 0.1610\n",
      "Epoch 9, Batch 5600/5867, Loss: 0.1564\n",
      "Epoch 9, Batch 5610/5867, Loss: 0.4099\n",
      "Epoch 9, Batch 5620/5867, Loss: 0.1976\n",
      "Epoch 9, Batch 5630/5867, Loss: 0.2176\n",
      "Epoch 9, Batch 5640/5867, Loss: 0.1771\n",
      "Epoch 9, Batch 5650/5867, Loss: 0.1018\n",
      "Epoch 9, Batch 5660/5867, Loss: 0.1185\n",
      "Epoch 9, Batch 5670/5867, Loss: 0.2323\n",
      "Epoch 9, Batch 5680/5867, Loss: 0.1958\n",
      "Epoch 9, Batch 5690/5867, Loss: 0.1662\n",
      "Epoch 9, Batch 5700/5867, Loss: 0.1983\n",
      "Epoch 9, Batch 5710/5867, Loss: 0.3624\n",
      "Epoch 9, Batch 5720/5867, Loss: 0.1581\n",
      "Epoch 9, Batch 5730/5867, Loss: 0.1802\n",
      "Epoch 9, Batch 5740/5867, Loss: 0.0615\n",
      "Epoch 9, Batch 5750/5867, Loss: 0.0928\n",
      "Epoch 9, Batch 5760/5867, Loss: 0.2446\n",
      "Epoch 9, Batch 5770/5867, Loss: 0.2638\n",
      "Epoch 9, Batch 5780/5867, Loss: 0.1277\n",
      "Epoch 9, Batch 5790/5867, Loss: 0.2131\n",
      "Epoch 9, Batch 5800/5867, Loss: 0.1951\n",
      "Epoch 9, Batch 5810/5867, Loss: 0.1969\n",
      "Epoch 9, Batch 5820/5867, Loss: 0.1934\n",
      "Epoch 9, Batch 5830/5867, Loss: 0.1198\n",
      "Epoch 9, Batch 5840/5867, Loss: 0.2236\n",
      "Epoch 9, Batch 5850/5867, Loss: 0.0905\n",
      "Epoch 9, Batch 5860/5867, Loss: 0.1060\n",
      "Epoch 9, Training Loss: 0.1834, Validation Loss: 0.1853\n",
      "Starting epoch 10...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 10/5867, Loss: 0.2338\n",
      "Epoch 10, Batch 20/5867, Loss: 0.2370\n",
      "Epoch 10, Batch 30/5867, Loss: 0.1786\n",
      "Epoch 10, Batch 40/5867, Loss: 0.3372\n",
      "Epoch 10, Batch 50/5867, Loss: 0.1661\n",
      "Epoch 10, Batch 60/5867, Loss: 0.2611\n",
      "Epoch 10, Batch 70/5867, Loss: 0.2699\n",
      "Epoch 10, Batch 80/5867, Loss: 0.1948\n",
      "Epoch 10, Batch 90/5867, Loss: 0.0902\n",
      "Epoch 10, Batch 100/5867, Loss: 0.2144\n",
      "Epoch 10, Batch 110/5867, Loss: 0.1916\n",
      "Epoch 10, Batch 120/5867, Loss: 0.1426\n",
      "Epoch 10, Batch 130/5867, Loss: 0.0297\n",
      "Epoch 10, Batch 140/5867, Loss: 0.1402\n",
      "Epoch 10, Batch 150/5867, Loss: 0.1708\n",
      "Epoch 10, Batch 160/5867, Loss: 0.1022\n",
      "Epoch 10, Batch 170/5867, Loss: 0.1522\n",
      "Epoch 10, Batch 180/5867, Loss: 0.2134\n",
      "Epoch 10, Batch 190/5867, Loss: 0.1058\n",
      "Epoch 10, Batch 200/5867, Loss: 0.1298\n",
      "Epoch 10, Batch 210/5867, Loss: 0.0625\n",
      "Epoch 10, Batch 220/5867, Loss: 0.2043\n",
      "Epoch 10, Batch 230/5867, Loss: 0.2830\n",
      "Epoch 10, Batch 240/5867, Loss: 0.1010\n",
      "Epoch 10, Batch 250/5867, Loss: 0.3784\n",
      "Epoch 10, Batch 260/5867, Loss: 0.1160\n",
      "Epoch 10, Batch 270/5867, Loss: 0.1667\n",
      "Epoch 10, Batch 280/5867, Loss: 0.0844\n",
      "Epoch 10, Batch 290/5867, Loss: 0.0963\n",
      "Epoch 10, Batch 300/5867, Loss: 0.0349\n",
      "Epoch 10, Batch 310/5867, Loss: 0.2840\n",
      "Epoch 10, Batch 320/5867, Loss: 0.2292\n",
      "Epoch 10, Batch 330/5867, Loss: 0.3890\n",
      "Epoch 10, Batch 340/5867, Loss: 0.4901\n",
      "Epoch 10, Batch 350/5867, Loss: 0.0754\n",
      "Epoch 10, Batch 360/5867, Loss: 0.0981\n",
      "Epoch 10, Batch 370/5867, Loss: 0.1308\n",
      "Epoch 10, Batch 380/5867, Loss: 0.1094\n",
      "Epoch 10, Batch 390/5867, Loss: 0.0605\n",
      "Epoch 10, Batch 400/5867, Loss: 0.1879\n",
      "Epoch 10, Batch 410/5867, Loss: 0.2131\n",
      "Epoch 10, Batch 420/5867, Loss: 0.1990\n",
      "Epoch 10, Batch 430/5867, Loss: 0.1435\n",
      "Epoch 10, Batch 440/5867, Loss: 0.1483\n",
      "Epoch 10, Batch 450/5867, Loss: 0.1509\n",
      "Epoch 10, Batch 460/5867, Loss: 0.1327\n",
      "Epoch 10, Batch 470/5867, Loss: 0.1038\n",
      "Epoch 10, Batch 480/5867, Loss: 0.0971\n",
      "Epoch 10, Batch 490/5867, Loss: 0.0915\n",
      "Epoch 10, Batch 500/5867, Loss: 0.0903\n",
      "Epoch 10, Batch 510/5867, Loss: 0.3160\n",
      "Epoch 10, Batch 520/5867, Loss: 0.0496\n",
      "Epoch 10, Batch 530/5867, Loss: 0.0728\n",
      "Epoch 10, Batch 540/5867, Loss: 0.1634\n",
      "Epoch 10, Batch 550/5867, Loss: 0.1329\n",
      "Epoch 10, Batch 560/5867, Loss: 0.1655\n",
      "Epoch 10, Batch 570/5867, Loss: 0.3505\n",
      "Epoch 10, Batch 580/5867, Loss: 0.0800\n",
      "Epoch 10, Batch 590/5867, Loss: 0.1536\n",
      "Epoch 10, Batch 600/5867, Loss: 0.1177\n",
      "Epoch 10, Batch 610/5867, Loss: 0.1078\n",
      "Epoch 10, Batch 620/5867, Loss: 0.1535\n",
      "Epoch 10, Batch 630/5867, Loss: 0.4099\n",
      "Epoch 10, Batch 640/5867, Loss: 0.1617\n",
      "Epoch 10, Batch 650/5867, Loss: 0.2880\n",
      "Epoch 10, Batch 660/5867, Loss: 0.1899\n",
      "Epoch 10, Batch 670/5867, Loss: 0.2717\n",
      "Epoch 10, Batch 680/5867, Loss: 0.1077\n",
      "Epoch 10, Batch 690/5867, Loss: 0.0968\n",
      "Epoch 10, Batch 700/5867, Loss: 0.2602\n",
      "Epoch 10, Batch 710/5867, Loss: 0.1506\n",
      "Epoch 10, Batch 720/5867, Loss: 0.0846\n",
      "Epoch 10, Batch 730/5867, Loss: 0.0681\n",
      "Epoch 10, Batch 740/5867, Loss: 0.1827\n",
      "Epoch 10, Batch 750/5867, Loss: 0.1919\n",
      "Epoch 10, Batch 760/5867, Loss: 0.2161\n",
      "Epoch 10, Batch 770/5867, Loss: 0.1279\n",
      "Epoch 10, Batch 780/5867, Loss: 0.1760\n",
      "Epoch 10, Batch 790/5867, Loss: 0.1299\n",
      "Epoch 10, Batch 800/5867, Loss: 0.2698\n",
      "Epoch 10, Batch 810/5867, Loss: 0.2093\n",
      "Epoch 10, Batch 820/5867, Loss: 0.2460\n",
      "Epoch 10, Batch 830/5867, Loss: 0.1180\n",
      "Epoch 10, Batch 840/5867, Loss: 0.1584\n",
      "Epoch 10, Batch 850/5867, Loss: 0.1336\n",
      "Epoch 10, Batch 860/5867, Loss: 0.1652\n",
      "Epoch 10, Batch 870/5867, Loss: 0.2988\n",
      "Epoch 10, Batch 880/5867, Loss: 0.1413\n",
      "Epoch 10, Batch 890/5867, Loss: 0.3347\n",
      "Epoch 10, Batch 900/5867, Loss: 0.2522\n",
      "Epoch 10, Batch 910/5867, Loss: 0.1074\n",
      "Epoch 10, Batch 920/5867, Loss: 0.1117\n",
      "Epoch 10, Batch 930/5867, Loss: 0.2929\n",
      "Epoch 10, Batch 940/5867, Loss: 0.3266\n",
      "Epoch 10, Batch 950/5867, Loss: 0.1800\n",
      "Epoch 10, Batch 960/5867, Loss: 0.0970\n",
      "Epoch 10, Batch 970/5867, Loss: 0.1019\n",
      "Epoch 10, Batch 980/5867, Loss: 0.2407\n",
      "Epoch 10, Batch 990/5867, Loss: 0.0375\n",
      "Epoch 10, Batch 1000/5867, Loss: 0.3689\n",
      "Epoch 10, Batch 1010/5867, Loss: 0.1647\n",
      "Epoch 10, Batch 1020/5867, Loss: 0.0360\n",
      "Epoch 10, Batch 1030/5867, Loss: 0.1880\n",
      "Epoch 10, Batch 1040/5867, Loss: 0.0807\n",
      "Epoch 10, Batch 1050/5867, Loss: 0.1873\n",
      "Epoch 10, Batch 1060/5867, Loss: 0.1888\n",
      "Epoch 10, Batch 1070/5867, Loss: 0.0693\n",
      "Epoch 10, Batch 1080/5867, Loss: 0.2421\n",
      "Epoch 10, Batch 1090/5867, Loss: 0.1602\n",
      "Epoch 10, Batch 1100/5867, Loss: 0.1626\n",
      "Epoch 10, Batch 1110/5867, Loss: 0.1757\n",
      "Epoch 10, Batch 1120/5867, Loss: 0.2412\n",
      "Epoch 10, Batch 1130/5867, Loss: 0.2226\n",
      "Epoch 10, Batch 1140/5867, Loss: 0.2771\n",
      "Epoch 10, Batch 1150/5867, Loss: 0.1858\n",
      "Epoch 10, Batch 1160/5867, Loss: 0.2163\n",
      "Epoch 10, Batch 1170/5867, Loss: 0.1451\n",
      "Epoch 10, Batch 1180/5867, Loss: 0.0938\n",
      "Epoch 10, Batch 1190/5867, Loss: 0.0787\n",
      "Epoch 10, Batch 1200/5867, Loss: 0.2151\n",
      "Epoch 10, Batch 1210/5867, Loss: 0.0708\n",
      "Epoch 10, Batch 1220/5867, Loss: 0.0771\n",
      "Epoch 10, Batch 1230/5867, Loss: 0.1496\n",
      "Epoch 10, Batch 1240/5867, Loss: 0.1727\n",
      "Epoch 10, Batch 1250/5867, Loss: 0.2159\n",
      "Epoch 10, Batch 1260/5867, Loss: 0.1180\n",
      "Epoch 10, Batch 1270/5867, Loss: 0.2181\n",
      "Epoch 10, Batch 1280/5867, Loss: 0.3032\n",
      "Epoch 10, Batch 1290/5867, Loss: 0.1664\n",
      "Epoch 10, Batch 1300/5867, Loss: 0.1843\n",
      "Epoch 10, Batch 1310/5867, Loss: 0.4022\n",
      "Epoch 10, Batch 1320/5867, Loss: 0.1066\n",
      "Epoch 10, Batch 1330/5867, Loss: 0.1859\n",
      "Epoch 10, Batch 1340/5867, Loss: 0.1717\n",
      "Epoch 10, Batch 1350/5867, Loss: 0.1188\n",
      "Epoch 10, Batch 1360/5867, Loss: 0.2039\n",
      "Epoch 10, Batch 1370/5867, Loss: 0.1064\n",
      "Epoch 10, Batch 1380/5867, Loss: 0.2088\n",
      "Epoch 10, Batch 1390/5867, Loss: 0.1810\n",
      "Epoch 10, Batch 1400/5867, Loss: 0.1858\n",
      "Epoch 10, Batch 1410/5867, Loss: 0.0936\n",
      "Epoch 10, Batch 1420/5867, Loss: 0.1718\n",
      "Epoch 10, Batch 1430/5867, Loss: 0.2190\n",
      "Epoch 10, Batch 1440/5867, Loss: 0.1078\n",
      "Epoch 10, Batch 1450/5867, Loss: 0.2241\n",
      "Epoch 10, Batch 1460/5867, Loss: 0.2001\n",
      "Epoch 10, Batch 1470/5867, Loss: 0.1729\n",
      "Epoch 10, Batch 1480/5867, Loss: 0.1606\n",
      "Epoch 10, Batch 1490/5867, Loss: 0.1637\n",
      "Epoch 10, Batch 1500/5867, Loss: 0.2252\n",
      "Epoch 10, Batch 1510/5867, Loss: 0.1541\n",
      "Epoch 10, Batch 1520/5867, Loss: 0.1466\n",
      "Epoch 10, Batch 1530/5867, Loss: 0.2706\n",
      "Epoch 10, Batch 1540/5867, Loss: 0.2324\n",
      "Epoch 10, Batch 1550/5867, Loss: 0.3294\n",
      "Epoch 10, Batch 1560/5867, Loss: 0.1275\n",
      "Epoch 10, Batch 1570/5867, Loss: 0.1562\n",
      "Epoch 10, Batch 1580/5867, Loss: 0.3009\n",
      "Epoch 10, Batch 1590/5867, Loss: 0.0836\n",
      "Epoch 10, Batch 1600/5867, Loss: 0.1776\n",
      "Epoch 10, Batch 1610/5867, Loss: 0.1633\n",
      "Epoch 10, Batch 1620/5867, Loss: 0.2851\n",
      "Epoch 10, Batch 1630/5867, Loss: 0.2050\n",
      "Epoch 10, Batch 1640/5867, Loss: 0.0932\n",
      "Epoch 10, Batch 1650/5867, Loss: 0.0367\n",
      "Epoch 10, Batch 1660/5867, Loss: 0.1546\n",
      "Epoch 10, Batch 1670/5867, Loss: 0.3378\n",
      "Epoch 10, Batch 1680/5867, Loss: 0.0433\n",
      "Epoch 10, Batch 1690/5867, Loss: 0.1876\n",
      "Epoch 10, Batch 1700/5867, Loss: 0.3723\n",
      "Epoch 10, Batch 1710/5867, Loss: 0.1636\n",
      "Epoch 10, Batch 1720/5867, Loss: 0.0705\n",
      "Epoch 10, Batch 1730/5867, Loss: 0.1993\n",
      "Epoch 10, Batch 1740/5867, Loss: 0.1296\n",
      "Epoch 10, Batch 1750/5867, Loss: 0.1056\n",
      "Epoch 10, Batch 1760/5867, Loss: 0.1161\n",
      "Epoch 10, Batch 1770/5867, Loss: 0.1521\n",
      "Epoch 10, Batch 1780/5867, Loss: 0.1881\n",
      "Epoch 10, Batch 1790/5867, Loss: 0.1936\n",
      "Epoch 10, Batch 1800/5867, Loss: 0.1605\n",
      "Epoch 10, Batch 1810/5867, Loss: 0.2344\n",
      "Epoch 10, Batch 1820/5867, Loss: 0.1181\n",
      "Epoch 10, Batch 1830/5867, Loss: 0.1574\n",
      "Epoch 10, Batch 1840/5867, Loss: 0.2838\n",
      "Epoch 10, Batch 1850/5867, Loss: 0.2022\n",
      "Epoch 10, Batch 1860/5867, Loss: 0.1883\n",
      "Epoch 10, Batch 1870/5867, Loss: 0.1298\n",
      "Epoch 10, Batch 1880/5867, Loss: 0.0775\n",
      "Epoch 10, Batch 1890/5867, Loss: 0.0582\n",
      "Epoch 10, Batch 1900/5867, Loss: 0.1324\n",
      "Epoch 10, Batch 1910/5867, Loss: 0.3401\n",
      "Epoch 10, Batch 1920/5867, Loss: 0.1748\n",
      "Epoch 10, Batch 1930/5867, Loss: 0.2533\n",
      "Epoch 10, Batch 1940/5867, Loss: 0.2577\n",
      "Epoch 10, Batch 1950/5867, Loss: 0.0981\n",
      "Epoch 10, Batch 1960/5867, Loss: 0.1487\n",
      "Epoch 10, Batch 1970/5867, Loss: 0.0911\n",
      "Epoch 10, Batch 1980/5867, Loss: 0.1867\n",
      "Epoch 10, Batch 1990/5867, Loss: 0.1254\n",
      "Epoch 10, Batch 2000/5867, Loss: 0.1215\n",
      "Epoch 10, Batch 2010/5867, Loss: 0.0552\n",
      "Epoch 10, Batch 2020/5867, Loss: 0.2615\n",
      "Epoch 10, Batch 2030/5867, Loss: 0.1291\n",
      "Epoch 10, Batch 2040/5867, Loss: 0.0584\n",
      "Epoch 10, Batch 2050/5867, Loss: 0.2851\n",
      "Epoch 10, Batch 2060/5867, Loss: 0.1473\n",
      "Epoch 10, Batch 2070/5867, Loss: 0.1333\n",
      "Epoch 10, Batch 2080/5867, Loss: 0.1621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 2090/5867, Loss: 0.1194\n",
      "Epoch 10, Batch 2100/5867, Loss: 0.1482\n",
      "Epoch 10, Batch 2110/5867, Loss: 0.2291\n",
      "Epoch 10, Batch 2120/5867, Loss: 0.1203\n",
      "Epoch 10, Batch 2130/5867, Loss: 0.1875\n",
      "Epoch 10, Batch 2140/5867, Loss: 0.0779\n",
      "Epoch 10, Batch 2150/5867, Loss: 0.1187\n",
      "Epoch 10, Batch 2160/5867, Loss: 0.2558\n",
      "Epoch 10, Batch 2170/5867, Loss: 0.2943\n",
      "Epoch 10, Batch 2180/5867, Loss: 0.4404\n",
      "Epoch 10, Batch 2190/5867, Loss: 0.1613\n",
      "Epoch 10, Batch 2200/5867, Loss: 0.4242\n",
      "Epoch 10, Batch 2210/5867, Loss: 0.0926\n",
      "Epoch 10, Batch 2220/5867, Loss: 0.2096\n",
      "Epoch 10, Batch 2230/5867, Loss: 0.0980\n",
      "Epoch 10, Batch 2240/5867, Loss: 0.2113\n",
      "Epoch 10, Batch 2250/5867, Loss: 0.2625\n",
      "Epoch 10, Batch 2260/5867, Loss: 0.1285\n",
      "Epoch 10, Batch 2270/5867, Loss: 0.0382\n",
      "Epoch 10, Batch 2280/5867, Loss: 0.4016\n",
      "Epoch 10, Batch 2290/5867, Loss: 0.1155\n",
      "Epoch 10, Batch 2300/5867, Loss: 0.1874\n",
      "Epoch 10, Batch 2310/5867, Loss: 0.1468\n",
      "Epoch 10, Batch 2320/5867, Loss: 0.0819\n",
      "Epoch 10, Batch 2330/5867, Loss: 0.1506\n",
      "Epoch 10, Batch 2340/5867, Loss: 0.2171\n",
      "Epoch 10, Batch 2350/5867, Loss: 0.1352\n",
      "Epoch 10, Batch 2360/5867, Loss: 0.2133\n",
      "Epoch 10, Batch 2370/5867, Loss: 0.2114\n",
      "Epoch 10, Batch 2380/5867, Loss: 0.1921\n",
      "Epoch 10, Batch 2390/5867, Loss: 0.2065\n",
      "Epoch 10, Batch 2400/5867, Loss: 0.1408\n",
      "Epoch 10, Batch 2410/5867, Loss: 0.1312\n",
      "Epoch 10, Batch 2420/5867, Loss: 0.0807\n",
      "Epoch 10, Batch 2430/5867, Loss: 0.2220\n",
      "Epoch 10, Batch 2440/5867, Loss: 0.3825\n",
      "Epoch 10, Batch 2450/5867, Loss: 0.0833\n",
      "Epoch 10, Batch 2460/5867, Loss: 0.1702\n",
      "Epoch 10, Batch 2470/5867, Loss: 0.1778\n",
      "Epoch 10, Batch 2480/5867, Loss: 0.1668\n",
      "Epoch 10, Batch 2490/5867, Loss: 0.1952\n",
      "Epoch 10, Batch 2500/5867, Loss: 0.1413\n",
      "Epoch 10, Batch 2510/5867, Loss: 0.1911\n",
      "Epoch 10, Batch 2520/5867, Loss: 0.2601\n",
      "Epoch 10, Batch 2530/5867, Loss: 0.1843\n",
      "Epoch 10, Batch 2540/5867, Loss: 0.1717\n",
      "Epoch 10, Batch 2550/5867, Loss: 0.2089\n",
      "Epoch 10, Batch 2560/5867, Loss: 0.2928\n",
      "Epoch 10, Batch 2570/5867, Loss: 0.1211\n",
      "Epoch 10, Batch 2580/5867, Loss: 0.3270\n",
      "Epoch 10, Batch 2590/5867, Loss: 0.1141\n",
      "Epoch 10, Batch 2600/5867, Loss: 0.0533\n",
      "Epoch 10, Batch 2610/5867, Loss: 0.1563\n",
      "Epoch 10, Batch 2620/5867, Loss: 0.2375\n",
      "Epoch 10, Batch 2630/5867, Loss: 0.1734\n",
      "Epoch 10, Batch 2640/5867, Loss: 0.1877\n",
      "Epoch 10, Batch 2650/5867, Loss: 0.1451\n",
      "Epoch 10, Batch 2660/5867, Loss: 0.0404\n",
      "Epoch 10, Batch 2670/5867, Loss: 0.1250\n",
      "Epoch 10, Batch 2680/5867, Loss: 0.1642\n",
      "Epoch 10, Batch 2690/5867, Loss: 0.1351\n",
      "Epoch 10, Batch 2700/5867, Loss: 0.1021\n",
      "Epoch 10, Batch 2710/5867, Loss: 0.0980\n",
      "Epoch 10, Batch 2720/5867, Loss: 0.2537\n",
      "Epoch 10, Batch 2730/5867, Loss: 0.3419\n",
      "Epoch 10, Batch 2740/5867, Loss: 0.1505\n",
      "Epoch 10, Batch 2750/5867, Loss: 0.4708\n",
      "Epoch 10, Batch 2760/5867, Loss: 0.1437\n",
      "Epoch 10, Batch 2770/5867, Loss: 0.1677\n",
      "Epoch 10, Batch 2780/5867, Loss: 0.1359\n",
      "Epoch 10, Batch 2790/5867, Loss: 0.2238\n",
      "Epoch 10, Batch 2800/5867, Loss: 0.2437\n",
      "Epoch 10, Batch 2810/5867, Loss: 0.2747\n",
      "Epoch 10, Batch 2820/5867, Loss: 0.1596\n",
      "Epoch 10, Batch 2830/5867, Loss: 0.1350\n",
      "Epoch 10, Batch 2840/5867, Loss: 0.1343\n",
      "Epoch 10, Batch 2850/5867, Loss: 0.1624\n",
      "Epoch 10, Batch 2860/5867, Loss: 0.3356\n",
      "Epoch 10, Batch 2870/5867, Loss: 0.3125\n",
      "Epoch 10, Batch 2880/5867, Loss: 0.1561\n",
      "Epoch 10, Batch 2890/5867, Loss: 0.1764\n",
      "Epoch 10, Batch 2900/5867, Loss: 0.1424\n",
      "Epoch 10, Batch 2910/5867, Loss: 0.3484\n",
      "Epoch 10, Batch 2920/5867, Loss: 0.0930\n",
      "Epoch 10, Batch 2930/5867, Loss: 0.1007\n",
      "Epoch 10, Batch 2940/5867, Loss: 0.2489\n",
      "Epoch 10, Batch 2950/5867, Loss: 0.1682\n",
      "Epoch 10, Batch 2960/5867, Loss: 0.0614\n",
      "Epoch 10, Batch 2970/5867, Loss: 0.2951\n",
      "Epoch 10, Batch 2980/5867, Loss: 0.3819\n",
      "Epoch 10, Batch 2990/5867, Loss: 0.2702\n",
      "Epoch 10, Batch 3000/5867, Loss: 0.3709\n",
      "Epoch 10, Batch 3010/5867, Loss: 0.1900\n",
      "Epoch 10, Batch 3020/5867, Loss: 0.0630\n",
      "Epoch 10, Batch 3030/5867, Loss: 0.2036\n",
      "Epoch 10, Batch 3040/5867, Loss: 0.2368\n",
      "Epoch 10, Batch 3050/5867, Loss: 0.2478\n",
      "Epoch 10, Batch 3060/5867, Loss: 0.1365\n",
      "Epoch 10, Batch 3070/5867, Loss: 0.2292\n",
      "Epoch 10, Batch 3080/5867, Loss: 0.0823\n",
      "Epoch 10, Batch 3090/5867, Loss: 0.1369\n",
      "Epoch 10, Batch 3100/5867, Loss: 0.0771\n",
      "Epoch 10, Batch 3110/5867, Loss: 0.1908\n",
      "Epoch 10, Batch 3120/5867, Loss: 0.0682\n",
      "Epoch 10, Batch 3130/5867, Loss: 0.2166\n",
      "Epoch 10, Batch 3140/5867, Loss: 0.0748\n",
      "Epoch 10, Batch 3150/5867, Loss: 0.1318\n",
      "Epoch 10, Batch 3160/5867, Loss: 0.1830\n",
      "Epoch 10, Batch 3170/5867, Loss: 0.2442\n",
      "Epoch 10, Batch 3180/5867, Loss: 0.2096\n",
      "Epoch 10, Batch 3190/5867, Loss: 0.0928\n",
      "Epoch 10, Batch 3200/5867, Loss: 0.1154\n",
      "Epoch 10, Batch 3210/5867, Loss: 0.1659\n",
      "Epoch 10, Batch 3220/5867, Loss: 0.0956\n",
      "Epoch 10, Batch 3230/5867, Loss: 0.2081\n",
      "Epoch 10, Batch 3240/5867, Loss: 0.0781\n",
      "Epoch 10, Batch 3250/5867, Loss: 0.1243\n",
      "Epoch 10, Batch 3260/5867, Loss: 0.2851\n",
      "Epoch 10, Batch 3270/5867, Loss: 0.2383\n",
      "Epoch 10, Batch 3280/5867, Loss: 0.1536\n",
      "Epoch 10, Batch 3290/5867, Loss: 0.2362\n",
      "Epoch 10, Batch 3300/5867, Loss: 0.3895\n",
      "Epoch 10, Batch 3310/5867, Loss: 0.1532\n",
      "Epoch 10, Batch 3320/5867, Loss: 0.1582\n",
      "Epoch 10, Batch 3330/5867, Loss: 0.1593\n",
      "Epoch 10, Batch 3340/5867, Loss: 0.1735\n",
      "Epoch 10, Batch 3350/5867, Loss: 0.1081\n",
      "Epoch 10, Batch 3360/5867, Loss: 0.1018\n",
      "Epoch 10, Batch 3370/5867, Loss: 0.1030\n",
      "Epoch 10, Batch 3380/5867, Loss: 0.0615\n",
      "Epoch 10, Batch 3390/5867, Loss: 0.0689\n",
      "Epoch 10, Batch 3400/5867, Loss: 0.2944\n",
      "Epoch 10, Batch 3410/5867, Loss: 0.2532\n",
      "Epoch 10, Batch 3420/5867, Loss: 0.3152\n",
      "Epoch 10, Batch 3430/5867, Loss: 0.1364\n",
      "Epoch 10, Batch 3440/5867, Loss: 0.1697\n",
      "Epoch 10, Batch 3450/5867, Loss: 0.2423\n",
      "Epoch 10, Batch 3460/5867, Loss: 0.2481\n",
      "Epoch 10, Batch 3470/5867, Loss: 0.1321\n",
      "Epoch 10, Batch 3480/5867, Loss: 0.2557\n",
      "Epoch 10, Batch 3490/5867, Loss: 0.3661\n",
      "Epoch 10, Batch 3500/5867, Loss: 0.2982\n",
      "Epoch 10, Batch 3510/5867, Loss: 0.1390\n",
      "Epoch 10, Batch 3520/5867, Loss: 0.1289\n",
      "Epoch 10, Batch 3530/5867, Loss: 0.1103\n",
      "Epoch 10, Batch 3540/5867, Loss: 0.1295\n",
      "Epoch 10, Batch 3550/5867, Loss: 0.0598\n",
      "Epoch 10, Batch 3560/5867, Loss: 0.2208\n",
      "Epoch 10, Batch 3570/5867, Loss: 0.2811\n",
      "Epoch 10, Batch 3580/5867, Loss: 0.0965\n",
      "Epoch 10, Batch 3590/5867, Loss: 0.2950\n",
      "Epoch 10, Batch 3600/5867, Loss: 0.1757\n",
      "Epoch 10, Batch 3610/5867, Loss: 0.1578\n",
      "Epoch 10, Batch 3620/5867, Loss: 0.2420\n",
      "Epoch 10, Batch 3630/5867, Loss: 0.0967\n",
      "Epoch 10, Batch 3640/5867, Loss: 0.2098\n",
      "Epoch 10, Batch 3650/5867, Loss: 0.1021\n",
      "Epoch 10, Batch 3660/5867, Loss: 0.1374\n",
      "Epoch 10, Batch 3670/5867, Loss: 0.2515\n",
      "Epoch 10, Batch 3680/5867, Loss: 0.3592\n",
      "Epoch 10, Batch 3690/5867, Loss: 0.1330\n",
      "Epoch 10, Batch 3700/5867, Loss: 0.1577\n",
      "Epoch 10, Batch 3710/5867, Loss: 0.3053\n",
      "Epoch 10, Batch 3720/5867, Loss: 0.3818\n",
      "Epoch 10, Batch 3730/5867, Loss: 0.2618\n",
      "Epoch 10, Batch 3740/5867, Loss: 0.1224\n",
      "Epoch 10, Batch 3750/5867, Loss: 0.1966\n",
      "Epoch 10, Batch 3760/5867, Loss: 0.1087\n",
      "Epoch 10, Batch 3770/5867, Loss: 0.1472\n",
      "Epoch 10, Batch 3780/5867, Loss: 0.2352\n",
      "Epoch 10, Batch 3790/5867, Loss: 0.0392\n",
      "Epoch 10, Batch 3800/5867, Loss: 0.2863\n",
      "Epoch 10, Batch 3810/5867, Loss: 0.1118\n",
      "Epoch 10, Batch 3820/5867, Loss: 0.1948\n",
      "Epoch 10, Batch 3830/5867, Loss: 0.0095\n",
      "Epoch 10, Batch 3840/5867, Loss: 0.2172\n",
      "Epoch 10, Batch 3850/5867, Loss: 0.1031\n",
      "Epoch 10, Batch 3860/5867, Loss: 0.3209\n",
      "Epoch 10, Batch 3870/5867, Loss: 0.0842\n",
      "Epoch 10, Batch 3880/5867, Loss: 0.0524\n",
      "Epoch 10, Batch 3890/5867, Loss: 0.2813\n",
      "Epoch 10, Batch 3900/5867, Loss: 0.2974\n",
      "Epoch 10, Batch 3910/5867, Loss: 0.1058\n",
      "Epoch 10, Batch 3920/5867, Loss: 0.3436\n",
      "Epoch 10, Batch 3930/5867, Loss: 0.2935\n",
      "Epoch 10, Batch 3940/5867, Loss: 0.2203\n",
      "Epoch 10, Batch 3950/5867, Loss: 0.2083\n",
      "Epoch 10, Batch 3960/5867, Loss: 0.1771\n",
      "Epoch 10, Batch 3970/5867, Loss: 0.2895\n",
      "Epoch 10, Batch 3980/5867, Loss: 0.0902\n",
      "Epoch 10, Batch 3990/5867, Loss: 0.0745\n",
      "Epoch 10, Batch 4000/5867, Loss: 0.1779\n",
      "Epoch 10, Batch 4010/5867, Loss: 0.0840\n",
      "Epoch 10, Batch 4020/5867, Loss: 0.3098\n",
      "Epoch 10, Batch 4030/5867, Loss: 0.1646\n",
      "Epoch 10, Batch 4040/5867, Loss: 0.2101\n",
      "Epoch 10, Batch 4050/5867, Loss: 0.1744\n",
      "Epoch 10, Batch 4060/5867, Loss: 0.1302\n",
      "Epoch 10, Batch 4070/5867, Loss: 0.2247\n",
      "Epoch 10, Batch 4080/5867, Loss: 0.1930\n",
      "Epoch 10, Batch 4090/5867, Loss: 0.1170\n",
      "Epoch 10, Batch 4100/5867, Loss: 0.2685\n",
      "Epoch 10, Batch 4110/5867, Loss: 0.0890\n",
      "Epoch 10, Batch 4120/5867, Loss: 0.1116\n",
      "Epoch 10, Batch 4130/5867, Loss: 0.1914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 4140/5867, Loss: 0.1085\n",
      "Epoch 10, Batch 4150/5867, Loss: 0.1776\n",
      "Epoch 10, Batch 4160/5867, Loss: 0.2200\n",
      "Epoch 10, Batch 4170/5867, Loss: 0.3557\n",
      "Epoch 10, Batch 4180/5867, Loss: 0.2788\n",
      "Epoch 10, Batch 4190/5867, Loss: 0.2253\n",
      "Epoch 10, Batch 4200/5867, Loss: 0.1370\n",
      "Epoch 10, Batch 4210/5867, Loss: 0.2676\n",
      "Epoch 10, Batch 4220/5867, Loss: 0.2750\n",
      "Epoch 10, Batch 4230/5867, Loss: 0.3790\n",
      "Epoch 10, Batch 4240/5867, Loss: 0.0531\n",
      "Epoch 10, Batch 4250/5867, Loss: 0.0416\n",
      "Epoch 10, Batch 4260/5867, Loss: 0.1501\n",
      "Epoch 10, Batch 4270/5867, Loss: 0.1579\n",
      "Epoch 10, Batch 4280/5867, Loss: 0.1538\n",
      "Epoch 10, Batch 4290/5867, Loss: 0.0990\n",
      "Epoch 10, Batch 4300/5867, Loss: 0.2476\n",
      "Epoch 10, Batch 4310/5867, Loss: 0.3496\n",
      "Epoch 10, Batch 4320/5867, Loss: 0.0939\n",
      "Epoch 10, Batch 4330/5867, Loss: 0.2281\n",
      "Epoch 10, Batch 4340/5867, Loss: 0.2310\n",
      "Epoch 10, Batch 4350/5867, Loss: 0.1414\n",
      "Epoch 10, Batch 4360/5867, Loss: 0.0770\n",
      "Epoch 10, Batch 4370/5867, Loss: 0.0506\n",
      "Epoch 10, Batch 4380/5867, Loss: 0.1145\n",
      "Epoch 10, Batch 4390/5867, Loss: 0.2011\n",
      "Epoch 10, Batch 4400/5867, Loss: 0.2801\n",
      "Epoch 10, Batch 4410/5867, Loss: 0.1021\n",
      "Epoch 10, Batch 4420/5867, Loss: 0.1642\n",
      "Epoch 10, Batch 4430/5867, Loss: 0.1366\n",
      "Epoch 10, Batch 4440/5867, Loss: 0.1272\n",
      "Epoch 10, Batch 4450/5867, Loss: 0.2522\n",
      "Epoch 10, Batch 4460/5867, Loss: 0.2271\n",
      "Epoch 10, Batch 4470/5867, Loss: 0.4494\n",
      "Epoch 10, Batch 4480/5867, Loss: 0.1376\n",
      "Epoch 10, Batch 4490/5867, Loss: 0.2178\n",
      "Epoch 10, Batch 4500/5867, Loss: 0.1430\n",
      "Epoch 10, Batch 4510/5867, Loss: 0.2266\n",
      "Epoch 10, Batch 4520/5867, Loss: 0.1273\n",
      "Epoch 10, Batch 4530/5867, Loss: 0.0475\n",
      "Epoch 10, Batch 4540/5867, Loss: 0.1347\n",
      "Epoch 10, Batch 4550/5867, Loss: 0.0868\n",
      "Epoch 10, Batch 4560/5867, Loss: 0.1601\n",
      "Epoch 10, Batch 4570/5867, Loss: 0.2966\n",
      "Epoch 10, Batch 4580/5867, Loss: 0.1291\n",
      "Epoch 10, Batch 4590/5867, Loss: 0.1080\n",
      "Epoch 10, Batch 4600/5867, Loss: 0.1222\n",
      "Epoch 10, Batch 4610/5867, Loss: 0.1327\n",
      "Epoch 10, Batch 4620/5867, Loss: 0.2561\n",
      "Epoch 10, Batch 4630/5867, Loss: 0.1699\n",
      "Epoch 10, Batch 4640/5867, Loss: 0.0921\n",
      "Epoch 10, Batch 4650/5867, Loss: 0.1007\n",
      "Epoch 10, Batch 4660/5867, Loss: 0.1343\n",
      "Epoch 10, Batch 4670/5867, Loss: 0.2063\n",
      "Epoch 10, Batch 4680/5867, Loss: 0.0934\n",
      "Epoch 10, Batch 4690/5867, Loss: 0.3375\n",
      "Epoch 10, Batch 4700/5867, Loss: 0.2480\n",
      "Epoch 10, Batch 4710/5867, Loss: 0.2585\n",
      "Epoch 10, Batch 4720/5867, Loss: 0.2896\n",
      "Epoch 10, Batch 4730/5867, Loss: 0.1188\n",
      "Epoch 10, Batch 4740/5867, Loss: 0.1608\n",
      "Epoch 10, Batch 4750/5867, Loss: 0.0896\n",
      "Epoch 10, Batch 4760/5867, Loss: 0.3027\n",
      "Epoch 10, Batch 4770/5867, Loss: 0.1078\n",
      "Epoch 10, Batch 4780/5867, Loss: 0.1351\n",
      "Epoch 10, Batch 4790/5867, Loss: 0.1068\n",
      "Epoch 10, Batch 4800/5867, Loss: 0.2098\n",
      "Epoch 10, Batch 4810/5867, Loss: 0.1987\n",
      "Epoch 10, Batch 4820/5867, Loss: 0.2966\n",
      "Epoch 10, Batch 4830/5867, Loss: 0.1275\n",
      "Epoch 10, Batch 4840/5867, Loss: 0.2322\n",
      "Epoch 10, Batch 4850/5867, Loss: 0.2029\n",
      "Epoch 10, Batch 4860/5867, Loss: 0.1913\n",
      "Epoch 10, Batch 4870/5867, Loss: 0.1503\n",
      "Epoch 10, Batch 4880/5867, Loss: 0.1009\n",
      "Epoch 10, Batch 4890/5867, Loss: 0.1010\n",
      "Epoch 10, Batch 4900/5867, Loss: 0.0954\n",
      "Epoch 10, Batch 4910/5867, Loss: 0.2496\n",
      "Epoch 10, Batch 4920/5867, Loss: 0.1029\n",
      "Epoch 10, Batch 4930/5867, Loss: 0.1460\n",
      "Epoch 10, Batch 4940/5867, Loss: 0.2607\n",
      "Epoch 10, Batch 4950/5867, Loss: 0.3257\n",
      "Epoch 10, Batch 4960/5867, Loss: 0.1312\n",
      "Epoch 10, Batch 4970/5867, Loss: 0.2465\n",
      "Epoch 10, Batch 4980/5867, Loss: 0.3267\n",
      "Epoch 10, Batch 4990/5867, Loss: 0.1433\n",
      "Epoch 10, Batch 5000/5867, Loss: 0.2897\n",
      "Epoch 10, Batch 5010/5867, Loss: 0.1482\n",
      "Epoch 10, Batch 5020/5867, Loss: 0.2601\n",
      "Epoch 10, Batch 5030/5867, Loss: 0.1873\n",
      "Epoch 10, Batch 5040/5867, Loss: 0.2493\n",
      "Epoch 10, Batch 5050/5867, Loss: 0.2819\n",
      "Epoch 10, Batch 5060/5867, Loss: 0.1313\n",
      "Epoch 10, Batch 5070/5867, Loss: 0.1371\n",
      "Epoch 10, Batch 5080/5867, Loss: 0.2495\n",
      "Epoch 10, Batch 5090/5867, Loss: 0.1603\n",
      "Epoch 10, Batch 5100/5867, Loss: 0.2763\n",
      "Epoch 10, Batch 5110/5867, Loss: 0.2366\n",
      "Epoch 10, Batch 5120/5867, Loss: 0.2139\n",
      "Epoch 10, Batch 5130/5867, Loss: 0.2752\n",
      "Epoch 10, Batch 5140/5867, Loss: 0.2019\n",
      "Epoch 10, Batch 5150/5867, Loss: 0.2068\n",
      "Epoch 10, Batch 5160/5867, Loss: 0.1115\n",
      "Epoch 10, Batch 5170/5867, Loss: 0.1702\n",
      "Epoch 10, Batch 5180/5867, Loss: 0.2361\n",
      "Epoch 10, Batch 5190/5867, Loss: 0.1965\n",
      "Epoch 10, Batch 5200/5867, Loss: 0.3213\n",
      "Epoch 10, Batch 5210/5867, Loss: 0.3068\n",
      "Epoch 10, Batch 5220/5867, Loss: 0.2579\n",
      "Epoch 10, Batch 5230/5867, Loss: 0.2548\n",
      "Epoch 10, Batch 5240/5867, Loss: 0.3008\n",
      "Epoch 10, Batch 5250/5867, Loss: 0.2758\n",
      "Epoch 10, Batch 5260/5867, Loss: 0.2156\n",
      "Epoch 10, Batch 5270/5867, Loss: 0.0883\n",
      "Epoch 10, Batch 5280/5867, Loss: 0.1707\n",
      "Epoch 10, Batch 5290/5867, Loss: 0.1218\n",
      "Epoch 10, Batch 5300/5867, Loss: 0.1606\n",
      "Epoch 10, Batch 5310/5867, Loss: 0.1203\n",
      "Epoch 10, Batch 5320/5867, Loss: 0.1755\n",
      "Epoch 10, Batch 5330/5867, Loss: 0.1582\n",
      "Epoch 10, Batch 5340/5867, Loss: 0.2224\n",
      "Epoch 10, Batch 5350/5867, Loss: 0.1012\n",
      "Epoch 10, Batch 5360/5867, Loss: 0.1244\n",
      "Epoch 10, Batch 5370/5867, Loss: 0.0535\n",
      "Epoch 10, Batch 5380/5867, Loss: 0.1916\n",
      "Epoch 10, Batch 5390/5867, Loss: 0.2021\n",
      "Epoch 10, Batch 5400/5867, Loss: 0.1233\n",
      "Epoch 10, Batch 5410/5867, Loss: 0.1179\n",
      "Epoch 10, Batch 5420/5867, Loss: 0.0571\n",
      "Epoch 10, Batch 5430/5867, Loss: 0.2061\n",
      "Epoch 10, Batch 5440/5867, Loss: 0.1616\n",
      "Epoch 10, Batch 5450/5867, Loss: 0.2021\n",
      "Epoch 10, Batch 5460/5867, Loss: 0.1686\n",
      "Epoch 10, Batch 5470/5867, Loss: 0.0767\n",
      "Epoch 10, Batch 5480/5867, Loss: 0.0578\n",
      "Epoch 10, Batch 5490/5867, Loss: 0.0473\n",
      "Epoch 10, Batch 5500/5867, Loss: 0.1343\n",
      "Epoch 10, Batch 5510/5867, Loss: 0.1622\n",
      "Epoch 10, Batch 5520/5867, Loss: 0.0610\n",
      "Epoch 10, Batch 5530/5867, Loss: 0.3521\n",
      "Epoch 10, Batch 5540/5867, Loss: 0.1633\n",
      "Epoch 10, Batch 5550/5867, Loss: 0.1931\n",
      "Epoch 10, Batch 5560/5867, Loss: 0.0632\n",
      "Epoch 10, Batch 5570/5867, Loss: 0.1448\n",
      "Epoch 10, Batch 5580/5867, Loss: 0.2316\n",
      "Epoch 10, Batch 5590/5867, Loss: 0.2067\n",
      "Epoch 10, Batch 5600/5867, Loss: 0.4983\n",
      "Epoch 10, Batch 5610/5867, Loss: 0.1552\n",
      "Epoch 10, Batch 5620/5867, Loss: 0.0774\n",
      "Epoch 10, Batch 5630/5867, Loss: 0.3152\n",
      "Epoch 10, Batch 5640/5867, Loss: 0.1529\n",
      "Epoch 10, Batch 5650/5867, Loss: 0.1142\n",
      "Epoch 10, Batch 5660/5867, Loss: 0.2983\n",
      "Epoch 10, Batch 5670/5867, Loss: 0.2193\n",
      "Epoch 10, Batch 5680/5867, Loss: 0.2064\n",
      "Epoch 10, Batch 5690/5867, Loss: 0.0924\n",
      "Epoch 10, Batch 5700/5867, Loss: 0.3691\n",
      "Epoch 10, Batch 5710/5867, Loss: 0.1798\n",
      "Epoch 10, Batch 5720/5867, Loss: 0.2514\n",
      "Epoch 10, Batch 5730/5867, Loss: 0.0935\n",
      "Epoch 10, Batch 5740/5867, Loss: 0.2734\n",
      "Epoch 10, Batch 5750/5867, Loss: 0.0704\n",
      "Epoch 10, Batch 5760/5867, Loss: 0.1421\n",
      "Epoch 10, Batch 5770/5867, Loss: 0.2926\n",
      "Epoch 10, Batch 5780/5867, Loss: 0.1232\n",
      "Epoch 10, Batch 5790/5867, Loss: 0.1067\n",
      "Epoch 10, Batch 5800/5867, Loss: 0.1244\n",
      "Epoch 10, Batch 5810/5867, Loss: 0.1915\n",
      "Epoch 10, Batch 5820/5867, Loss: 0.2033\n",
      "Epoch 10, Batch 5830/5867, Loss: 0.1162\n",
      "Epoch 10, Batch 5840/5867, Loss: 0.0976\n",
      "Epoch 10, Batch 5850/5867, Loss: 0.2321\n",
      "Epoch 10, Batch 5860/5867, Loss: 0.1365\n",
      "Epoch 10, Training Loss: 0.1808, Validation Loss: 0.1974\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2657918/344518270.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;31m# Plot Training and Validation Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Dataset Class with BERT Tokenizer\n",
    "class BertTextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, max_len=100):\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.long)  # Target labels\n",
    "        self.texts = [\n",
    "            tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,  # Add [CLS] and [SEP] tokens\n",
    "                max_length=max_len,  # Truncate/pad to max_len\n",
    "                padding=\"max_length\",  # Pad to max length\n",
    "                truncation=True,  # Truncate if longer\n",
    "                return_tensors=\"pt\"  # Return PyTorch tensors\n",
    "            )\n",
    "            for text in texts\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.texts[idx][\"input_ids\"].squeeze(0)  # Token IDs\n",
    "        attention_mask = self.texts[idx][\"attention_mask\"].squeeze(0)  # Attention mask\n",
    "        return input_ids, attention_mask, self.labels[idx]\n",
    "\n",
    "# Load Dataset\n",
    "data = pd.read_csv(\"combined_annotated_data_updated.csv\")\n",
    "data = data.dropna(subset=[\"processed_post\"])  # Drop rows with missing posts\n",
    "X = data[\"processed_post\"]\n",
    "y = data[\"depression_label\"]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = BertTextDataset(X_train, y_train)\n",
    "test_dataset = BertTextDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Define LSTM Model with Pre-Trained BERT Embeddings\n",
    "class BertLSTMClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\", hidden_dim=128, output_dim=2):\n",
    "        super(BertLSTMClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)  # Pre-trained BERT\n",
    "        self.lstm = nn.LSTM(self.bert.config.hidden_size, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)  # Fully connected layer\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # BERT embeddings\n",
    "        with torch.no_grad():  # Freeze BERT parameters to speed up training\n",
    "            bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use the last hidden state as input to LSTM\n",
    "        lstm_input = bert_output.last_hidden_state  # Shape: [batch_size, seq_len, hidden_dim]\n",
    "        _, (hidden, _) = self.lstm(lstm_input)  # LSTM hidden state\n",
    "        out = self.fc(hidden[-1])  # Fully connected layer\n",
    "        return out\n",
    "\n",
    "# Initialize Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertLSTMClassifier().to(device)\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"Training LSTM Model with BERT Embeddings...\")\n",
    "for epoch in range(10):\n",
    "    print(f\"Starting epoch {epoch + 1}...\")\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for batch_idx, (input_ids, attention_mask, labels) in enumerate(train_loader):\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Batch {batch_idx + 1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Average Training Loss\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, labels in test_loader:\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_losses.append(val_loss / len(test_loader))\n",
    "    print(f\"Epoch {epoch + 1}, Training Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e854f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b825c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAGDCAYAAABuj7cYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABTkUlEQVR4nO3deXxU9b3/8dcnOyErCUuGLSAIsiQBERRQwX2B4HrdW7S12rq0drPtbau/2lZvr721Vm1rrdpWq7VWLbivFRU3EIKETZawJSwJkASykOX7++MMIUCABDI5M8n7+XjkkZlzzsx8MgPkzXc15xwiIiIiEh6i/C5ARERERPZSOBMREREJIwpnIiIiImFE4UxEREQkjCiciYiIiIQRhTMRERGRMKJwJtLJmNkrZvbl9r7WT2ZWZGZnhOB5/2NmXw3evsrMXm/NtUfwOgPMbKeZRR9prSLSdSiciYSB4C/uPV+NZlbd7P5VbXku59y5zrm/tPe14cjMfmhmc1o4nmlmu81sVGufyzn3pHPurHaqa58w6Zxb55xLcs41tMfz7/dazsyGtPfztvK1zzazOWZWaWZbzexdM8v3oxaRzkThTCQMBH9xJznnkoB1wPRmx57cc52ZxfhXZVj6GzDRzAbtd/xy4HPn3GIfauoSzOwS4J/AX4F+QG/gp8D0I3guMzP9PhIJ0l8GkTBmZlPMbIOZ3W5mm4DHzCzdzF4MtlRsD97u1+wxzbvqZprZ+2Z2b/DaNWZ27hFeO6hZK8mbZvagmT1xkLpbU+NdZvZB8PleN7PMZuevMbO1ZlZmZv99sPfHObcBeBu4Zr9TXwL+crg69qt5ppm93+z+mWa2zMzKzewBwJqdO8bM3g7WV2pmT5pZWvDc34ABwOxgy+f3zSw72MIVE7wmYGazzGybma00s+ubPfedZvaMmf01+N4Umtm4g70HB2NmqcHn2Bp8L3+8JwCZ2ZBgK1d5sP5/BI+bmf3GzLYEzy2yFlofzcyA/wPucs494pwrd841Oufedc5d3+zneKLZY/Z/D/5jZr8wsw+AKuBHZjZvv9e5zcxmBW/HB/9srjOzzWb2BzPr1tb3RSQSKJyJhL8+QA9gIPA1vL+3jwXvDwCqgQcO8fgJwHIgE/gV8OfgL9e2Xvt34BMgA7iTAwNRc62p8UrgWqAXEAd8F8DMRgC/Dz5/IPh6LQaqoL80r8XMhgF5wFOtrOMAwaD4L+DHeO/FKmBS80uAu4P1HQf0x3tPcM5dw76tn79q4SWeAjYEH38J8EszO73Z+XzgaSANmNWamlvwOyAVGAycihdYrw2euwt4HUjHe29/Fzx+FnAKcGzwtS8Dylp47mF4P/OzR1BXc9fg/ZlODtYwzMyGNjt/Jd6fO4D/CdaVBwwB+uK11Il0OgpnIuGvEbjDOVfrnKt2zpU55/7lnKtyzlUCv8D75Xswa51zfwqOd/oLkIXXBdXqa81sAHAC8FPn3G7n3Pt4oaFFrazxMefcCudcNfAM3i9d8MLKi865Oc65WuAnwffgYJ4P1jgxeP9LwCvOua1H8F7tcR6wxDn3rHOuDrgP2NTs51vpnHsj+JlsxWtFas3zYmb9gcnA7c65GufcQuAR9g277zvnXg5+Dn8Dclvz3M1eIxovWP3QOVfpnCsCft3sNerwAmsgWMP7zY4nA8MBc84tdc6VtPASGcHvLZ1ri8edc4XOuXrnXDnwb+CK4M8wNFjHrOB/EK4HbnPObQt+lr/E674W6XQUzkTC31bnXM2eO2aWaGZ/DHZVVQBzgDQ7+EzA5qGiKngzqY3XBoBtzY4BrD9Ywa2scVOz21XNago0f27n3C5abr1pXuc/gS8Ff4lfhRcsj+S92mP/Glzz+2bWy8yeNrONwed9Aq+FrTX2vJeVzY6txWsJ2mP/9ybB2jbeMBOvNXLtQV7j+3itf58Eu02vA3DOvY3XSvcgsNnMHjazlBaef8/nkdWGmlqy/5+hvxMMZ3itZi8EP9+eQCIw38x2mNkO4NXgcZFOR+FMJPy5/e5/B69baYJzLgWvGwqajYkKgRKgh5klNjvW/xDXH02NJc2fO/iaGQe/HPDC2H8BZ+K1/Lx4lHXsX4Ox7897N97nkhN83qv3e879P7PmivHey+RmxwYAGw9TU1uUsrd17IDXcM5tcs5d75wLADcAD1lwxqdz7n7n3PHASLxuxO+18PzL8YLVxYeoYRdeoNqjTwvX7P8+vQ5kmlkeXkjb06VZitclPdI5lxb8Sg1OoBHpdBTORCJPMt4vqh1m1gO4I9Qv6JxbC8wD7jSzODM7iUPPyjuaGp8FppnZZDOLA37G4f+teg/YATwMPO2c232UdbwEjDSzi4ItVreyb7hIBnYGn7cvBwaYzXhjvQ7gnFsPzAXuNrMEM8sBvgI82dL1rRQXfK4EM0sIHnsG+IWZJZvZQODbeC18mNmltndixHa8kNRgZieY2QQzi8ULVzXAAct/BFsSvw38xMyuNbMUM4sKfmYPBy9bCJxi3hpvqcAPD/dDOOfq8T7//8UbZ/lG8Hgj8CfgN2bWK/gz9DWzs9v2NolEBoUzkchzH9ANrzXhI7zunY5wFXASXpfWz4F/ALUHufY+jrBG51whcBNeq0kJXnjYcJjHOLwlHQYGvx9VHc65UuBS4B68n3co8EGzS/4fMBYoxwtyz+33FHcDPw52wX23hZe4AsjGa0V7Hm9M4Rutqe0gCvFC6J6va4Fb8ALWauB9vPfz0eD1JwAfm9lOvLGD33TOrQFS8ELQdrxu0DLg3pZe0Dn3LN64tuuCP8dmvD8X/w6efwPvz8giYD57WzMP5+/AGcA/g2Ftj9uBlcBHwa7kN/FaRUU6HfP+TRMRaZvg8gvLnHMhb7kTEelK1HImIq0S7PI6Jth9dQ4wA3jB57JERDodrTYuIq3VB6/7LgOvm/HrzrkF/pYkItL5qFtTREREJIyoW1NEREQkjCiciYiIiISRTjXmLDMz02VnZ/tdhoiIiMhhzZ8/v9Q5d8BOF50qnGVnZzNv3jy/yxARERE5LDNb29JxdWuKiIiIhBGFMxEREZEwonAmIiIiEkZCOuYsuIr4b4Fo4BHn3D37nb8Kb7808DYR/rpzriB47jbgq3gb8n4OXOucqwllvSIiIuGsrq6ODRs2UFOjX4eRJCEhgX79+hEbG9uq60MWzswsGngQOBNvNfFPzWyWc25Js8vWAKc657ab2bnAw8AEM+sL3AqMcM5Vm9kzwOXA46GqV0REJNxt2LCB5ORksrOzMTO/y5FWcM5RVlbGhg0bGDRoUKseE8puzfHASufcaufcbuBpvL34mjjn5jrntgfvfgT0a3Y6BuhmZjFAIlAcwlpFRETCXk1NDRkZGQpmEcTMyMjIaFNrZyjDWV9gfbP7G4LHDuYrwCsAzrmNwL3AOqAEKHfOvd7Sg8zsa2Y2z8zmbd26tV0KFxERCVcKZpGnrZ9ZKMNZS5W0uJGnmU3FC2e3B++n47WyDQICQHczu7qlxzrnHnbOjXPOjevZ84B13ERERKSdlJWVkZeXR15eHn369KFv375N93fv3n3Ix86bN49bb731sK8xceLEdqn1P//5D9OmTWuX5+pooZwQsAHo3+x+P1romjSzHOAR4FznXFnw8BnAGufc1uA1zwETgSdCWK+IiIgcQkZGBgsXLgTgzjvvJCkpie9+97tN5+vr64mJaTlajBs3jnHjxh32NebOndsutUayULacfQoMNbNBZhaHN6B/VvMLzGwA8BxwjXNuRbNT64ATzSzRvLbA04GlIaxVREREjsDMmTP59re/zdSpU7n99tv55JNPmDhxImPGjGHixIksX74c2Lcl68477+S6665jypQpDB48mPvvv7/p+ZKSkpqunzJlCpdccgnDhw/nqquuwjmvA+7ll19m+PDhTJ48mVtvvbVNLWRPPfUUo0ePZtSoUdx+u7dgRENDAzNnzmTUqFGMHj2a3/zmNwDcf//9jBgxgpycHC6//PKjf7NaKWQtZ865ejO7GXgNbymNR51zhWZ2Y/D8H4CfAhnAQ8H+2PpgF+XHZvYs8BlQDyzAm8kpIiIiwP+bXciS4op2fc4RgRTumD6yzY9bsWIFb775JtHR0VRUVDBnzhxiYmJ48803+dGPfsS//vWvAx6zbNky3nnnHSorKxk2bBhf//rXD1hqYsGCBRQWFhIIBJg0aRIffPAB48aN44YbbmDOnDkMGjSIK664otV1FhcXc/vttzN//nzS09M566yzeOGFF+jfvz8bN25k8eLFAOzYsQOAe+65hzVr1hAfH990rCOEdBFa59zLzrljnXPHOOd+ETz2h2Awwzn3VedcunMuL/g1rtlj73DODXfOjXLOXeOcqw1lrYfjnGNpSQUL1+/wswwREZGwc+mllxIdHQ1AeXk5l156KaNGjeK2226jsLCwxcecf/75xMfHk5mZSa9evdi8efMB14wfP55+/foRFRVFXl4eRUVFLFu2jMGDBzctS9GWcPbpp58yZcoUevbsSUxMDFdddRVz5sxh8ODBrF69mltuuYVXX32VlJQUAHJycrjqqqt44oknDtpdGwqdauPzULvp75/RKzmep792kt+liIhIF3ckLVyh0r1796bbP/nJT5g6dSrPP/88RUVFTJkypcXHxMfHN92Ojo6mvr6+Vdfs6do8Egd7bHp6OgUFBbz22ms8+OCDPPPMMzz66KO89NJLzJkzh1mzZnHXXXdRWFjYISFN2ze1kpkxPSfAx2u2salcKzOLiIi0pLy8nL59vZWzHn/88XZ//uHDh7N69WqKiooA+Mc//tHqx06YMIF3332X0tJSGhoaeOqppzj11FMpLS2lsbGRiy++mLvuuovPPvuMxsZG1q9fz9SpU/nVr37Fjh072LlzZ7v/PC1ROGuD/LwAzsGLi7QeroiISEu+//3v88Mf/pBJkybR0NDQ7s/frVs3HnroIc455xwmT55M7969SU1NbfHat956i379+jV9FRUVcffddzN16lRyc3MZO3YsM2bMYOPGjUyZMoW8vDxmzpzJ3XffTUNDA1dffTWjR49mzJgx3HbbbaSlpbX7z9MSO5rmwXAzbtw4N2/evJC+xvn3v0dMdBT/vmlSSF9HRERkf0uXLuW4447zuwzf7dy5k6SkJJxz3HTTTQwdOpTbbrvN77IOqaXPzszmNx9vv4daztooPzdAwfodrC3b5XcpIiIiXdKf/vQn8vLyGDlyJOXl5dxwww1+l9SuFM7aaFpuAIDZBeraFBER8cNtt93GwoULWbJkCU8++SSJiYl+l9SuFM7aqG9aN8YNTGeWwpmIiIiEgMLZEcjPC7Bi806WbWrfxf9EREREFM6OwHmjs4iOMmYtVOuZiIiItC+FsyOQmRTPxGMymL2o+KgWwxMRERHZn8LZEcrPDbB+W7W2cxIRkS5jypQpvPbaa/scu++++/jGN75xyMfsWebqvPPOa3GPyjvvvJN77733kK/9wgsvsGTJkqb7P/3pT3nzzTfbUH3Lmm/IHi4Uzo7Q2aP6EBcTpYkBIiLSZVxxxRU8/fTT+xx7+umnW72/5csvv3zEC7nuH85+9rOfccYZZxzRc4U7hbMjlJIQy9RhPXlxUQkNjeraFBGRzu+SSy7hxRdfpLa2FoCioiKKi4uZPHkyX//61xk3bhwjR47kjjvuaPHx2dnZlJaWAvCLX/yCYcOGccYZZ7B8+fKma/70pz9xwgknkJuby8UXX0xVVRVz585l1qxZfO973yMvL49Vq1Yxc+ZMnn32WcDbCWDMmDGMHj2a6667rqm+7Oxs7rjjDsaOHcvo0aNZtmxZq3/Wp556itGjRzNq1Chuv/12ABoaGpg5cyajRo1i9OjR/OY3vwHg/vvvZ8SIEeTk5HD55Ze38V09kDY+PwrTcwO8VriZj1eXMXFIpt/liIhIV/LKD2DT5+37nH1Gw7n3HPR0RkYG48eP59VXX2XGjBk8/fTTXHbZZZgZv/jFL+jRowcNDQ2cfvrpLFq0iJycnBafZ/78+Tz99NMsWLCA+vp6xo4dy/HHHw/ARRddxPXXXw/Aj3/8Y/785z9zyy23kJ+fz7Rp07jkkkv2ea6amhpmzpzJW2+9xbHHHsuXvvQlfv/73/Otb30LgMzMTD777DMeeugh7r33Xh555JHDvg3FxcXcfvvtzJ8/n/T0dM466yxeeOEF+vfvz8aNG1m8eDFAUxftPffcw5o1a4iPj2+x27at1HJ2FE4f3pvucdHq2hQRkS6jeddm8y7NZ555hrFjxzJmzBgKCwv36YLc33vvvceFF15IYmIiKSkp5OfnN51bvHgxJ598MqNHj+bJJ5+ksLDwkPUsX76cQYMGceyxxwLw5S9/mTlz5jSdv+iiiwA4/vjjmzZLP5xPP/2UKVOm0LNnT2JiYrjqqquYM2cOgwcPZvXq1dxyyy28+uqrpKSkAJCTk8NVV13FE088QUzM0bd7qeXsKHSLi+bMEb15ZfEmfjZjFHExyroiItJBDtHCFUoXXHAB3/72t/nss8+orq5m7NixrFmzhnvvvZdPP/2U9PR0Zs6cSU1NzSGfx8xaPD5z5kxeeOEFcnNzefzxx/nPf/5zyOc53KoJ8fHxAERHR1NfX3/Iaw/3nOnp6RQUFPDaa6/x4IMP8swzz/Doo4/y0ksvMWfOHGbNmsVdd91FYWHhUYU0pYmjlJ8XoLy6jjkrtvpdioiISMglJSUxZcoUrrvuuqZWs4qKCrp3705qaiqbN2/mlVdeOeRznHLKKTz//PNUV1dTWVnJ7Nmzm85VVlaSlZVFXV0dTz75ZNPx5ORkKisrD3iu4cOHU1RUxMqVKwH429/+xqmnnnpUP+OECRN49913KS0tpaGhgaeeeopTTz2V0tJSGhsbufjii7nrrrv47LPPaGxsZP369UydOpVf/epX7Nixg507dx7V66vl7ChNHtKTtMRYZhUUc8aI3n6XIyIiEnJXXHEFF110UVP3Zm5uLmPGjGHkyJEMHjyYSZMmHfLxY8eO5bLLLiMvL4+BAwdy8sknN5276667mDBhAgMHDmT06NFNgezyyy/n+uuv5/7772+aCACQkJDAY489xqWXXkp9fT0nnHACN954Y5t+nrfeeot+/fo13f/nP//J3XffzdSpU3HOcd555zFjxgwKCgq49tpraWxsBODuu++moaGBq6++mvLycpxz3HbbbUc8I3UP60yLqI4bN87tWUulI/3wuc95YcFG5v/kDBLjlHdFRCQ0li5dynHHHed3GXIEWvrszGy+c27c/teqW7Md5OcGqK5r4K2lW/wuRURERCKcwlk7GD+oB71T4jVrU0RERI6awlk7iI4yzh8d4N3lWymvrvO7HBEREYlgCmftJD8vwO6GRl5bvMnvUkREpBPrTGPFu4q2fmYKZ+0kt18qAzMS1bUpIiIhk5CQQFlZmQJaBHHOUVZWRkJCQqsfo6mF7cTMmJ4T4KH/rGRLZQ29klv/IYiIiLRGv3792LBhA1u3am3NSJKQkLDPUh2Ho3DWjvLzAjzwzkpeXlTCzEmD/C5HREQ6mdjYWAYN0u+Xzk7dmu3o2N7JDO+TzOxFJX6XIiIiIhFK4aydTc8NMH/tdjZsr/K7FBEREYlACmftLD83AMDsArWeiYiISNspnLWz/j0SyeufplmbIiIickQUzkIgPzfA0pIKVm6p9LsUERERiTAKZyEwLSeLKINZC9V6JiIiIm2jcBYCvVISOHFwBrMKirVQoIiIiLSJwlmI5OcGKCqrYvHGCr9LERERkQiicBYi547KIjbamFWw0e9SREREJIIonIVIamIspx7bkxcXldDYqK5NERERaR2FsxCanhugpLyGT4u2+V2KiIiIRAiFsxA647jeJMRGac0zERERaTWFsxDqHh/DGcf15uXPS6hraPS7HBEREYkACmchlp8bYHtVHe+vLPW7FBEREYkACmchduqwnqQkxDBbC9KKiIhIKyichVh8TDTnjOrD60s2U1PX4Hc5IiIiEuYUzjpAfm5fdtbW886yLX6XIiIiImFO4awDnHRMBplJ8Zq1KSIiIoelcNYBoqOMaTlZvLVsC5U1dX6XIyIiImFM4ayDTM/NYnd9I68Xbva7FBEREQljCmcdZOyAdPqmdVPXpoiIiBySwlkHMTOm5wZ4f2UpZTtr/S5HREREwpTCWQfKzw3Q0Oh4efEmv0sRERGRMKVw1oGOy0pmSK8kZqtrU0RERA5C4awDmRn5uQE+LdpGSXm13+WIiIhIGFI462DTcwM4By8WlPhdioiIiIShkIYzMzvHzJab2Uoz+0EL568ys0XBr7lmltvsXJqZPWtmy8xsqZmdFMpaO8qgzO6M7puqWZsiIiLSopCFMzOLBh4EzgVGAFeY2Yj9LlsDnOqcywHuAh5udu63wKvOueFALrA0VLV2tPzcAJ9vLGdN6S6/SxEREZEwE8qWs/HASufcaufcbuBpYEbzC5xzc51z24N3PwL6AZhZCnAK8OfgdbudcztCWGuHmpabhRnMWqjWMxEREdlXKMNZX2B9s/sbgscO5ivAK8Hbg4GtwGNmtsDMHjGz7i09yMy+ZmbzzGze1q1b26PukMtK7cYJ2T2YVbAR55zf5YiIiEgYCWU4sxaOtZhEzGwqXji7PXgoBhgL/N45NwbYBRwwZg3AOfewc26cc25cz549j77qDpKfG2DV1l0sLan0uxQREREJI6EMZxuA/s3u9wMO6MczsxzgEWCGc66s2WM3OOc+Dt5/Fi+sdRrnjc4iJso0MUBERET2Ecpw9ikw1MwGmVkccDkwq/kFZjYAeA64xjm3Ys9x59wmYL2ZDQseOh1YEsJaO1yP7nFMHprJ7IJidW2KiIhIk5CFM+dcPXAz8BreTMtnnHOFZnajmd0YvOynQAbwkJktNLN5zZ7iFuBJM1sE5AG/DFWtfsnPDbBxRzWfrdt++ItFRESkS4gJ5ZM7514GXt7v2B+a3f4q8NWDPHYhMC6U9fntzBG9iY+JYtbCYo4f2MPvckRERCQMaIcAHyUnxHLa8F689HkJ9Q2NfpcjIiIiYUDhzGf5uQFKd+7mw9Vlh79YREREOj2FM59NHd6LpPgYLUgrIiIigMKZ7xJiozlrZG9eLdxEbX2D3+WIiIiIzxTOwkB+boDKmnreXR4ZOxyIiIhI6CichYFJQzLp0T1OC9KKiIiIwlk4iI2O4rzRfXhz6WZ21db7XY6IiIj4SOEsTEzPCVBT18ibSzf7XYqIiIj4SOEsTJyQ3YOs1ATN2hQREeniFM7CRFSUMS0nizlfbGVH1W6/yxERERGfKJyFkfzcvtQ1OF5ZvMnvUkRERMQnCmdhZFTfFAZldme2Zm2KiIh0WQpnYcTMmJ4b4MPVZWypqPG7HBEREfGBwlmYyc8N4By8uKjE71JERETEBwpnYWZIryRGZKVoQVoREZEuSuEsDE3PDbBw/Q7WlVX5XYqIiIh0MIWzMDQ9NwuA2YvUeiYiItLVKJyFoX7piRw/MF0L0oqIiHRBCmdhKj83wPLNlSzfVOl3KSIiItKBFM7C1Hmjs4gytOaZiIhIF6NwFqZ6JsczaUgmswqKcc75XY6IiIh0EIWzMDY9N8C6bVUUbCj3uxQRERHpIApnYezskX2Ii47SxAAREZEuROEsjKV2i+XUYT15cVExDY3q2hQREekKFM7CXH5ugC2VtXy8pszvUkRERKQDKJyFuTOO601iXLRmbYqIiHQRCmdhrltcNGeO6M0rizexu77R73JEREQkxBTOIkB+boAdVXW8v3Kr36WIiIhIiCmcRYCTh/YktVusZm2KiIh0AQpnESAuJorzRvfh9SWbqd7d4Hc5IiIiEkIKZxFiek6Aqt0NvLVss9+liIiISAgpnEWICYMz6JUcr65NERGRTk7hLEJERxnn52Txn+VbKa+u87scERERCRGFswiSnxtgd0MjrxVu8rsUERERCRGFswiS1z+NAT0StSCtiIhIJ6ZwFkHMjOm5WcxdVUbpzlq/yxEREZEQUDiLMPm5fWlodLz8eYnfpYiIiEgIKJxFmGF9khnWO1mzNkVERDophbMIND03i3lrt7NxR7XfpYiIiEg7UziLQNNzAwCaGCAiItIJKZxFoIEZ3cntn6auTRERkU5I4SxC5ecGWFJSwcotO/0uRURERNqRwlmEmpaThZm6NkVERDobhbMI1TslgRMHZTC7oBjnnN/liIiISDtROItg+XkBVpfuorC4wu9SREREpJ0onEWwc0f1ISbKmKWuTRERkU5D4SyCpSXGccqxPZldUExjo7o2RUREOgOFswiXnxugpLyGeWu3+12KiIiItAOFswh35ojeJMRGMatgo9+liIiISDtQOItw3eNjOP243rz8+SbqGxr9LkdERESOksJZJ5CfG2Dbrt18sKrM71JERETkKCmcdQJThvUkOSFG2zmJiIh0AiENZ2Z2jpktN7OVZvaDFs5fZWaLgl9zzSx3v/PRZrbAzF4MZZ2RLj4mmnNG9uH1wk3U1DX4XY6IiIgchZCFMzOLBh4EzgVGAFeY2Yj9LlsDnOqcywHuAh7e7/w3gaWhqrEzyc8LUFlbz3+Wb/G7FBERETkKoWw5Gw+sdM6tds7tBp4GZjS/wDk31zm3Zw2Ij4B+e86ZWT/gfOCRENbYaZw0OIPMpDgtSCsiIhLhQhnO+gLrm93fEDx2MF8BXml2/z7g+8AhpyCa2dfMbJ6Zzdu6desRlhr5YqKjOG90Fm8t3UJlTZ3f5YiIiMgRCmU4sxaOtbiMvZlNxQtntwfvTwO2OOfmH+5FnHMPO+fGOefG9ezZ82jqjXj5uQFq6xt5Y8lmv0sRERGRIxTKcLYB6N/sfj/ggD43M8vB67qc4ZzbsxbEJCDfzIrwukNPM7MnQlhrpzB2QDp907oxW12bIiIiESuU4exTYKiZDTKzOOByYFbzC8xsAPAccI1zbsWe4865Hzrn+jnnsoOPe9s5d3UIa+0UoqKMablZvPdFKdt37fa7HBERETkCIQtnzrl64GbgNbwZl8845wrN7EYzuzF42U+BDOAhM1toZvNCVU9XkZ8boL7R8fLiEr9LERERkSNgzrU4DCwijRs3zs2b17XznXOOM/7vXTKT4vnHDSf5XY6IiIgchJnNd86N2/+4dgjoZMyM/Ny+fFK0jU3lNX6XIyIiIm2kcNYJTc/Nwjl4cZEmBoiIiEQahbNOaHDPJEb1TdGCtCIiIhFI4ayTys8NsGhDOWtKd/ldioiIiLSBwlknNS0nAMCLaj0TERGJKApnnVQgrRvjs3swq6CYzjQjV0REpLNTOOvEpucF+GLLTpZtqvS7FBEREWklhbNO7LxRfYiOMk0MEBERiSAKZ51YRlI8k4ZkMltdmyIiIhFD4ayTy88NsGF7NZ+t2+F3KSIiItIKCmed3NkjexMXE8VsdW2KiIhEBIWzTi45IZbThvXixUUlNDSqa1NERCTcKZx1Afl5AUp31vLR6jK/SxEREZHDUDjrAk4b3ouk+BhmLVTXpoiISLhTOOsCEmKjOWtEb15ZXEJtfYPf5YiIiMghKJx1EdPzAlTU1DNnRanfpYiIiMghKJx1EZOHZJKeGKsFaUVERMKcwlkXERsdxbmjs3hzyWaqdtf7XY6IiIgcRKvCmZl1N7Oo4O1jzSzfzGJDW5q0t/zcANV1DbyxZLPfpYiIiMhBtLblbA6QYGZ9gbeAa4HHQ1WUhMb47B70SUlgdkGJ36WIiIjIQbQ2nJlzrgq4CPidc+5CYEToypJQiIoypuVk8e6KLZRX1fldjoiIiLSg1eHMzE4CrgJeCh6LCU1JEkr5eQHqGhyvFqr1TEREJBy1Npx9C/gh8LxzrtDMBgPvhKwqCZnRfVPJzkjUrE0REZEw1apw5px71zmX75z7n+DEgFLn3K0hrk1CwMzIzw3w4aoytlTW+F2OiIiI7Ke1szX/bmYpZtYdWAIsN7PvhbY0CZXpuQEaHby0SF2bIiIi4aa13ZojnHMVwAXAy8AA4JpQFSWhNbR3MsP7JKtrU0REJAy1NpzFBtc1uwD4t3OuDnAhqypcOQcNnWOWY35egAXrdrB+W5XfpYiIiEgzrQ1nfwSKgO7AHDMbCFSEqqiw1FAPT10Or/2335W0i+k5AQBmL1LrmYiISDhp7YSA+51zfZ1z5znPWmBqiGsLL9ExkJ4Nn/wRVr3tdzVHrX+PRMYOSGPWQoUzERGRcNLaCQGpZvZ/ZjYv+PVrvFa0ruWMOyHzWHjhJqje7nc1Ry0/N8CyTZV8sbnS71JEREQkqLXdmo8ClcB/Bb8qgMdCVVTYiu0GF/4Rdm2BlyN/sur5OQGiDE0MEBERCSOtDWfHOOfucM6tDn79P2BwKAsLW33Hwinfh8//CYuf87uao9IzOZ6Jx2Qyq6AY57re/A4REZFw1NpwVm1mk/fcMbNJQHVoSooAJ38H+h4PL94GFZG9Vtj03CzWllWxaEO536WIiIgIrQ9nNwIPmlmRmRUBDwA3hKyqcBcdAxc+DPW18O+bvCU2ItQ5I7OIjTZ1bYqIiISJ1s7WLHDO5QI5QI5zbgxwWkgrC3eZQ+Csu2DVWzDvz35Xc8RSE2M59dhevLiomMbGyA2ZIiIinUVrW84AcM5VBHcKAPh2COqJLCd8FY45DV7/CZSt8ruaI5afF2BzRS2fFG3zuxQREZEur03hbD/WblVEKjOY8SBEx8FzX/MWqo1AZxzXi26x0eraFBERCQNHE87UBwaQEoDzfw0b58H7v/G7miOSGBfDmSN688rnJdQ1NPpdjoiISJd2yHBmZpVmVtHCVyUQ6KAaw9/oS2DUxfDuPVC8wO9qjkh+boDtVXW8/0Wp36WIiIh0aYcMZ865ZOdcSgtfyc65mI4qMiKcdy907wnP3QB1kbfKyCnH9iQlIUZdmyIiIj47mm5NaS6xhzf+rHQ5vPUzv6tps7iYKM4dlcVrhZtYtGGH3+WIiIh0WQpn7WnI6XDC9fDRQ7D6Xb+rabOvTzmG9MQ4LvnDh/xr/ga/yxEREemSFM7a25k/g4wh8MI3oHqH39W0SXZmd2bfMpnjB6TznX8W8LPZS6jXBAEREZEOpXDW3uISvd0DKkvgldv9rqbNenSP469fGc+1k7J59IM1fOnRT9i+a7ffZYmIiHQZCmeh0O94OOW7sOhpWPJvv6tps9joKO6YPpL/vSSHeWu3M/2B91laUnH4B4qIiMhRUzgLlVO+B1l5MPtbULnJ72qOyKXj+vPMDSdR19DIRQ/N5aVFkb3Ju4iISCRQOAuV6Fi46GGoq4JZt0Ts5uh5/dOYffNkjstK5qa/f8b/vraMBu3BKSIiEjIKZ6HUcxiccSd88TrMf9zvao5Yr5QEnvraiVwxvj8PvrOK6/86j4qaOr/LEhER6ZQUzkJt/A0w6FR47b9h22q/qzli8THR/PLC0dx1wSjmrNjKBQ98wMotO/0uS0REpNNROAu1qCi44CGIioHnb4TGBr8rOmJmxjUnDuTJr06gvLqOCx78gDeXbPa7LBERkU5F4awjpPaD8/4X1n8MH9zndzVHbcLgDGbfMpnszESu/9s8fvfWFzRqHJqIiEi7UDjrKDn/BSNmwDt3Q8kiv6s5aoG0bjx740Rm5Ab49Rsr+MaTn7Grtt7vskRERCJeSMOZmZ1jZsvNbKWZ/aCF81eZ2aLg11wzyw0e729m75jZUjMrNLNvhrLODmEG0+7z9uB87mtQV+N3RUctITaa31yWx4/PP47Xl2zioofmsrZsl99liYiIRLSQhTMziwYeBM4FRgBXmNmI/S5bA5zqnMsB7gIeDh6vB77jnDsOOBG4qYXHRp49m6NvXQpv3+V3Ne3CzPjqyYP563UT2FRRQ/4DH/DeF1v9LktERCRihbLlbDyw0jm32jm3G3gamNH8AufcXOfc9uDdj4B+weMlzrnPgrcrgaVA3xDW2nGGngnHXwsfPghF7/tdTbuZPDST2TdPpk9KAl9+9BP+NGc1LkLXdhMREfFTKMNZX2B9s/sbOHTA+grwyv4HzSwbGAN83NKDzOxrZjbPzOZt3RohLTZn/RzSs+H5r0NN59kWaUBGIs99YyJnj+zDL15eyrefKaCmLnJnp4qIiPghlOHMWjjWYlOKmU3FC2e373c8CfgX8C3nXIspxjn3sHNunHNuXM+ePY+y5A4Sn+TtHlCxAV79od/VtKvu8TE8dNVYvnvWsbywcCOX/GEuG3dU+12WiIhIxAhlONsA9G92vx9QvP9FZpYDPALMcM6VNTseixfMnnTOPRfCOv3RfzxMvg0WPgHLXvK7mnZlZtx82lD+dM04ikqryP/d+3y8uuzwDxQREZGQhrNPgaFmNsjM4oDLgVnNLzCzAcBzwDXOuRXNjhvwZ2Cpc+7/Qlijv079AfTJgVm3ws4I6ZJtgzNG9OaFmyaR2i2Wqx75mL99WKRxaCIiIocRsnDmnKsHbgZewxvQ/4xzrtDMbjSzG4OX/RTIAB4ys4VmNi94fBJwDXBa8PhCMzsvVLX6JibO696srYTZt0bs5uiHMqRXEs/fNImTh2byk38X8sPnPqe2XuPQREREDsY6U0vGuHHj3Lx58w5/YbiZ+wC8/t+Q/wCMvcbvakKiodHxf28s58F3VjF2QBp/uPp4eqUk+F2WiIiIb8xsvnNu3P7HtUNAODjxG5B9Mrz6A9he5Hc1IREdZXzv7OE8eOVYlpZUMv2B91mwbvvhHygiItLFKJyFgz2bo1uUt7xGBG+Ofjjn52Tx3DcmEhcTxWV//Ih/zlt/+AeJiIh0IQpn4SJtAJz7P7BuLnz4gN/VhNRxWSnMumkyJwxK53vPLuLOWYXUNTT6XZaIiEhYUDgLJ7lXwPBp8PbPYdNiv6sJqfTucfzl2vF8ZfIgHp9bxJf+/Anbdu32uywRERHfKZyFEzOY/ltISIPnb4D6Wr8rCqmY6Ch+Mm0Ev740l/nrtjP9d+9TWFzud1kiIiK+UjgLN90zIf93sHkxvPNLv6vpEBcf349nbzyJRue4+PdzmVVwwFrFIiIiXYbCWTgadg6M/RJ88FtY+6Hf1XSInH5pzLp5MqMCqdz61ALufmUpDY2dZ5kXERGR1lI4C1dn/9KbJPD8Dd4itV1Az+R4/n79iVw5YQB/fHc11z3+KeVVdX6XJSIi0qEUzsJVfDJc+EfYsQ5e+5Hf1XSYuJgofnnhaH5x4SjmriplxoPv88XmrhFORUREQOEsvA08CSZ9Ez77Kyx/xe9qOtRVEwby9+tPZGdtAxc8+AGvF27yuyQREZEOoXAW7qb+CHqPglm3wK5Sv6vpUCdk92D2LZM4plcSX/vbfO57cwWNGocmIiKdnMJZuIuJ9zZHrymH2d/slJujH0pWajeeueEkLhrTl/ve/IIbn5jPztp6v8sSEREJGYWzSNB7JJz2Y1j2IhQ85Xc1HS4hNppf/1cuP502greWbeHCBz+gqHSX32WJiIiEhMJZpDjpZhgwEV7+vjdJoIsxM66bPIi/XjeerTtryX/gff6zfIvfZYmIiLQ7hbNIERUNF/4ecPDCN6Cxa+5FOWlIJrNvnkwgrRvXPf4pf3h3Fa6LdfWKiEjnpnAWSdKz4Zx7oOg9+Oghv6vxTf8eiTz3jYmcOyqLe15ZxjefXkj17ga/yxIREWkXCmeRZszVMOw8eOtnsGWp39X4JjEuhgeuHMP3zh7G7EXFXPz7uWzYXuV3WSIiIkdN4SzSmMH0+71Fap+7Hup3+12Rb8yMm6YO4c9fHsf6bVXkP/ABH64q87ssERGRo6JwFomSekL+/bDpc3j3Hr+r8d1pw3vzws2TSE+M5eo/f8xf5hZpHJqIiEQshbNINfx8yLsa3v8NrPvY72p8d0zPJJ6/aRJTh/XkjlmF3P6vRdTWaxyaiIhEHoWzSHbO3ZDSL7g5+k6/q/FdSkIsD18zjltOG8Iz8zZw2R8/YnNFjd9liYiItInCWSRLSPGW19heBK//2O9qwkJUlPGds4bx+6vGsmJzJdN+9z7z1273uywREZFWUziLdNmT4aSbYP5jsOJ1v6sJG+eOzuK5b0ykW2w0Vzz8Ef/4tOst3CsiIpFJ4awzOO0n0GsEzLoZdmm24h7D+6Qw6+ZJTBjcg9v/9Tk/eWExdQ1dc/FeERGJHApnnUFsAlz4R6jaBi/d1uU2Rz+UtMQ4Hpt5AtefPIi/fbSWqx75WPtyiohIWFM46yyycmDqD2HJv2HRM35XE1ZioqP47/NHcN9leRSs38HUX/+H6x7/lPe+2KolN0REJOxYZ/rlNG7cODdv3jy/y/BPYwM8di5sWQbfmAup/fyuKOxsqajhiY/X8feP11K6czdDeiXx5YnZXDSmL93jY/wuT0REuhAzm++cG3fAcYWzTmbbavj9ZOg3Dq55AaLUONqS2voGXlpUwmMfFPH5xnKSE2K4bFx/vnRSNgMyEv0uT0REugCFs65k3mPw4rfgnP+BE2/0u5qw5pzjs3XbeeyDIl5ZvIlG5zh9eG+um5TNScdkYGZ+lygiIp3UwcKZ+nE6o+NnwvJX4M074Jip0HOY3xWFLTPj+IE9OH5gD0rKq3nyo3X8/ZN1vLl0M8f2TmLmxEFcOKYv3eKi/S5VRES6CLWcdVaVm+GhEyFtAHz1TYiO9buiiFFT18DsgmIe+6CIJSUVpHaL5fIT+nPNSQPpl64uTxERaR/q1uyKlvwbnvkSnHo7TP2R39VEHOccnxZt5/G5a3itcDPOOc4c0ZtrJw1iwqAe6vIUEZGjom7NrmjEDMi5HObcC0PPhn7H+11RRDEzxg/qwfhBPdi4o5onPlrLU5+s47XCzQzvk8y1k7KZkdeXhFh1eYqISPtRy1lnV1MOD030Fqq94T2IU7fc0aipa+DfCzfy2AdFLNtUSVpiLFeMH8A1Jw4kkNbN7/JERCSCqFuzK1v9Lvw1H064Hs6/1+9qOgXnHB+t3sbjc9fwxpLNmBlnj/S6PMcNTFeXp4iIHJa6NbuywafCid+Ajx6CYefCkNP9rijimRknHZPBScdksH5bVVOX58ufb2JkIIWZE7OZnhtQl6eIiLSZWs66irpq+OOpUFsBX58LiT38rqjTqdpdzwsLinl87hpWbN5Jj+5xXDl+AFefOJA+qQl+lyciImFG3ZoCxQvhkdO9iQKXPOp3NZ2Wc465q8p47IMi3lq2mWgzzhnVh2snDWLsgDR1eYqICKBuTQEI5MGpP4B3fg7DzoPRl/hdUadkZkwaksmkIZmsK6virx8W8Y9563lxUQk5/VKZOTGb83OyiI9Rl6eIiBxILWddTUM9PHYOlK6Ab3wEKQG/K+oSdtXW89xnG3hsbhGrt+4iMymOKycM5OoJA+iVoi5PEZGuSN2aslfZKvjDZBhwIlz9HKibrcM0NjreX1nK43OLeHvZFmKjjfNHZzFz0iDy+qf5XZ6IiHQghTPZ16ePwEvfgfPuhfHX+11Nl7SmdBd/mVvEs/M3sLO2nrz+aVw7KZtzR2URFxPld3kiIhJiCmeyL+fgyUug6AO48T3IHOp3RV1WZU0d/5q/gb98uJY1pbvomRzP1RMGcuWEAfRMjve7PBERCRGFMzlQRQn8/iToMRiuex2iNT/ET42Njne/2MrjHxTx7oqtxEVHMS03i2snDmJ0v1S/yxMRkXamcCYtW/wcPHstTPkRTLnd72okaNXWnU1dnlW7Gzh+YDozJ2Zzzqg+xEary1NEpDNQOJOD+9dXvZD21Teh71i/q5FmKmrq+Oe8DfxlbhHrtlXROyWea04cyBXjB5CRpC5PEZFIpnAmB1e93dscPT4JbpgDsdrAO9w0NDr+s3wLj88t4r0vSomLiWJGboAvT8xmVF91eYqIRCKFMzm0Ve/A3y6AMVd7G6SnBCAxE6LUhRZuvthcyeNzi3jus41U1zUwPrsHMydlc9aI3sSoy1NEJGIonMnhvfID+Pj3e+9HxUBSH0jJguQ+kBwI3g5+pQS84/HJ/tXchZVX1fHMvPX85cMiNmyvJpCawNUnDeTyEwbQo3uc3+WJiMhhKJzJ4TkHJQuhfIM3k7My+FVRDJWbvNu1FQc+Li758AEuqTdEx3b4j9QVNDQ63lq6mcfnFjF3VRkxUcbkoZlMywlw1sjepCTofRcRCUcKZ9I+ancGg1rxwQNcZQk01u/3QIOkXgcJcM1ud0vXjgVHYfmmSp5bsIEXC0rYuKOauOgopgzrybTcAGcc14vEOC2XIiISLhTOpOM0NkJV2aEDXEUxVG878LExCYcPcMlZEKv9KA/FOceC9TuYXVDMS4tK2FJZS7fYaE4/rhfTcgJMGdaThFhtvC4i4idfwpmZnQP8FogGHnHO3bPf+auAPYtr7QS+7pwraM1jW6JwFmHqamDnpkMHuMoSqK858LHd0psFuIN0p2pCA+B1e35atI3ZBcW8sngT23btJik+hrNG9mZ6ToDJQzO1dpqIiA86PJyZWTSwAjgT2AB8ClzhnFvS7JqJwFLn3HYzOxe40zk3oTWPbYnCWSfkHNTs2C/AtRDmdm4G9vuz3OKEhgD0GQ39xkFC11uCor6hkbmryphdUMyrhZuorKknLTGWc0f1YVpOgBMHZxAdpW5lEZGO4Ec4OwkvbJ0dvP9DAOfc3Qe5Ph1Y7Jzr29bH7qFw1oU11HsB7XDj4ZomNBj0Hgn9x0P/Cd739EFdarxbbX0D760oZfaiYt5Yspmq3Q1kJsVz3ug+TM8NcPyAdKIU1EREQuZg4SyUo4P7Auub3d8ATDjE9V8BXmnrY83sa8DXAAYMGHCktUqki46B1L7eF8cf/LrqHVC8ANZ/Aus/gs+fhXmPeue692oW1iZAVm6nHtsWHxPNGSN6c8aI3lTvbuCd5VuYXVDMPz5dz18/XEtWagLTcrKYlhMgp18q1oWCq4iIn0IZzlr6l7zFZjozm4oXzia39bHOuYeBh8FrOWt7mdKldEuDY6Z6XwCNDbB1Gaz/2Ats6z6CZS9656LjICvPC2wDToR+4yG5t1+Vh1S3uGjOG53FeaOz2Flbz5tLNjO7oJjH5xbxp/fWMKBHItNzvaA2vE+ygpqISAiFMpxtAPo3u98PKN7/IjPLAR4BznXOlbXlsSJHLSra697sPRLGXecd27kl2LIWDGyf/Ak+fMA7l569txu0/4nQ6zjvOTqRpPgYLhjTlwvG9KW8qo7XCjcxe1Exf3h3NQ++s4ohvZKYlpPF9NwAx/RM8rtcEZFOJ5RjzmLwBvWfDmzEG9R/pXOusNk1A4C3gS855+a25bEt0ZgzCYn6WigpCIa1j2Hdx7Bri3cuLtmbXLAnsHXiiQalO2t5ZfEmZhcU82nRNpyDEVkpTMvNYnpOgP49Ev0uUUQkovi1lMZ5wH14y2E86pz7hZndCOCc+4OZPQJcDKwNPqR+T5EtPfZwr6dwJh3COdix1gtpe1rXthSCa6SrTDTYVF7DS5+XMLugmIXrdwCQ1z+taYxan9TOO1ZPRKS9aBFakVCqqYCN8/e2rm2Yt3dmaPeeeycZdMKJBuu3VfHiIi+oLSmpwAxOyO7B9Jwszh2dRWZSvN8lioiEJYUzkY7U0kSD7Wu8c514osGqrTt5saCE2YuKWbllJ1EGk4ZkMi0ni3NGZpGaqH0+RUT2UDgT8dv+Ew2KF0BDrXdun4kGE6DXiIieaOCcY/nmSmYXFPPiohLWllURG22cMrQn03KzOHNEH5Litc+niIShDfNh5Rsw5QchfymFM5Fw00UmGjjn+HxjeVNQKymvIT4mitOGe/t8nja8F93iIjeIikgnsbsK/vNL+PBBbxvAG9+HxB4hfUmFM5Fwd7iJBr1GwIAJET3RoLHR8dm67d6G7J9vonRnLYlx0Zw5ojfTcgKccmwm8TEKaiLSwYo+gFk3w7bVcPxMOPNnHfIfYoUzkUjUNNEguKNBJ5po0NDo+Hh1GbMXeRuy76iqIzkhhnNG9mFaboCJx2RoQ3YRCa3aSnjjDpj3Z0gbCPm/g8GndtjLK5yJdAatmWgweArkXg4Zx/hZaZvUNTTy/spSZhcU80bhZipr6+nRPa5pQ/bxg3poQ3YRaV8r34TZ34LyDXDi1+G0H0Nc9w4tQeFMpLPaZ6JBMLThvNa03Ctg5IXetlURoqaugXdXbGV2QTFvLd1CdV0DvZLjOT+4htrYAWnaPkpEjlzVNnjtv6Hg75B5LMx40Bsq4gOFM5GuoqIYFv0DFj4FpcshJgGGnw+5V3p7ikbQLNCq3fW8tdTbkP0/K7ayu76RPikJjBmQxqi+qYwMpDCqb6rWUhOR1lk6G176DuwqhcnfglO+7+twEIUzka7GOSj+zAtpi5+F6u2Q1Ady/gvyrvT2BY0gFTV1vFG4mbeXbWFxcTlry6qazvVJSWBU3xRGBlIZ1TeVUX1T6JOSoBY2EfHs3AIvfw+WvAB9RnutZVm5flelcCbSpdXXworXYOHfvfV7Guu98Wl5V8KoS6B7ht8Vtll5dR1LiisoLC5n8cZyFhdXsGrrTvb8k9aje1xTy9qogBfYBvRIVGAT6Uqcg0XPwKu3w+5dcOr3YdK3IDo8FsRWOBMRz86t8Pk/vfEWmz6HqFg49mxvfNrQsyAmzu8Kj1jV7nqWllTuDWwbK1ixuZL6Ru/fueSEGC+wNWthG5SZpMkGIp1R+UZ48Tb44jXodwLkPwC9hvtd1T4UzkTkQJsWQ8FT3v8sd22BxAyvJS3vCq9lrRO0MtXWN7Bi004WN2thW1pSwe76RgC6xUYzIpDCqEAKI4Pj2Ib2SiYuRst4iEQk5+Czv8DrP4GGOjj9pzDhhrAcb6twJiIH11APq97yuj2XvwwNu6HncV63Z85/QXIfvytsV3UNjazaupPCjRUsLi6ncKPXPbprdwMAcdFRDOuTvM84tuF9kkmIDb9/3EWkmW1rYPatsGYOZJ8M+fdDj8F+V3VQCmci0jrV22Hxc16L2oZPwaLgmNO91rRh50fUQrdt0djoKCrbxeLiCgo3lgdb2ioor64DIDrKGNorKRjWvLFsx2WlaI9QkXDQ2AAf/xHevgssGs66C8Z+GaLCuwVc4UxE2q70Cy+kFfwDKjZAfCqMutBblqP/+E7R7Xkozjk2bK8OjmHzWtc+31hB6U5vw3ozGJTZnVGBvct6jAykkJZ4FOP2dpV569KFYReMSFjauhz+fTNs+MQbNzvtN5Daz++qWkXhTESOXGMjFM3xluVYOgvqqqDHMd4kgtzLIG2A3xV2qC0VNU0ta4s3llNYXMHGHdVN5/uld2uaIToyOFu0Z3ILa7Ht3AolC6F4wd6vypLgkieXeu9v75Ed94OJRJKGOvjgt/Du/3gr+5/zP94wjAj6T6PCmYi0j9pKWDLLa1Eres87ln2yNz7tuHyIT/K3Pp9s27W7qYVtcXE5S4orWFO6q+n80OTdnNtjE+Pj1zG04QsyKpYQU7kxeNYgcygExngb3K//xJth1ljvrcmUe4U3USO5tz8/nEi4KVkE/74JNi2CETPgvHshqZffVbWZwpmItL/ta6HgaS+obV8Dsd1hRL4XJrJPDvvxHiFTvQNKCqhZN49da+YRu6WAlOqNTadXN/bhczeYlTFDqc4cTeLAsRw7IItRgVQG9EgkKsq87s3F//Le2+LPvHE0Q0739k0ddh7EdvPv5xPxS30tvPsr+OA+6NYDzv+1929OhFI4E5HQcc7bhL3g71D4AtRWQGp/yLnMa1GLoE3Y26y2EkoKmnVNLoRtq/aeTxvotYgFv6ozR7N0h3mTDoKtbCs2V1LXEFyLLT6G0f1SGTMgjTH908kbkEZmdZEXghf9Ayo2QnwKjLzAC8H9T+y6IVi6lvWfeq1lpcu9P/tn/xISe/hd1VFROBORjlFXDcte8pblWP0OuMaI3YT9ALt3eQv3Nh8jVvoFEPx3NLU/BPK8IJYV/N6KXx676xtZsbkyOOGgnIL15SwtqWhaPLd/j25eUOuXwsmxyxhcPJvoZbNh905vvF/O5V6LWmcOwdJ17d4Fb/8cPvo9pPSF6ffB0DP9rqpdKJyJSMerKPFaewqegq3LIDre24Q970oYPBWiw3gZirpqb5He4gV7B+1vXeaFTYDkrH1axMjKg6Se7fby1bsbWFxczoJ121m4fgcL1u2gpLwG8NZhG5MVx2VJBUyuepOeW+ZiOOg33gtpIy+M+BYFEcBbr2zWLbC9CMZ9Bc64ExJS/K6q3SiciYh/nPPCTcFT3tZR1dshqbc3syr3Sug9wt/66mthc+G+XZNbloDzFqWle08IjA0GsTwviKVkdXiZm8prWLh+OwvW7WDB+h0s2rCDmrpGerONKxM/5pLo9+hbV0RjVBwNQ88mdsyVMOSMiN6SS7qomgp446cw/zFIHwQzHoDsyX5X1e4UzkQkPNTv9mYiLnxq74zErFwvpI2+NPSbsDfUecGreOHeMLa5EBq9xWbp1mPfFrHAGEgJhOX0/PqGRpZtqmxqWVuwbhvdypZwUfR7zIj+gEyrYGd0KsX9zifu+KvoP3Ii0dEanyZhbsXr8OK3vGVlTvwGTP1viEv0u6qQUDgTkfCzqxQ+f9abSFBSAFExMPRsbzeCoWcffYtPQ703eLj5GLFNi6HBW0SWhNR9x4cFxnhjuMIwiLVWeVUdCzfsoKBoKw1fvMWIrS8xxc0j3upY5frySerZlA+5gGOGDCevf1rL66+J+KFqG7z6A28oRM/hMONB6HdAbulUFM5EJLxtLvQmEezZhL1bDxh9iTc+rTWbsDc2QNnKfYNYySKoDy4OG5ccHKyftzeIpQ+K6CDWGs451hWXUPbJP+ix8jmydy2i0RlzG0fwXMPJfJ5yCsMHBhjTP428AWmMDKQQH6PdCaSDFb4AL3/XG/Iw+dtwynchpvP/x0HhTEQiQ0M9rHrba01b9rLXytXzOK81bfR/eWO9Ghth2+r9glgB1AUXfY3tDlk5+3ZN9jhGS04AbFtD3YKnaVj4FAmVa6m1BN62CTxRM5EPG0cSEx3DiEAKef3TGDMgjbED0umX3g3r5CFWfFK5GV7+Diyd7Q1vmPGgt/ByF6FwJiKRp3o7FD7vjU/b8Im3CXuf0bBtjbeWGkBMAvTZL4hlDtXelIfjnLcTQcFTUPgc1JRTk9CLBeln8c+6yby8OY2aOm9makb3OMYMSAsGtnRy+qWSnBDr8w8QppzzZvp20jFS7cY5b+2+V3/gvV9TfgATbw3vGdwhoHAmIpGtdKUXJNZ/DJnH7g1iPYd3uX/Q211dDax41ftlufINaKzH9cll06ALeD9hCh9tjmbh+u2s2uq1TJrB0F5JjOmf7oW2AWkM7ZVMdFQXal2rr/Vab0u/gLIvvO97bteUe+txNc3uDX7vnul31eFhx3pvwP/KN701EPMfgJ7H+l2VLxTORETk8HZu3bttVMlCb9uooWdC7uWU9z+DhZtqWLhuBwuCS3qUV3uzXLvHRZPTz+sKHTMgvXNMNnAOdm5uFsBWQukK7/aOdXvXvANIDkDmEMgY6q2Bt2ciStnKvdekDth33GNWXtdaj66xEeY/Cm/c4b13p98B46/v0q3cCmciItI2W5YGt416BiqLIT4VRl0Y3DZqAg4oKqtiwTovqC1cv2OfnQ36pXdrCmpjwnmyQV01lK3aG8DKvgiGsFV7u88BYhO9XRgyhnpd503fh0B8UsvPXVPuTUxpPj5y+5q959Oz950tnJUb2btoHEzZKph1K6x9HwadCvn3ez97F6dwJiIiR6axwVupveBpWDoL6qq8X6y5V3j7p/YY1HTpnp0Nmreu7dnZIDbaGBFIZURWCoHUBLLSujV9z0pNICE2hMHNOago3tsFWbZyb1dk+XqatuACbxuujCHNAtgQrys9OdA+k0qqtx+4H+uOtXvP9xi8784TWbmRuyp+YwN89BC8/QuIjoOzfw5jrun0s6RbS+FMRESOXu1OWPai1+25+l3AwYCTvG2jRlzQYqtP084G63ewYO0OVm7dybZduw+4Lj0xlqzUbgTSEshK7Uaf1ISm24HUbvROjT98y9vuXXuDV9P3YIvYntm8AHFJBwawjKFey1hc96N6i45I1bZ9tworXhgMjUEZQ/eOYQuM8SbBHKy1LlxsWQr/vhk2zoNjz4Vp/+ct6CxNFM5ERKR9lW+Ez5/xZtOWLvf2Th12rteiNuR0iD74jM6augZKymso2VHtfS+vpnif+zVN49may0yKI5ASz4julYyM38wgKyFQv4GMmrV0r1xDzM7iZlcbpPX3Wr2aB7DM4LiwcG+92VW6704WxQu87mUADHoO27dLtM/o8Jgl2lAH7/8G3v0VxCfDef8Loy4O//fbBwpnIiISGs55LT4FT3t7p1aVQWKmtx1X7uVet9wR/GLeVbGdbeuWUFW8jPqtK4jdvoqknWvIqF1PvKttuq7CdWO1y2K1C7DaBSiNH0BVyiBIH0xmehpZqQlk7WmBS0ugZ1I8MZG6jVXl5n1b14o/8yYtgLfUTM/h+3aJ9hkFsd06rr7iBV5r2ebFMPIiOPdXkNSz414/wiiciYhI6DXUeUskFDwFy1+Bht3eIsK5l3sb3e/frdXY4HXfNV+KYk+XZGXJ3ussCtIG7jsQP3MoO5OyKa5PoaSilpIde1vfNlXUUBxshava3bDPS0ZHGb2S44OhzRv31ie12z7j4DKT4omKlKVBKkr27RLd+BlUlXrnLBp6jdh3lmjvUe2/+n5dDbx7D3xwP3Tv6XVhDj+/fV+jE1I4ExGRjrVnEeGCp7316TAYPMULCWWrvABWtmrvXqcACWkHDsTPGOpNOjiCQOGco6K6npKKakp21FBc7n3f05VaUu6FuNr6xn0eFxNl9E7ZO+YtKy2BrJQ94c27n9E9Ljx3TnAOKjYe2CVavc07HxULvY7bd+HmXiOOfC/bdR95rWVlX8CYq+Gsn0O39Hb7cTozhTMREfFP2SpvQ+uCp6F8gxe29h8HlnksJGZ0+Ngk5xzbq+q8sLZj7/i3TeV7W982ldewu2HfABcXHUWf1ASyUhMIpAUnMARv9++RSP/0RLrFhcnSIc55LZTNw1rxQqjZ4Z2PjoPeI/ftEu113CHHDVK7E96+Cz7+ozfDdfp93lhDaTWFMxER8Z9zXldmhO3q0Njo2Fa1u1nrWzUlFTV7w9yOGjZX1DSt8bZHz+R4BvZIZECPRPoHvw/I8L739Lvr1DnYXrTfLNECqC33zkfHe5MM9nSHBsZA5jDvs1v1Dsy+1VuM94Tr4Yw7vMH/0iYKZyIiIiHU2Ogo3VnLxh3VrN9ezfptVawt28W6bVWs31ZNcXk1zX/lxsdEeWGteXALhjffWt0aG71Fcpu3rpUshN07vfMx3bwlSDZ/Dj2OgRkPwMCJHV9nJ6FwJiIi4qPa+gaKd9SwbluV9xUMbuu2VbOubBe79pu40Cs5/sDwFmx165Uc33Hj3RobYduqvYFt0+fQ7wQ49fsdOxO0E1I4ExERCVN7xr2tC7a2rd8T4A7S6pYQG0X/9ANb3QZmJNIvnMa6ySEdLJxFVqe/iIhIJ2Rm9OgeR4/uceT1Tzvg/D6tbk0tbl6r20ery1rV6jZwz1i3jmx1kyOicCYiIhLm4mOiGZTZnUGZ3YF9F3Xd0+q2d3zb3la3j9ds4/mFGw/b6rYnuKnVLTwonImIiESw5q1uYwYcuL5YbX0DG7dXHxDcWtvqtie4qdWt4yiciYiIdGLxMdEM7pnE4J4HbpTunGPbrt3Nxre1rtVtYEYi2RndGZjZnezg7UBaN6IjZVeFMKdwJiIi0kWZGRlJ8WQkxbe61W1tmff9/ZWl1NTtXZg3Ntro3yORQRndGZjRnexML7R5wS0hcvcz9YHCmYiIiLTocK1umytqKSrbRVHpLorKvJmma0p3MXdVGdV1e7tLY6OtqcVtYIY3dm5P61u/9G4KbvtROBMREZE2MzP6pCbQJzWBEwdn7HPOOcfWylrWlO5ibVmVF+DKdlFU6nWXNt+MPibK6Jfe7YDQlp3pBbfYLhjcFM5ERESkXZkZvVIS6JWSwISWgtvOWtaWVQXDm9fqVlS6i/lrt7Oztr7p2ugoo29aN7KDY9u8AOd975+eSFxM5wxuCmciIiLSYcyMXskJ9EpO4ITsHvucc85Rtmv3Ad2ka8uqWLB2O5XNgluUQd/0bt7EhIy949uyM71ZpvExkbskiMKZiIiIhAUzIzMpnsykeMa1ENy27drd1MrW1OJWtot/Lyymsqa+2fNAILXbPpMSBmYkMiizO/17JJIQG97BTeFMREREwl7zmaXHD9x3Zqlzjh1VdawpC4a20j3j3Kp4cVEJ5dV1zZ4HslISyM4MzirNSAx2m3oBLhyCW0jDmZmdA/wWiAYecc7ds9/54cBjwFjgv51z9zY7dxvwVcABnwPXOudqQlmviIiIRB4zI717HOnd4xjbwpIgO6r2trgVle1qGu/26uIStlfV7XNtVmoC2Rnd+dtXxvs2izRk4czMooEHgTOBDcCnZjbLObek2WXbgFuBC/Z7bN/g8RHOuWozewa4HHg8VPWKiIhI55SWGEdeYsv7lpZX1TXNJl0bDHAVNXW+Lu8Rypaz8cBK59xqADN7GpgBNIUz59wWYIuZnX+Q2rqZWR2QCBSHsFYRERHpglITY8lNTCO3heDml1DGwr7A+mb3NwSPHZZzbiNwL7AOKAHKnXOvt3StmX3NzOaZ2bytW7ceZckiIiIi/gplOGtpgy3XwrEDH2iWjtfKNggIAN3N7OqWrnXOPeycG+ecG9ezZ88jLlZEREQkHIQynG0A+je734/Wd02eAaxxzm11ztUBzwET27k+ERERkbATynD2KTDUzAaZWRzegP5ZrXzsOuBEM0s0MwNOB5aGqE4RERGRsBGyCQHOuXozuxl4DW8pjUedc4VmdmPw/B/MrA8wD0gBGs3sW3gzND82s2eBz4B6YAHwcKhqFREREQkX5lyrhoFFhHHjxrl58+b5XYaIiIjIYZnZfOfcuP2Pd84dQ0VEREQilMKZiIiISBhROBMREREJIwpnIiIiImFE4UxEREQkjCiciYiIiIQRhTMRERGRMNKp1jkzs63AWr/riHCZQKnfRchR0WcY+fQZRjZ9fpGvoz7Dgc65AzYG71ThTI6emc1raUE8iRz6DCOfPsPIps8v8vn9GapbU0RERCSMKJyJiIiIhBGFM9mfNpiPfPoMI58+w8imzy/y+foZasyZiIiISBhRy5mIiIhIGFE4EwDMrL+ZvWNmS82s0My+6XdN0nZmFm1mC8zsRb9rkbYzszQze9bMlgX/Lp7kd03SNmZ2W/Df0MVm9pSZJfhdkxyamT1qZlvMbHGzYz3M7A0z+yL4Pb0ja1I4kz3qge84544DTgRuMrMRPtckbfdNYKnfRcgR+y3wqnNuOJCLPsuIYmZ9gVuBcc65UUA0cLm/VUkrPA6cs9+xHwBvOeeGAm8F73cYhTMBwDlX4pz7LHi7Eu+XQl9/q5K2MLN+wPnAI37XIm1nZinAKcCfAZxzu51zO3wtSo5EDNDNzGKARKDY53rkMJxzc4Bt+x2eAfwlePsvwAUdWZPCmRzAzLKBMcDHPpcibXMf8H2g0ec65MgMBrYCjwW7ph8xs+5+FyWt55zbCNwLrANKgHLn3Ov+ViVHqLdzrgS8xgugV0e+uMKZ7MPMkoB/Ad9yzlX4XY+0jplNA7Y45+b7XYscsRhgLPB759wYYBcd3JUiRyc4LmkGMAgIAN3N7Gp/q5JIpHAmTcwsFi+YPemce87veqRNJgH5ZlYEPA2cZmZP+FuStNEGYINzbk+L9bN4YU0ixxnAGufcVudcHfAcMNHnmuTIbDazLIDg9y0d+eIKZwKAmRneWJelzrn/87seaRvn3A+dc/2cc9l4A5Dfds7pf+wRxDm3CVhvZsOCh04HlvhYkrTdOuBEM0sM/pt6OprUEalmAV8O3v4y8O+OfPGYjnwxCWuTgGuAz81sYfDYj5xzL/tXkkiXcwvwpJnFAauBa32uR9rAOfexmT0LfIY3A34B2i0g7JnZU8AUINPMNgB3APcAz5jZV/BC96UdWpN2CBAREREJH+rWFBEREQkjCmciIiIiYUThTERERCSMKJyJiIiIhBGFMxEREZEwonAmIl2CmTWY2cJmX+22+r6ZZZvZ4vZ6PhHp2rTOmYh0FdXOuTy/ixARORy1nIlIl2ZmRWb2P2b2SfBrSPD4QDN7y8wWBb8PCB7vbWbPm1lB8GvP9jzRZvYnMys0s9fNrJtvP5SIRDSFMxHpKrrt1615WbNzFc658cADwH3BYw8Af3XO5QBPAvcHj98PvOucy8Xb+7IweHwo8KBzbiSwA7g4pD+NiHRa2iFARLoEM9vpnEtq4XgRcJpzbrWZxQKbnHMZZlYKZDnn6oLHS5xzmWa2FejnnKtt9hzZwBvOuaHB+7cDsc65n3fAjyYinYxazkREwB3k9sGuaUlts9sNaEyviBwhhTMREbis2fcPg7fnApcHb18FvB+8/RbwdQAzizazlI4qUkS6Bv3PTkS6im5mtrDZ/Vedc3uW04g3s4/x/sN6RfDYrcCjZvY9YCtwbfD4N4GHzewreC1kXwdKQl28iHQdGnMmIl1acMzZOOdcqd+1iIiAujVFREREwopazkRERETCiFrORERERMKIwpmIiIhIGFE4ExEREQkjCmciIiIiYUThTERERCSMKJyJiIiIhJH/D7v+6WLoNjXyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Training and Validation Loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), train_losses, label=\"Training Loss\")\n",
    "plt.plot(range(1, 11), val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7ab4bf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================================================\n",
      "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #                   Trainable\n",
      "================================================================================================================================================================\n",
      "BertLSTMClassifier                                           [1, 100]                  [1, 2]                    --                        True\n",
      "├─BertModel: 1-1                                             --                        [1, 768]                  --                        True\n",
      "│    └─BertEmbeddings: 2-1                                   --                        [1, 100, 768]             --                        True\n",
      "│    │    └─Embedding: 3-1                                   [1, 100]                  [1, 100, 768]             23,440,896                True\n",
      "│    │    └─Embedding: 3-2                                   [1, 100]                  [1, 100, 768]             1,536                     True\n",
      "│    │    └─Embedding: 3-3                                   [1, 100]                  [1, 100, 768]             393,216                   True\n",
      "│    │    └─LayerNorm: 3-4                                   [1, 100, 768]             [1, 100, 768]             1,536                     True\n",
      "│    │    └─Dropout: 3-5                                     [1, 100, 768]             [1, 100, 768]             --                        --\n",
      "│    └─BertEncoder: 2-2                                      [1, 100, 768]             [1, 100, 768]             --                        True\n",
      "│    │    └─ModuleList: 3-6                                  --                        --                        85,054,464                True\n",
      "│    └─BertPooler: 2-3                                       [1, 100, 768]             [1, 768]                  --                        True\n",
      "│    │    └─Linear: 3-7                                      [1, 768]                  [1, 768]                  590,592                   True\n",
      "│    │    └─Tanh: 3-8                                        [1, 768]                  [1, 768]                  --                        --\n",
      "├─LSTM: 1-2                                                  [1, 100, 768]             [1, 100, 128]             459,776                   True\n",
      "├─Linear: 1-3                                                [1, 128]                  [1, 2]                    258                       True\n",
      "================================================================================================================================================================\n",
      "Total params: 109,942,274\n",
      "Trainable params: 109,942,274\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 155.46\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 83.67\n",
      "Params size (MB): 439.77\n",
      "Estimated Total Size (MB): 523.44\n",
      "================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# Generate a summary of the model\n",
    "model_summary = summary(\n",
    "    model,\n",
    "    input_data=(torch.randint(0, tokenizer.vocab_size, (1, 100)).to(device),  # Simulate input_ids\n",
    "                torch.ones((1, 100), dtype=torch.long).to(device)),           # Simulate attention_mask\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    depth=3  # Depth of nested modules to display\n",
    ")\n",
    "\n",
    "print(model_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "628717f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Non-Depression       0.96      0.93      0.95     37311\n",
      "    Depression       0.77      0.85      0.81      9621\n",
      "\n",
      "      accuracy                           0.92     46932\n",
      "     macro avg       0.86      0.89      0.88     46932\n",
      "  weighted avg       0.92      0.92      0.92     46932\n",
      "\n",
      "Overall Accuracy: 0.9167\n",
      "Confusion Matrix:\n",
      "                Predicted Non-Depression  Predicted Depression\n",
      "Non-Depression                     34819                  2492\n",
      "Depression                          1417                  8204\n"
     ]
    }
   ],
   "source": [
    "# Switch the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Loop through test_loader to generate predictions\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, labels in test_loader:  # Unpack correctly\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        outputs = model(input_ids, attention_mask)  # Pass input_ids and attention_mask\n",
    "        _, preds = torch.max(outputs, 1)  # Get the predicted class\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Non-Depression', 'Depression']))\n",
    "\n",
    "# Print accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(conf_matrix, index=['Non-Depression', 'Depression'], \n",
    "                   columns=['Predicted Non-Depression', 'Predicted Depression']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c5896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to lstm_depression_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model_save_path = \"lstm_depression_model.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "599a2513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2657918/3397097680.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(model_save_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Predicted Label: 1 (0: Not Depressed, 1: Depressed)\n"
     ]
    }
   ],
   "source": [
    "# Reload the model\n",
    "loaded_model = BertLSTMClassifier().to(device)  # Reinitialize model architecture\n",
    "loaded_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "loaded_model.eval()  # Set model to evaluation mode\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# Example text input for inference\n",
    "example_text = \"I feel very sad and hopeless lately.\"\n",
    "\n",
    "# Preprocess the text\n",
    "encoded_input = tokenizer.encode_plus(\n",
    "    example_text,\n",
    "    add_special_tokens=True,\n",
    "    max_length=100,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "input_ids = encoded_input[\"input_ids\"].to(device)\n",
    "attention_mask = encoded_input[\"attention_mask\"].to(device)\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    output = loaded_model(input_ids, attention_mask)\n",
    "    prediction = torch.argmax(output, dim=1).item()\n",
    "\n",
    "print(f\"Predicted Label: {prediction} (0: Not Depressed, 1: Depressed)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98600e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
